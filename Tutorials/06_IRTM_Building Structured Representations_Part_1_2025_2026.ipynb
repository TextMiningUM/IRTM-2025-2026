{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f17561f53956c2c40d998254e44c7f3",
     "grade": false,
     "grade_id": "cell-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![maastricht-university-logo.jpeg](data:image/jpeg;base64,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)\n",
    "#Faculty of Science and Engineering - Department of Advanced Computer Sciences\n",
    "# Course Information Retrieval and Text Mining - Tutorial Building Structured Representations from Text - Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "058824685e11def6316e09324ed8a076",
     "grade": false,
     "grade_id": "cell-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By Jan Scholtes\n",
    "\n",
    "**Version 2025-2026**\n",
    "\n",
    "Welcome to the tutorial for the lectures on *Building Structured Representations from Text*. In this notebook you will learn how various NLP approaches let us deal with syntactic structures, semantics, co-reference & pronoun resolution, and negation handling — all fundamental steps on the road to building Knowledge Graphs from text.\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Understand and apply sentence detection, tokenization, stemming, and lemmatization\n",
    "2. Understand POS tagging: rule-based, statistical (HMM), and discriminative (CRF) approaches\n",
    "3. Know the mathematical foundations of HMMs and CRFs for sequence labelling\n",
    "4. Understand phrase detection (chunking) and dependency parsing\n",
    "5. Understand the principles of co-reference resolution and negation scope detection\n",
    "\n",
    "These methods have been used since the 1970s. In many aspects, they are limited and often slow. The goal of this tutorial is to let you experience hands-on the challenges in NLP (especially dealing with ambiguity), but also the limitations of grammar-based approaches (e.g. not being able to deal with ambiguity, wrong spelling, or unexpected grammatical use). This will help you understand why statistical and deep-learning methods are so much better for many NLP tasks.\n",
    "\n",
    "In Part 2 of this tutorial we will build on these foundations to perform Named Entity Recognition, Relation Extraction, and Knowledge Graph construction.\n",
    "\n",
    "In this notebook, we use the NLTK library throughout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cda95b4306edcbb1e5b777f507b50f2a",
     "grade": false,
     "grade_id": "cell-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Library Installation\n",
    "\n",
    "We install all required packages in a single cell. Run this cell once at the beginning of your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "225b83489706cac21200f6e5cb9ed0e7",
     "grade": false,
     "grade_id": "cell-4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (0.9.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from sklearn-crfsuite) (0.9.12)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from sklearn-crfsuite) (1.8.0)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from sklearn-crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from sklearn-crfsuite) (4.67.3)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (2.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jcsch\\onedrive - dennenhof capital bv\\documents\\um\\irtm\\irtm 2025-2026\\.venv\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess, sys\n",
    "\n",
    "packages = [\"python-crfsuite\", \"sklearn-crfsuite\", \"fastcoref\"]\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbd1ee1b4b4e640073bcd325600a80f3",
     "grade": false,
     "grade_id": "cell-5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n",
      "[nltk_data] Downloading package tagsets_json to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets_json is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jcsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('book')\n",
    "nltk.download('tagsets_json')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('treebank')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8362f59fa2f3f4abe84afc80b90f6485",
     "grade": false,
     "grade_id": "cell-6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "NLTK comes with many corpora, toy grammars, trained models, etc. A complete list is posted at: https://www.nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "791828bd7040fc38773a66a6fa404e1a",
     "grade": false,
     "grade_id": "cell-7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Load Data\n",
    "\n",
    "We will use the Moby Dick corpus from NLTK for our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d17b15c0ccb791ac12fe7dc08d19ff7e",
     "grade": false,
     "grade_id": "cell-8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e04796ee5128a89bd4e2c81d96f0e38",
     "grade": false,
     "grade_id": "cell-9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar', 'School', ')', 'The', 'pale', 'Usher', '--', 'threadbare', 'in', 'coat', ',', 'heart', ',', 'body', ',', 'and', 'brain', ';', 'I', 'see', 'him', 'now', '.', 'He', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', ',', 'with', 'a', 'queer', 'handkerchief', ',', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', '.', 'He', 'loved', 'to', 'dust', 'his', 'old', 'grammars', ';', 'it', 'somehow', 'mildly', 'reminded', 'him', 'of', 'his', 'mortality', '.', '\"', 'While', 'you', 'take', 'in', 'hand', 'to', 'school', 'others', ',', 'and', 'to', 'teach', 'them', 'by', 'what', 'name', 'a', 'whale', '-', 'fish', 'is', 'to', 'be', 'called', 'in', 'our', 'tongue', 'leaving', 'out', ',', 'through', 'ignorance', ',', 'the', 'letter', 'H', ',', 'which', 'almost', 'alone', 'maketh', 'the', 'signification', 'of', 'the', 'word', ',', 'you', 'deliver', 'that', 'which', 'is', 'not', 'true', '.\"', '--', 'HACKLUYT', '\"', 'WHALE', '.', '...', 'Sw', '.', 'and', 'Dan', '.', 'HVAL', '.', 'This', 'animal', 'is', 'named', 'from', 'roundness', 'or', 'rolling', ';', 'for', 'in', 'Dan', '.', 'HVALT', 'is', 'arched', 'or', 'vaulted', '.\"', '--', 'WEBSTER', \"'\", 'S', 'DICTIONARY', '\"', 'WHALE', '.', '...', 'It', 'is', 'more', 'immediately', 'from', 'the', 'Dut', '.', 'and', 'Ger', '.', 'WALLEN', ';', 'A', '.', 'S', '.', 'WALW', '-', 'IAN', ',', 'to', 'roll', ',', 'to', 'wallow', '.\"', '--', 'RICHARDSON', \"'\", 'S', 'DICTIONARY', 'KETOS', ',', 'GREEK', '.', 'CETUS', ',', 'LATIN', '.', 'WHOEL', ',', 'ANGLO', '-', 'SAXON', '.', 'HVALT', ',', 'DANISH', '.', 'WAL', ',', 'DUTCH', '.', 'HWAL', ',', 'SWEDISH', '.', 'WHALE', ',', 'ICELANDIC', '.', 'WHALE', ',', 'ENGLISH', '.', 'BALEINE', ',', 'FRENCH', '.', 'BALLENA', ',', 'SPANISH', '.', 'PEKEE', '-', 'NUEE', '-', 'NUEE', ',', 'FEGEE', '.', 'PEKEE', '-', 'NUEE', '-', 'NUEE', ',', 'ERROMANGOAN', '.', 'EXTRACTS', '(', 'Supplied', 'by', 'a', 'Sub', '-', 'Sub', '-', 'Librarian', ').', 'It', 'will', 'be', 'seen', 'that', 'this', 'mere', 'painstaking', 'burrower', 'and', 'grub', '-', 'worm', 'of', 'a', 'poor', 'devil', 'of', 'a', 'Sub', '-', 'Sub', 'appears', 'to', 'have', 'gone', 'through', 'the', 'long', 'Vaticans', 'and', 'street', '-', 'stalls', 'of', 'the', 'earth', ',', 'picking', 'up', 'whatever', 'random', 'allusions', 'to', 'whales', 'he', 'could', 'anyways', 'find', 'in', 'any', 'book', 'whatsoever', ',', 'sacred', 'or', 'profane', '.', 'Therefore', 'you', 'must', 'not', ',', 'in', 'every', 'case', 'at', 'least', ',', 'take', 'the', 'higgledy', '-', 'piggledy', 'whale', 'statements', ',', 'however', 'authentic', ',', 'in', 'these', 'extracts', ',', 'for', 'veritable', 'gospel', 'cetology', '.', 'Far', 'from', 'it', '.', 'As', 'touching', 'the', 'ancient', 'authors', 'generally', ',', 'as', 'well', 'as', 'the', 'poets', 'here', 'appearing', ',', 'these', 'extracts', 'are', 'solely', 'valuable', 'or', 'entertaining', ',', 'as', 'affording', 'a', 'glancing', 'bird', \"'\", 's', 'eye', 'view', 'of', 'what', 'has', 'been', 'promiscuously', 'said', ',', 'thought', ',', 'fancied', ',', 'and', 'sung', 'of', 'Leviathan', ',', 'by', 'many', 'nations', 'and', 'generations', ',', 'including', 'our', 'own', '.', 'So', 'fare', 'thee', 'well', ',', 'poor', 'devil', 'of', 'a', 'Sub', '-', 'Sub', ',', 'whose', 'commentator', 'I', 'am', '.', 'Thou', 'belongest', 'to', 'that', 'hopeless', ',', 'sallow', 'tribe', 'which', 'no', 'wine', 'of', 'this', 'world', 'will', 'ever', 'warm', ';', 'and', 'for', 'whom', 'even', 'Pale', 'Sherry', 'would', 'be', 'too', 'rosy', '-', 'strong', ';', 'but', 'with', 'whom', 'one', 'sometimes', 'loves', 'to', 'sit', ',', 'and', 'feel', 'poor', '-', 'devilish', ',', 'too', ';', 'and', 'grow', 'convivial', 'upon', 'tears', ';', 'and', 'say', 'to', 'them', 'bluntly', ',', 'with', 'full', 'eyes', 'and', 'empty', 'glasses', ',', 'and', 'in', 'not', 'altogether', 'unpleasant', 'sadness', '--', 'Give', 'it', 'up', ',', 'Sub', '-', 'Subs', '!', 'For', 'by', 'how', 'much', 'the', 'more', 'pains', 'ye', 'take', 'to', 'please', 'the', 'world', ',', 'by', 'so', 'much', 'the', 'more', 'shall', 'ye', 'for', 'ever', 'go', 'thankless', '!', 'Would', 'that', 'I', 'could', 'clear', 'out', 'Hampton', 'Court', 'and', 'the', 'Tuileries', 'for', 'ye', '!', 'But', 'gulp', 'down', 'your', 'tears', 'and', 'hie', 'aloft', 'to', 'the', 'royal', '-', 'mast', 'with', 'your', 'hearts', ';', 'for', 'your', 'friends', 'who', 'have', 'gone', 'before', 'are', 'clearing', 'out', 'the', 'seven', '-', 'storied', 'heavens', ',', 'and', 'making', 'refugees', 'of', 'long', '-', 'pampered', 'Gabriel', ',', 'Michael', ',', 'and', 'Raphael', ',', 'against', 'your', 'coming', '.', 'Here', 'ye', 'strike', 'but', 'splintered', 'hearts', 'together', '--', 'there', ',', 'ye', 'shall', 'strike', 'unsplinterable', 'glasses', '!', 'EXTRACTS', '.', '\"', 'And', 'God', 'created', 'great', 'whales', '.\"', '--', 'GENESIS', '.', '\"', 'Leviathan', 'maketh', 'a', 'path', 'to', 'shine', 'after', 'him', ';', 'One', 'would', 'think', 'the', 'deep', 'to', 'be', 'hoary', '.\"', '--', 'JOB', '.', '\"', 'Now', 'the', 'Lord', 'had', 'prepared', 'a', 'great', 'fish', 'to', 'swallow', 'up', 'Jonah', '.\"', '--', 'JONAH', '.', '\"', 'There', 'go', 'the', 'ships', ';', 'there', 'is', 'that', 'Leviathan', 'whom', 'thou', 'hast', 'made', 'to', 'play', 'therein', '.\"', '--', 'PSALMS', '.', '\"', 'In', 'that', 'day', ',', 'the', 'Lord', 'with', 'his', 'sore', ',', 'and', 'great', ',', 'and', 'strong', 'sword', ',', 'shall', 'punish', 'Leviathan', 'the', 'piercing', 'serpent', ',', 'even', 'Leviathan', 'that', 'crooked', 'serpent', ';', 'and', 'he', 'shall', 'slay', 'the', 'dragon', 'that', 'is', 'in', 'the', 'sea', '.\"', '--', 'ISAIAH', '\"', 'And', 'what', 'thing', 'soever', 'besides', 'cometh', 'within', 'the', 'chaos', 'of', 'this', 'monster', \"'\", 's', 'mouth', ',', 'be', 'it', 'beast', ',', 'boat', ',', 'or', 'stone', ',', 'down', 'it', 'goes', 'all', 'incontinently', 'that', 'foul', 'great', 'swallow', 'of', 'his', ',', 'and', 'perisheth', 'in', 'the', 'bottomless', 'gulf', 'of', 'his', 'paunch', '.\"', '--', 'HOLLAND', \"'\", 'S', 'PLUTARCH', \"'\", 'S', 'MORALS', '.', '\"', 'The', 'Indian', 'Sea', 'breedeth', 'the', 'most', 'and', 'the', 'biggest', 'fishes', 'that', 'are', ':', 'among', 'which', 'the', 'Whales', 'and', 'Whirlpooles', 'called', 'Balaene', ',', 'take', 'up', 'as', 'much', 'in', 'length', 'as', 'four', 'acres', 'or', 'arpens', 'of', 'land', '.\"', '--', 'HOLLAND', \"'\", 'S', 'PLINY', '.', '\"', 'Scarcely', 'had', 'we', 'proceeded', 'two', 'days', 'on', 'the', 'sea', ',', 'when', 'about', 'sunrise', 'a', 'great', 'many', 'Whales', 'and', 'other', 'monsters', 'of', 'the', 'sea', ',', 'appeared', '.', 'Among', 'the', 'former', ',', 'one', 'was', 'of', 'a', 'most', 'monstrous', 'size', '.', '...', 'This', 'came', 'towards', 'us', ',', 'open', '-', 'mouthed', ',', 'raising', 'the', 'waves', 'on', 'all', 'sides', ',', 'and', 'beating', 'the', 'sea', 'before', 'him', 'into', 'a', 'foam', '.\"', '--', 'TOOKE', \"'\", 'S', 'LUCIAN', '.', '\"', 'THE', 'TRUE', 'HISTORY', '.\"', '\"', 'He', 'visited', 'this', 'country', 'also', 'with', 'a', 'view', 'of', 'catching', 'horse', '-', 'whales', ',', 'which', 'had', 'bones', 'of', 'very', 'great', 'value', 'for', 'their', 'teeth', ',', 'of', 'which', 'he', 'brought', 'some', 'to', 'the', 'king', '.', '...', 'The', 'best', 'whales', 'were', 'catched', 'in', 'his', 'own', 'country', ',', 'of', 'which', 'some', 'were', 'forty', '-', 'eight', ',', 'some', 'fifty', 'yards', 'long', '.', 'He']\n"
     ]
    }
   ],
   "source": [
    "list_of_text = text1\n",
    "print(list_of_text[0:1000:1])  # print first 1000 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f31e69c0a21f846e13127fe9a515568",
     "grade": false,
     "grade_id": "cell-10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's convert this list to a long string, as this is what NLTK requires as input and what you would normally get from any preprocessing text-extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb081b5af76873fe469ab524d4343a23",
     "grade": false,
     "grade_id": "cell-11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Moby Dick by Herman Melville 1851 ] ETYMOLOGY . ( Supplied by a Late Consumptive Usher to a Grammar School ) The pale Usher -- threadbare in coat , heart , body , and brain ; I see him now . He was ever dusting his old lexicons and grammars , with a queer handkerchief , mockingly embellished with all the gay flags of all the known nations of the world . He loved to dust his old grammars ; it somehow mildly reminded him of his mortality . \" While you take in hand to school others , and to teach them by what name a whale - fish is to be called in our tongue leaving out , through ignorance , the letter H , which almost alone maketh the signification of the word , you deliver that which is not true .\" -- HACKLUYT \" WHALE . ... Sw . and Dan . HVAL . This animal is named from roundness or rolling ; for in Dan . HVALT is arched or vaulted .\" -- WEBSTER ' S DICTIONARY \" WHALE . ... It is more immediately from the Dut . and Ger . WALLEN ; A . S . WALW - IAN , to roll , to wallow .\" -- RICHARDSON ' S DICTIONARY KETOS , GREEK . CETUS , LATIN . WHOEL , ANGLO - SAXON . HVALT , DANISH . WAL , DUTCH . HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALEINE , FRENCH . BALLENA , SPANISH . PEKEE - NUEE - NUEE , FEGEE . PEKEE - NUEE - NUEE , ERROMANGOAN . EXTRACTS ( Supplied by a Sub - Sub - Librarian ). It will be seen that this mere painstaking burrower and grub - worm of a poor devil of a Sub - Sub appears to have gone through the long Vaticans and street - stalls of the earth , picking up whatever random allusions to whales he could anyways find in any book whatsoever , sacred or profane . Therefore you must not , in every case at least , take the higgledy - piggledy whale statements , however authentic , in these extracts , for veritable gospel cetology . Far from it . As touching the ancient authors generally , as well as the poets here appearing , these extracts are solely valuable or entertaining , as affording a glancing bird ' s eye view of what has been promiscuous\n"
     ]
    }
   ],
   "source": [
    "RawTextMobyDick = \" \".join(list_of_text)\n",
    "print(RawTextMobyDick[:2000])  # print first 2000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02ad5ad5e7948fc0f112095eb5d61a35",
     "grade": false,
     "grade_id": "cell-12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Sentence Detection\n",
    "\n",
    "Sentence detection (or sentence segmentation) is the task of splitting a text into individual sentences. This is harder than it looks — periods can appear in abbreviations (\"Dr.\"), numbers (\"3.14\"), and URLs.\n",
    "\n",
    "NLTK's Punkt tokenizer uses an unsupervised algorithm trained on large corpora to detect sentence boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06140625d7c206c0efe5839838e6579b",
     "grade": false,
     "grade_id": "cell-13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [ Moby Dick by Herman Melville 1851 ] ETYMOLOGY .\n",
      "[1] ( Supplied by a Late Consumptive Usher to a Grammar School ) The pale Usher -- threadbare in coat , heart , body , and brain ; I see him now .\n",
      "[2] He was ever dusting his old lexicons and grammars , with a queer handkerchief , mockingly embellished with all the gay flags of all the known nations of the world .\n",
      "[3] He loved to dust his old grammars ; it somehow mildly reminded him of his mortality . \"\n",
      "[4] While you take in hand to school others , and to teach them by what name a whale - fish is to be called in our tongue leaving out , through ignorance , the letter H , which almost alone maketh the signification of the word , you deliver that which is not true .\"\n",
      "[5] -- HACKLUYT \" WHALE .\n",
      "[6] ... Sw .\n",
      "[7] and Dan .\n",
      "[8] HVAL .\n",
      "[9] This animal is named from roundness or rolling ; for in Dan .\n",
      "[10] HVALT is arched or vaulted .\"\n",
      "[11] -- WEBSTER ' S DICTIONARY \" WHALE .\n",
      "[12] ...\n",
      "[13] It is more immediately from the Dut .\n",
      "[14] and Ger .\n",
      "[15] WALLEN ; A .\n",
      "[16] S .\n",
      "[17] WALW - IAN , to roll , to wallow .\"\n",
      "[18] -- RICHARDSON ' S DICTIONARY KETOS , GREEK .\n",
      "[19] CETUS , LATIN .\n",
      "[20] WHOEL , ANGLO - SAXON .\n",
      "[21] HVALT , DANISH .\n",
      "[22] WAL , DUTCH .\n",
      "[23] HWAL , SWEDISH .\n",
      "[24] WHALE , ICELANDIC .\n",
      "[25] WHALE , ENGLISH .\n",
      "[26] BALEINE , FRENCH .\n",
      "[27] BALLENA , SPANISH .\n",
      "[28] PEKEE - NUEE - NUEE , FEGEE .\n",
      "[29] PEKEE - NUEE - NUEE , ERROMANGOAN .\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "sentences = tokenizer.tokenize(RawTextMobyDick)\n",
    "\n",
    "for i, s in enumerate(sentences[:30]):\n",
    "    print(f\"[{i}] {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5916283fc508510afebf37e44f139602",
     "grade": false,
     "grade_id": "cell-14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 4. Tokenization\n",
    "\n",
    "We tokenize the text into individual words (tokens). We leave punctuation in, as we need it later for linguistic operations like POS tagging and parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b0743463c2b3aa6299b453e3bdb5b53",
     "grade": false,
     "grade_id": "cell-15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "Moby\n",
      "Dick\n",
      "by\n",
      "Herman\n",
      "Melville\n",
      "1851\n",
      "]\n",
      "ETYMOLOGY\n",
      ".\n",
      "(\n",
      "Supplied\n",
      "by\n",
      "a\n",
      "Late\n",
      "Consumptive\n",
      "Usher\n",
      "to\n",
      "a\n",
      "Grammar\n",
      "School\n",
      ")\n",
      "The\n",
      "pale\n",
      "Usher\n",
      "--\n",
      "threadbare\n",
      "in\n",
      "coat\n",
      ",\n",
      "heart\n",
      ",\n",
      "body\n",
      ",\n",
      "and\n",
      "brain\n",
      ";\n",
      "I\n",
      "see\n",
      "him\n",
      "now\n",
      ".\n",
      "He\n",
      "was\n",
      "ever\n",
      "dusting\n",
      "his\n",
      "old\n",
      "lexicons\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(RawTextMobyDick)\n",
    "\n",
    "for i, w in enumerate(words[:50]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf60dcb3c5704c751ac6ba07fd225c4a",
     "grade": false,
     "grade_id": "cell-16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 5. Stemming\n",
    "\n",
    "Stemming reduces words to their root form by stripping suffixes using simple rules. The most common stemmer for English is the **Porter Stemmer** (1980).\n",
    "\n",
    "While fast, stemming often produces non-words (e.g. \"studies\" → \"studi\", \"university\" → \"univers\"). It has no linguistic knowledge — it merely applies character-level transformation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7d04db0ba26f66953c7b776d9366996",
     "grade": false,
     "grade_id": "cell-17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    → [\n",
      "Moby                 → mobi\n",
      "Dick                 → dick\n",
      "by                   → by\n",
      "Herman               → herman\n",
      "Melville             → melvil\n",
      "1851                 → 1851\n",
      "]                    → ]\n",
      "ETYMOLOGY            → etymolog\n",
      ".                    → .\n",
      "(                    → (\n",
      "Supplied             → suppli\n",
      "by                   → by\n",
      "a                    → a\n",
      "Late                 → late\n",
      "Consumptive          → consumpt\n",
      "Usher                → usher\n",
      "to                   → to\n",
      "a                    → a\n",
      "Grammar              → grammar\n",
      "School               → school\n",
      ")                    → )\n",
      "The                  → the\n",
      "pale                 → pale\n",
      "Usher                → usher\n",
      "--                   → --\n",
      "threadbare           → threadbar\n",
      "in                   → in\n",
      "coat                 → coat\n",
      ",                    → ,\n",
      "heart                → heart\n",
      ",                    → ,\n",
      "body                 → bodi\n",
      ",                    → ,\n",
      "and                  → and\n",
      "brain                → brain\n",
      ";                    → ;\n",
      "I                    → i\n",
      "see                  → see\n",
      "him                  → him\n",
      "now                  → now\n",
      ".                    → .\n",
      "He                   → he\n",
      "was                  → wa\n",
      "ever                 → ever\n",
      "dusting              → dust\n",
      "his                  → hi\n",
      "old                  → old\n",
      "lexicons             → lexicon\n",
      "and                  → and\n",
      "grammars             → grammar\n",
      ",                    → ,\n",
      "with                 → with\n",
      "a                    → a\n",
      "queer                → queer\n",
      "handkerchief         → handkerchief\n",
      ",                    → ,\n",
      "mockingly            → mockingli\n",
      "embellished          → embellish\n",
      "with                 → with\n",
      "all                  → all\n",
      "the                  → the\n",
      "gay                  → gay\n",
      "flags                → flag\n",
      "of                   → of\n",
      "all                  → all\n",
      "the                  → the\n",
      "known                → known\n",
      "nations              → nation\n",
      "of                   → of\n",
      "the                  → the\n",
      "world                → world\n",
      ".                    → .\n",
      "He                   → he\n",
      "loved                → love\n",
      "to                   → to\n",
      "dust                 → dust\n",
      "his                  → hi\n",
      "old                  → old\n",
      "grammars             → grammar\n",
      ";                    → ;\n",
      "it                   → it\n",
      "somehow              → somehow\n",
      "mildly               → mildli\n",
      "reminded             → remind\n",
      "him                  → him\n",
      "of                   → of\n",
      "his                  → hi\n",
      "mortality            → mortal\n",
      ".                    → .\n",
      "``                   → ``\n",
      "While                → while\n",
      "you                  → you\n",
      "take                 → take\n",
      "in                   → in\n",
      "hand                 → hand\n",
      "to                   → to\n",
      "school               → school\n",
      "others               → other\n",
      ",                    → ,\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for i, w in enumerate(words[:100]):\n",
    "    print(f\"{w:20s} → {ps.stem(w)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c00af2d56694295ae198c2c77b5e44f",
     "grade": false,
     "grade_id": "cell-18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 6. POS Tagging (Rule-Based)\n",
    "\n",
    "**Part-of-Speech (POS) tagging** is the process of assigning a grammatical tag (noun, verb, adjective, etc.) to each word in a text based on its definition and context.\n",
    "\n",
    "Schools teach 9 parts of speech in English: noun, verb, article, adjective, preposition, pronoun, adverb, conjunction, and interjection. However, annotation schemes like the **Penn Treebank** tag set use ~45 fine-grained tags.\n",
    "\n",
    "## The Penn Treebank\n",
    "\n",
    "The Penn Treebank (PTB) project annotated 2,499 Wall Street Journal stories with syntactic structure. Its POS tag set has become the de facto standard. Below is a summary of the most important tags:\n",
    "\n",
    "| Tag | Description | Example |\n",
    "|-----|------------|---------|\n",
    "| NN  | Noun, singular | dog, city |\n",
    "| NNS | Noun, plural | dogs, cities |\n",
    "| NNP | Proper noun, singular | London, Jan |\n",
    "| VB  | Verb, base form | run, eat |\n",
    "| VBD | Verb, past tense | ran, ate |\n",
    "| VBG | Verb, gerund | running, eating |\n",
    "| VBN | Verb, past participle | run, eaten |\n",
    "| JJ  | Adjective | big, fast |\n",
    "| RB  | Adverb | quickly, very |\n",
    "| DT  | Determiner | the, a, an |\n",
    "| IN  | Preposition | in, of, by |\n",
    "| PRP | Personal pronoun | he, she, it |\n",
    "| CC  | Coordinating conjunction | and, but, or |\n",
    "\n",
    "The full list can be viewed with `nltk.help.upenn_tagset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb948fc5e8793d969778d06f07a1b9d",
     "grade": false,
     "grade_id": "cell-19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94e35b9fff7e9c8a3ace0847bde16986",
     "grade": false,
     "grade_id": "cell-20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's apply POS tagging to our text using NLTK's default tagger (a trained Averaged Perceptron model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6986be542fdbb9c7c13a85916755232",
     "grade": false,
     "grade_id": "cell-21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[', 'JJ')\n",
      "('Moby', 'NNP')\n",
      "('Dick', 'NNP')\n",
      "('by', 'IN')\n",
      "('Herman', 'NNP')\n",
      "('Melville', 'NNP')\n",
      "('1851', 'CD')\n",
      "(']', 'NNP')\n",
      "('ETYMOLOGY', 'NNP')\n",
      "('.', '.')\n",
      "('(', '(')\n",
      "('Supplied', 'VBN')\n",
      "('by', 'IN')\n",
      "('a', 'DT')\n",
      "('Late', 'JJ')\n",
      "('Consumptive', 'NNP')\n",
      "('Usher', 'NNP')\n",
      "('to', 'TO')\n",
      "('a', 'DT')\n",
      "('Grammar', 'NNP')\n",
      "('School', 'NNP')\n",
      "(')', ')')\n",
      "('The', 'DT')\n",
      "('pale', 'NN')\n",
      "('Usher', 'NNP')\n",
      "('--', ':')\n",
      "('threadbare', 'NN')\n",
      "('in', 'IN')\n",
      "('coat', 'NN')\n",
      "(',', ',')\n",
      "('heart', 'NN')\n",
      "(',', ',')\n",
      "('body', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('brain', 'NN')\n",
      "(';', ':')\n",
      "('I', 'PRP')\n",
      "('see', 'VBP')\n",
      "('him', 'PRP')\n",
      "('now', 'RB')\n",
      "('.', '.')\n",
      "('He', 'PRP')\n",
      "('was', 'VBD')\n",
      "('ever', 'RB')\n",
      "('dusting', 'VBG')\n",
      "('his', 'PRP$')\n",
      "('old', 'JJ')\n",
      "('lexicons', 'NNS')\n",
      "('and', 'CC')\n",
      "('grammars', 'NNS')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('a', 'DT')\n",
      "('queer', 'NN')\n",
      "('handkerchief', 'NN')\n",
      "(',', ',')\n",
      "('mockingly', 'RB')\n",
      "('embellished', 'VBN')\n",
      "('with', 'IN')\n",
      "('all', 'PDT')\n",
      "('the', 'DT')\n",
      "('gay', 'NN')\n",
      "('flags', 'NNS')\n",
      "('of', 'IN')\n",
      "('all', 'PDT')\n",
      "('the', 'DT')\n",
      "('known', 'VBN')\n",
      "('nations', 'NNS')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "('world', 'NN')\n",
      "('.', '.')\n",
      "('He', 'PRP')\n",
      "('loved', 'VBD')\n",
      "('to', 'TO')\n",
      "('dust', 'VB')\n",
      "('his', 'PRP$')\n",
      "('old', 'JJ')\n",
      "('grammars', 'NNS')\n",
      "(';', ':')\n",
      "('it', 'PRP')\n",
      "('somehow', 'VBZ')\n",
      "('mildly', 'RB')\n",
      "('reminded', 'VBD')\n",
      "('him', 'PRP')\n",
      "('of', 'IN')\n",
      "('his', 'PRP$')\n",
      "('mortality', 'NN')\n",
      "('.', '.')\n",
      "('``', '``')\n",
      "('While', 'IN')\n",
      "('you', 'PRP')\n",
      "('take', 'VBP')\n",
      "('in', 'IN')\n",
      "('hand', 'NN')\n",
      "('to', 'TO')\n",
      "('school', 'NN')\n",
      "('others', 'NNS')\n",
      "(',', ',')\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "words_with_pos = nltk.pos_tag(words)\n",
    "\n",
    "for i, w in enumerate(words_with_pos[:100]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aad03ba5e5ed7afd6856adc1dbda706",
     "grade": false,
     "grade_id": "cell-22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 7. Lemmatization with POS Tags\n",
    "\n",
    "Stemming algorithms simply remove suffixes using rules, often producing non-linguistic outputs. **Lemmatization** instead performs morphological analysis — it returns the dictionary form (**lemma**) of a word by considering its grammatical role.\n",
    "\n",
    "For example:\n",
    "- \"better\" → \"good\" (adjective lemma)\n",
    "- \"ran\" → \"run\" (verb lemma)\n",
    "- \"mice\" → \"mouse\" (noun lemma)\n",
    "\n",
    "NLTK's `WordNetLemmatizer` requires the POS tag to work correctly. It accepts simplified tags: `'n'` (noun), `'v'` (verb), `'a'` (adjective), `'r'` (adverb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae810482a8996d368c9cc65ecb057fd8",
     "grade": false,
     "grade_id": "cell-23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS   Stem            Lemma          \n",
      "-------------------------------------------------------\n",
      "better          JJR   better          good           \n",
      "worse           NN    wors            worse          \n",
      "running         VBG   run             run            \n",
      "ran             JJ    ran             ran            \n",
      "mice            NN    mice            mouse          \n",
      "studies         NNS   studi           study          \n",
      "universities    NNS   univers         university     \n",
      "went            VBD   went            go             \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Map Penn Treebank tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'  # adjective\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'  # verb\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'  # noun\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'  # adverb\n",
    "    else:\n",
    "        return 'n'  # default to noun\n",
    "\n",
    "# Demonstrate lemmatization vs stemming\n",
    "demo_words = [\"better\", \"worse\", \"running\", \"ran\", \"mice\", \"studies\", \"universities\", \"went\"]\n",
    "demo_tagged = nltk.pos_tag(demo_words)\n",
    "\n",
    "print(f\"{'Word':15s} {'POS':5s} {'Stem':15s} {'Lemma':15s}\")\n",
    "print(\"-\" * 55)\n",
    "for word, tag in demo_tagged:\n",
    "    stem = ps.stem(word)\n",
    "    lemma = lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
    "    print(f\"{word:15s} {tag:5s} {stem:15s} {lemma:15s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4a0d23b5df7f5e61ff7677fd6cf176d",
     "grade": false,
     "grade_id": "cell-24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how lemmatization produces actual English words (\"better\" → \"good\", \"ran\" → \"run\"), while stemming produces non-words (\"better\" → \"better\", \"ran\" → \"ran\" or truncated forms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a8f36463f38d52107ca9bd577a7a18f",
     "grade": false,
     "grade_id": "cell-25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 8. Phrase Detection (Chunking)\n",
    "\n",
    "Above POS tags, sentences have higher-level syntactic structure. The most common phrases are **Noun Phrases (NP)** and **Verb Phrases (VP)**. Detecting these is useful for:\n",
    "- Understanding where a noun begins and ends (e.g. \"the big red dog\")\n",
    "- Identifying subjects and objects\n",
    "- Extracting candidate entities for Knowledge Graphs\n",
    "\n",
    "We define phrase patterns using **regular expressions over POS tags** and parse them with NLTK's `RegexpParser`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fba76b075b1ea4665ead8b519a56b004",
     "grade": false,
     "grade_id": "cell-26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Noun Phrase Chunking\n",
    "\n",
    "A simple NP grammar: an optional determiner, followed by zero or more adjectives, followed by a noun:\n",
    "\n",
    "```\n",
    "NP: {<DT>?<JJ>*<NN.*>+}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "669fb31f833bdc52f3853bdf8f0c768e",
     "grade": false,
     "grade_id": "cell-27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags: [('The', 'DT'), ('big', 'JJ'), ('red', 'JJ'), ('dog', 'NN'), ('chased', 'VBD'), ('the', 'DT'), ('small', 'JJ'), ('white', 'JJ'), ('cat', 'NN'), ('across', 'IN'), ('the', 'DT'), ('green', 'JJ'), ('field', 'NN')]\n",
      "\n",
      "Chunked result:\n",
      "(S\n",
      "  (NP The/DT big/JJ red/JJ dog/NN)\n",
      "  chased/VBD\n",
      "  (NP the/DT small/JJ white/JJ cat/NN)\n",
      "  across/IN\n",
      "  (NP the/DT green/JJ field/NN))\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser\n",
    "\n",
    "sentence = \"The big red dog chased the small white cat across the green field\"\n",
    "sentence_words = nltk.tokenize.word_tokenize(sentence)\n",
    "pos_sentence = nltk.pos_tag(sentence_words)\n",
    "print(\"POS tags:\", pos_sentence)\n",
    "\n",
    "# Define NP grammar\n",
    "grammar = 'NP: {<DT>?<JJ>*<NN.*>+}'\n",
    "cp = RegexpParser(grammar)\n",
    "result = cp.parse(pos_sentence)\n",
    "print(\"\\nChunked result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0474e6313fe562ea11a5612517e73b74",
     "grade": false,
     "grade_id": "cell-28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Verb Phrase Chunking\n",
    "\n",
    "We can similarly define a VP pattern — e.g. a modal or auxiliary verb followed by a main verb:\n",
    "\n",
    "```\n",
    "VP: {<MD>?<VB.*>+}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b51956db4d6a56b4d5faa54ce2214921",
     "grade": false,
     "grade_id": "cell-29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT student/NN)\n",
      "  (VP should/MD have/VB completed/VBN)\n",
      "  (NP the/DT assignment/NN)\n",
      "  before/IN\n",
      "  (NP the/DT deadline/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar_vp = \"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN.*>+}\n",
    "    VP: {<MD>?<VB.*>+}\n",
    "\"\"\"\n",
    "cp_vp = RegexpParser(grammar_vp)\n",
    "\n",
    "sentence2 = \"The student should have completed the assignment before the deadline\"\n",
    "words2 = nltk.tokenize.word_tokenize(sentence2)\n",
    "pos2 = nltk.pos_tag(words2)\n",
    "result2 = cp_vp.parse(pos2)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20a9edb2f152f10965b41635a259bca0",
     "grade": false,
     "grade_id": "cell-30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 9. Statistical POS Tagging — Hidden Markov Models (HMMs)\n",
    "\n",
    "The rule-based NLTK tagger works reasonably well, but to understand *why*, we need to look at the statistical models behind sequence labelling.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "A **Hidden Markov Model** is a generative probabilistic model for sequences. It models the **joint probability** of a tag sequence $T = t_1, t_2, \\ldots, t_n$ and a word sequence $W = w_1, w_2, \\ldots, w_n$.\n",
    "\n",
    "An HMM is defined by:\n",
    "\n",
    "**1. States:** The set of POS tags $\\{t_1, t_2, \\ldots, t_K\\}$\n",
    "\n",
    "**2. Transition probabilities** — the probability of moving from tag $t_i$ to tag $t_j$:\n",
    "\n",
    "$$a_{ij} = P(t_n = j \\mid t_{n-1} = i)$$\n",
    "\n",
    "**3. Emission probabilities** — the probability of observing word $w$ in state (tag) $t$:\n",
    "\n",
    "$$b_t(w) = P(w \\mid t)$$\n",
    "\n",
    "**4. Initial state distribution** $\\pi_i = P(t_1 = i)$\n",
    "\n",
    "## The Tagging Problem\n",
    "\n",
    "Given a word sequence $W$, find the most likely tag sequence $\\hat{T}$:\n",
    "\n",
    "$$\\hat{T} = \\arg\\max_{T} P(T \\mid W)$$\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "$$P(T \\mid W) \\propto P(W \\mid T) \\cdot P(T)$$\n",
    "\n",
    "With the Markov and independence assumptions, this becomes:\n",
    "\n",
    "$$P(T \\mid W) \\propto \\prod_{i=1}^{n} \\underbrace{P(w_i \\mid t_i)}_{\\text{emission}} \\cdot \\underbrace{P(t_i \\mid t_{i-1})}_{\\text{transition}}$$\n",
    "\n",
    "## The Viterbi Algorithm\n",
    "\n",
    "Finding the optimal tag sequence via brute force is exponential ($K^n$ possible sequences). The **Viterbi algorithm** uses dynamic programming to find the optimal path in $O(n \\cdot K^2)$ time.\n",
    "\n",
    "At each position $i$ and for each tag $t$, it computes:\n",
    "\n",
    "$$V_i(t) = \\max_{t'} \\left[ V_{i-1}(t') \\cdot a_{t',t} \\cdot b_t(w_i) \\right]$$\n",
    "\n",
    "Then backtracks from the end to recover the optimal tag sequence.\n",
    "\n",
    "## Why HMMs Struggle with Unknown Words\n",
    "\n",
    "Since HMMs model $P(w \\mid t)$, if a word $w$ was never seen during training, the emission probability $b_t(w) = 0$ for all tags. This makes the entire sequence probability zero — the model completely fails on out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5319a8164c4d4417f91c06c394ecbd5",
     "grade": false,
     "grade_id": "cell-31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training an HMM Tagger\n",
    "\n",
    "We use the Penn Treebank corpus in NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "038b5ed16f0150091063c0db25b4f3a3",
     "grade": false,
     "grade_id": "cell-32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d2b54a00c6084c73e15d45bfffff34",
     "grade": false,
     "grade_id": "cell-33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tags: 46\n",
      "\n",
      "Top 15 tags:\n",
      "  NN     : 13166\n",
      "  IN     : 9857\n",
      "  NNP    : 9410\n",
      "  DT     : 8165\n",
      "  -NONE- : 6592\n",
      "  NNS    : 6047\n",
      "  JJ     : 5834\n",
      "  ,      : 4886\n",
      "  .      : 3874\n",
      "  CD     : 3546\n",
      "  VBD    : 3043\n",
      "  RB     : 2822\n",
      "  VB     : 2554\n",
      "  CC     : 2265\n",
      "  TO     : 2179\n"
     ]
    }
   ],
   "source": [
    "# Inspect the tag distribution\n",
    "fd = FreqDist()\n",
    "for word, tag in treebank.tagged_words():\n",
    "    fd[tag] += 1\n",
    "\n",
    "print(f\"Total unique tags: {len(fd)}\")\n",
    "print(f\"\\nTop 15 tags:\")\n",
    "for tag, count in fd.most_common(15):\n",
    "    print(f\"  {tag:6s} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3521d47e9a4bafd784fcf3a708179d72",
     "grade": false,
     "grade_id": "cell-34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tagged sentences used for training: 3914\n"
     ]
    }
   ],
   "source": [
    "# Train HMM tagger (supervised / MLE)\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(treebank.tagged_sents())\n",
    "\n",
    "print(f\"Total tagged sentences used for training: {len(treebank.tagged_sents())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "277a4f8f0a003cf8cc4cf0b16271425b",
     "grade": false,
     "grade_id": "cell-35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: [('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.'), ('Yesterday', 'NN'), ('was', 'VBD'), ('also', 'RB'), ('a', 'DT'), ('great', 'JJ'), ('day', 'NN')]\n",
      "\n",
      "Log probability: -112.3188\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "# Test on a normal sentence\n",
    "result = tagger.tag(word_tokenize(\"Today is a good day. Yesterday was also a great day\"))\n",
    "print(\"Tags:\", result)\n",
    "print(f\"\\nLog probability: {tagger.log_probability(result):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7274227e9c2718832c6477c28c1fa7de",
     "grade": false,
     "grade_id": "cell-36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: [('Jan', 'NNP'), ('Scholtes', 'NNP'), ('is', 'NNP'), ('a', 'NNP'), ('name', 'NNP'), ('that', 'NNP'), ('does', 'NNP'), ('not', 'NNP'), ('occur', 'NNP'), ('in', 'NNP'), ('the', 'NNP'), ('corpus', 'NNP'), ('.', 'NNP'), ('What', 'NNP'), ('do', 'NNP'), ('you', 'NNP'), ('observe', 'NNP'), ('?', 'NNP')]\n",
      "\n",
      "Log probability: -17000000000000006245841794858494170301000959218480722106106245937520694386590132865754679153823358451348907731321888052283428539695830301422468351103034566755412674384372441482238139585366943724680347608466356331927483840127623836805164441387630739773403584665110065171610346015945424742268065542045696.0000\n"
     ]
    }
   ],
   "source": [
    "# Test on a sentence with out-of-vocabulary words\n",
    "result_oov = tagger.tag(word_tokenize(\n",
    "    \"Jan Scholtes is a name that does not occur in the corpus. What do you observe?\"\n",
    "))\n",
    "print(\"Tags:\", result_oov)\n",
    "print(f\"\\nLog probability: {tagger.log_probability(result_oov):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c8539011905ee202f5c59673af6f4a8",
     "grade": false,
     "grade_id": "cell-37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how the HMM assigns a very low (or $-\\infty$) probability to sentences containing unknown words like \"Jan\" and \"Scholtes\". The emission probability for unseen words is essentially zero, which causes the entire sequence probability to collapse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb4c359f4fc2613e1cd34675487272b6",
     "grade": false,
     "grade_id": "cell-38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 10. Discriminative POS Tagging — Conditional Random Fields (CRFs)\n",
    "\n",
    "## From Generative to Discriminative\n",
    "\n",
    "HMMs are **generative** models — they model the joint probability $P(W, T)$ and need to estimate $P(w \\mid t)$ for every word-tag pair. This is their Achilles' heel for unknown words.\n",
    "\n",
    "**Conditional Random Fields (CRFs)** are **discriminative** models — they directly model $P(T \\mid W)$ without ever needing to model how words are generated. This fundamental difference allows CRFs to use arbitrary **feature functions** that can look at the spelling, capitalization, suffixes, and context of words.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "A linear-chain CRF defines:\n",
    "\n",
    "$$P(T \\mid W) = \\frac{1}{Z(W)} \\exp\\left(\\sum_{i=1}^{n} \\sum_{k} \\lambda_k \\cdot f_k(t_{i-1}, t_i, W, i)\\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $f_k(t_{i-1}, t_i, W, i)$ are **feature functions** that can examine the entire input $W$, the current position $i$, and the current and previous tags\n",
    "- $\\lambda_k$ are learned **weights** for each feature function\n",
    "- $Z(W) = \\sum_{T'} \\exp\\left(\\sum_{i} \\sum_{k} \\lambda_k \\cdot f_k(t'_{i-1}, t'_i, W, i)\\right)$ is the **partition function** (normalisation constant)\n",
    "\n",
    "## Feature Functions — The Key Advantage\n",
    "\n",
    "Feature functions can capture rich patterns. Examples:\n",
    "\n",
    "| Feature function | Fires when... | Helps with... |\n",
    "|---|---|---|\n",
    "| $f(t_i, w_i)$: word is capitalised and $t_i$ = NNP | Current word starts with uppercase | Proper noun detection |\n",
    "| $f(t_i, w_i)$: word ends in \"-ing\" and $t_i$ = VBG | Word has gerund suffix | Verb form recognition |\n",
    "| $f(t_i, w_i)$: word ends in \"-tion\" and $t_i$ = NN | Word has nominal suffix | Noun detection |\n",
    "| $f(t_{i-1}, t_i)$: previous tag is DT, current is NN | Determiner → Noun pattern | Syntactic context |\n",
    "| $f(t_i, w_i)$: word contains digits and $t_i$ = CD | Word looks like a number | Cardinal number detection |\n",
    "\n",
    "These features allow CRFs to handle **unknown words** — even if \"Scholtes\" was never seen in training, the capitalisation feature fires, suggesting NNP (proper noun).\n",
    "\n",
    "## HMM vs CRF — Comparison\n",
    "\n",
    "| Aspect | HMM | CRF |\n",
    "|--------|-----|-----|\n",
    "| Model type | Generative: $P(W, T)$ | Discriminative: $P(T \\mid W)$ |\n",
    "| Unknown words | Fails (zero emission probability) | Handles via features (capitalisation, suffixes) |\n",
    "| Features | Only word identity | Arbitrary: spelling, context, suffixes, prefixes |\n",
    "| Training | Fast (counting) | Slower (iterative optimisation) |\n",
    "| Independence | $w_i$ depends only on $t_i$ | Can look at entire input $W$ |\n",
    "| Optimal when | Large training data, closed vocabulary | Open vocabulary, rich features needed |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "330ba913ce6ab327ead0caec487e1d0c",
     "grade": false,
     "grade_id": "cell-39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training a CRF Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "058134a58d6f30cd00922d663d83195c",
     "grade": false,
     "grade_id": "cell-40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tagged sentences: 3914\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "from nltk.tag import CRFTagger\n",
    "\n",
    "train_data = treebank.tagged_sents()\n",
    "print(f\"Total tagged sentences: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d2d497a8d397945a0cf597cdb46c891",
     "grade": false,
     "grade_id": "cell-41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 20293\n",
      "Seconds required: 0.039\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.000000\n",
      "c2: 1.000000\n",
      "num_memories: 6\n",
      "max_iterations: 2147483647\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 278543.668877\n",
      "Feature norm: 5.000000\n",
      "Error norm: 19458.187955\n",
      "Active features: 20293\n",
      "Line search trials: 2\n",
      "Line search step: 0.000222\n",
      "Seconds required for this iteration: 0.638\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 270748.081843\n",
      "Feature norm: 50.163828\n",
      "Error norm: 20173.052395\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 184046.413165\n",
      "Feature norm: 56.916053\n",
      "Error norm: 12282.207537\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 121974.789922\n",
      "Feature norm: 52.626404\n",
      "Error norm: 7366.040475\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 80924.899225\n",
      "Feature norm: 43.923740\n",
      "Error norm: 7054.161960\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.210\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 65533.045236\n",
      "Feature norm: 44.149667\n",
      "Error norm: 4000.779880\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.209\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 56830.881794\n",
      "Feature norm: 44.438222\n",
      "Error norm: 2569.956674\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 49788.319203\n",
      "Feature norm: 45.499932\n",
      "Error norm: 2348.054986\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 44815.903375\n",
      "Feature norm: 47.281028\n",
      "Error norm: 1833.184156\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 41017.114274\n",
      "Feature norm: 50.760750\n",
      "Error norm: 2133.832717\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 38060.044688\n",
      "Feature norm: 53.655410\n",
      "Error norm: 1578.454287\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.208\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 35512.435497\n",
      "Feature norm: 56.753218\n",
      "Error norm: 1134.117062\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.209\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 32737.326215\n",
      "Feature norm: 63.591057\n",
      "Error norm: 1653.593506\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 31524.144927\n",
      "Feature norm: 70.132548\n",
      "Error norm: 1644.128023\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 30549.305103\n",
      "Feature norm: 69.209860\n",
      "Error norm: 765.616182\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 29906.015182\n",
      "Feature norm: 69.343353\n",
      "Error norm: 671.496101\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 29145.844507\n",
      "Feature norm: 70.723720\n",
      "Error norm: 760.260174\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.209\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 28069.276122\n",
      "Feature norm: 74.528359\n",
      "Error norm: 941.657267\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 27493.663443\n",
      "Feature norm: 77.288806\n",
      "Error norm: 797.443907\n",
      "Active features: 20293\n",
      "Line search trials: 2\n",
      "Line search step: 0.495533\n",
      "Seconds required for this iteration: 0.426\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 27040.865758\n",
      "Feature norm: 79.047981\n",
      "Error norm: 473.088078\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 26552.263144\n",
      "Feature norm: 80.982272\n",
      "Error norm: 465.276981\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.220\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 26129.494367\n",
      "Feature norm: 82.864044\n",
      "Error norm: 466.247443\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 26034.393616\n",
      "Feature norm: 86.207669\n",
      "Error norm: 1322.430352\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 25362.251355\n",
      "Feature norm: 86.730072\n",
      "Error norm: 407.233295\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 25166.767496\n",
      "Feature norm: 86.408687\n",
      "Error norm: 306.732775\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 24938.286252\n",
      "Feature norm: 86.366212\n",
      "Error norm: 371.722380\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 24642.491014\n",
      "Feature norm: 87.076844\n",
      "Error norm: 462.945611\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 24467.254355\n",
      "Feature norm: 88.383163\n",
      "Error norm: 565.644187\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 24259.974523\n",
      "Feature norm: 88.349379\n",
      "Error norm: 260.012605\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 24130.111041\n",
      "Feature norm: 88.397335\n",
      "Error norm: 259.796553\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 23970.137811\n",
      "Feature norm: 88.676153\n",
      "Error norm: 319.322653\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 23939.767469\n",
      "Feature norm: 89.236824\n",
      "Error norm: 754.536554\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 23740.276438\n",
      "Feature norm: 89.268881\n",
      "Error norm: 230.484596\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 23679.084206\n",
      "Feature norm: 89.306500\n",
      "Error norm: 184.918945\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 23582.229220\n",
      "Feature norm: 89.463719\n",
      "Error norm: 244.252660\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 23466.563278\n",
      "Feature norm: 89.768593\n",
      "Error norm: 286.263484\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.225\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 23423.159881\n",
      "Feature norm: 90.379994\n",
      "Error norm: 453.209865\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 23325.380584\n",
      "Feature norm: 90.203299\n",
      "Error norm: 159.285505\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 23284.193755\n",
      "Feature norm: 90.142379\n",
      "Error norm: 167.088593\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 23221.927023\n",
      "Feature norm: 90.208946\n",
      "Error norm: 184.723996\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 23160.275606\n",
      "Feature norm: 90.411779\n",
      "Error norm: 328.856644\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 23101.042361\n",
      "Feature norm: 90.635961\n",
      "Error norm: 182.890921\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 23072.283582\n",
      "Feature norm: 90.686541\n",
      "Error norm: 123.467108\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.234\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 23028.867247\n",
      "Feature norm: 90.806624\n",
      "Error norm: 113.968146\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 23007.778962\n",
      "Feature norm: 90.931843\n",
      "Error norm: 194.887425\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 22982.951357\n",
      "Feature norm: 90.966022\n",
      "Error norm: 110.710534\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 22959.508376\n",
      "Feature norm: 90.978326\n",
      "Error norm: 95.650620\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.220\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 22939.055941\n",
      "Feature norm: 90.988954\n",
      "Error norm: 100.571543\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 22922.883634\n",
      "Feature norm: 91.027632\n",
      "Error norm: 193.219030\n",
      "Active features: 20293\n",
      "Line search trials: 2\n",
      "Line search step: 0.421534\n",
      "Seconds required for this iteration: 0.431\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 22898.328262\n",
      "Feature norm: 91.048908\n",
      "Error norm: 96.453952\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #51 *****\n",
      "Loss: 22886.187024\n",
      "Feature norm: 91.048547\n",
      "Error norm: 65.819545\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #52 *****\n",
      "Loss: 22873.669781\n",
      "Feature norm: 91.041699\n",
      "Error norm: 98.351250\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #53 *****\n",
      "Loss: 22864.847224\n",
      "Feature norm: 91.031979\n",
      "Error norm: 99.694897\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #54 *****\n",
      "Loss: 22856.871811\n",
      "Feature norm: 91.022239\n",
      "Error norm: 71.325809\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #55 *****\n",
      "Loss: 22845.342323\n",
      "Feature norm: 90.990844\n",
      "Error norm: 72.214969\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #56 *****\n",
      "Loss: 22840.104520\n",
      "Feature norm: 90.979411\n",
      "Error norm: 105.378313\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.223\n",
      "\n",
      "***** Iteration #57 *****\n",
      "Loss: 22834.884375\n",
      "Feature norm: 90.976228\n",
      "Error norm: 62.418089\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #58 *****\n",
      "Loss: 22828.721322\n",
      "Feature norm: 90.970366\n",
      "Error norm: 44.065555\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #59 *****\n",
      "Loss: 22825.509346\n",
      "Feature norm: 90.969075\n",
      "Error norm: 46.715120\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #60 *****\n",
      "Loss: 22821.087237\n",
      "Feature norm: 90.973367\n",
      "Error norm: 132.256319\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #61 *****\n",
      "Loss: 22814.549650\n",
      "Feature norm: 90.980601\n",
      "Error norm: 47.871386\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #62 *****\n",
      "Loss: 22812.757784\n",
      "Feature norm: 90.982005\n",
      "Error norm: 30.820728\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #63 *****\n",
      "Loss: 22810.214143\n",
      "Feature norm: 90.989359\n",
      "Error norm: 32.676068\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.211\n",
      "\n",
      "***** Iteration #64 *****\n",
      "Loss: 22808.263945\n",
      "Feature norm: 91.004157\n",
      "Error norm: 60.858189\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.210\n",
      "\n",
      "***** Iteration #65 *****\n",
      "Loss: 22805.975613\n",
      "Feature norm: 91.015718\n",
      "Error norm: 35.710055\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.210\n",
      "\n",
      "***** Iteration #66 *****\n",
      "Loss: 22803.763105\n",
      "Feature norm: 91.032509\n",
      "Error norm: 26.721072\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #67 *****\n",
      "Loss: 22802.091847\n",
      "Feature norm: 91.050217\n",
      "Error norm: 26.987577\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #68 *****\n",
      "Loss: 22801.034534\n",
      "Feature norm: 91.088178\n",
      "Error norm: 72.289273\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #69 *****\n",
      "Loss: 22798.873894\n",
      "Feature norm: 91.097716\n",
      "Error norm: 28.007899\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #70 *****\n",
      "Loss: 22797.930111\n",
      "Feature norm: 91.103457\n",
      "Error norm: 20.340522\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #71 *****\n",
      "Loss: 22796.843837\n",
      "Feature norm: 91.120189\n",
      "Error norm: 24.622888\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.224\n",
      "\n",
      "***** Iteration #72 *****\n",
      "Loss: 22796.064330\n",
      "Feature norm: 91.152266\n",
      "Error norm: 47.343679\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.222\n",
      "\n",
      "***** Iteration #73 *****\n",
      "Loss: 22795.042170\n",
      "Feature norm: 91.166147\n",
      "Error norm: 20.456141\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #74 *****\n",
      "Loss: 22794.405273\n",
      "Feature norm: 91.178715\n",
      "Error norm: 15.387127\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #75 *****\n",
      "Loss: 22793.807614\n",
      "Feature norm: 91.196556\n",
      "Error norm: 19.246604\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #76 *****\n",
      "Loss: 22793.016425\n",
      "Feature norm: 91.236990\n",
      "Error norm: 35.385702\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.213\n",
      "\n",
      "***** Iteration #77 *****\n",
      "Loss: 22792.190311\n",
      "Feature norm: 91.269837\n",
      "Error norm: 19.507550\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #78 *****\n",
      "Loss: 22791.724300\n",
      "Feature norm: 91.279484\n",
      "Error norm: 13.808737\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #79 *****\n",
      "Loss: 22791.127840\n",
      "Feature norm: 91.303909\n",
      "Error norm: 16.121540\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #80 *****\n",
      "Loss: 22791.001302\n",
      "Feature norm: 91.336579\n",
      "Error norm: 33.186455\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #81 *****\n",
      "Loss: 22790.596018\n",
      "Feature norm: 91.339903\n",
      "Error norm: 13.742303\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #82 *****\n",
      "Loss: 22790.357477\n",
      "Feature norm: 91.351847\n",
      "Error norm: 10.323798\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #83 *****\n",
      "Loss: 22790.113320\n",
      "Feature norm: 91.375556\n",
      "Error norm: 12.226693\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #84 *****\n",
      "Loss: 22789.764503\n",
      "Feature norm: 91.419499\n",
      "Error norm: 17.138150\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #85 *****\n",
      "Loss: 22789.600034\n",
      "Feature norm: 91.482020\n",
      "Error norm: 22.425602\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #86 *****\n",
      "Loss: 22789.346104\n",
      "Feature norm: 91.472921\n",
      "Error norm: 8.582369\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #87 *****\n",
      "Loss: 22789.227699\n",
      "Feature norm: 91.473770\n",
      "Error norm: 8.318100\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #88 *****\n",
      "Loss: 22789.038959\n",
      "Feature norm: 91.490672\n",
      "Error norm: 10.534776\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #89 *****\n",
      "Loss: 22788.821735\n",
      "Feature norm: 91.530098\n",
      "Error norm: 13.920220\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.220\n",
      "\n",
      "***** Iteration #90 *****\n",
      "Loss: 22788.694774\n",
      "Feature norm: 91.581905\n",
      "Error norm: 13.119315\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #91 *****\n",
      "Loss: 22788.587232\n",
      "Feature norm: 91.578471\n",
      "Error norm: 5.905558\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #92 *****\n",
      "Loss: 22788.520773\n",
      "Feature norm: 91.582080\n",
      "Error norm: 5.831333\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #93 *****\n",
      "Loss: 22788.447577\n",
      "Feature norm: 91.595862\n",
      "Error norm: 6.959206\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #94 *****\n",
      "Loss: 22788.390662\n",
      "Feature norm: 91.623661\n",
      "Error norm: 15.412357\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #95 *****\n",
      "Loss: 22788.283952\n",
      "Feature norm: 91.636264\n",
      "Error norm: 5.775075\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #96 *****\n",
      "Loss: 22788.239298\n",
      "Feature norm: 91.642938\n",
      "Error norm: 4.437296\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.214\n",
      "\n",
      "***** Iteration #97 *****\n",
      "Loss: 22788.187174\n",
      "Feature norm: 91.654625\n",
      "Error norm: 4.800172\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #98 *****\n",
      "Loss: 22788.161924\n",
      "Feature norm: 91.673494\n",
      "Error norm: 12.795901\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.219\n",
      "\n",
      "***** Iteration #99 *****\n",
      "Loss: 22788.100454\n",
      "Feature norm: 91.675853\n",
      "Error norm: 4.321814\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.224\n",
      "\n",
      "***** Iteration #100 *****\n",
      "Loss: 22788.077693\n",
      "Feature norm: 91.677127\n",
      "Error norm: 2.969945\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #101 *****\n",
      "Loss: 22788.056193\n",
      "Feature norm: 91.680387\n",
      "Error norm: 3.643487\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.217\n",
      "\n",
      "***** Iteration #102 *****\n",
      "Loss: 22788.025204\n",
      "Feature norm: 91.686527\n",
      "Error norm: 5.169387\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.212\n",
      "\n",
      "***** Iteration #103 *****\n",
      "Loss: 22788.004811\n",
      "Feature norm: 91.696267\n",
      "Error norm: 6.061971\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.223\n",
      "\n",
      "***** Iteration #104 *****\n",
      "Loss: 22787.983258\n",
      "Feature norm: 91.695918\n",
      "Error norm: 2.576651\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.237\n",
      "\n",
      "***** Iteration #105 *****\n",
      "Loss: 22787.971386\n",
      "Feature norm: 91.696443\n",
      "Error norm: 2.663963\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.215\n",
      "\n",
      "***** Iteration #106 *****\n",
      "Loss: 22787.957588\n",
      "Feature norm: 91.698730\n",
      "Error norm: 2.792625\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.218\n",
      "\n",
      "***** Iteration #107 *****\n",
      "Loss: 22787.942614\n",
      "Feature norm: 91.704136\n",
      "Error norm: 6.061318\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "***** Iteration #108 *****\n",
      "Loss: 22787.925483\n",
      "Feature norm: 91.707470\n",
      "Error norm: 2.225291\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.220\n",
      "\n",
      "***** Iteration #109 *****\n",
      "Loss: 22787.919119\n",
      "Feature norm: 91.707700\n",
      "Error norm: 1.680101\n",
      "Active features: 20293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.216\n",
      "\n",
      "L-BFGS terminated with the stopping criteria\n",
      "Total seconds required for training: 24.377\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 20293 (20293)\n",
      "Number of active attributes: 15011 (15011)\n",
      "Number of active labels: 46 (46)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the CRF tagger (this may take a few minutes)\n",
    "taggerCRF = CRFTagger(verbose=True)\n",
    "taggerCRF.train(train_data, 'model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33911a85e7f1445ab56451bfaa7837a8",
     "grade": false,
     "grade_id": "cell-42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal sentence:\n",
      "[('Today', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.'), ('Yesterday', 'NNP'), ('was', 'VBD'), ('also', 'RB'), ('a', 'DT'), ('great', 'JJ'), ('day', 'NN')]\n",
      "\n",
      "Sentence with unknown words:\n",
      "[('Jan', 'NNP'), ('Scholtes', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('name', 'NN'), ('that', 'WDT'), ('does', 'VBZ'), ('not', 'RB'), ('occur', 'VB'), ('in', 'IN'), ('the', 'DT'), ('corpus', 'NN'), ('.', '.'), ('What', 'WP'), ('do', 'VBP'), ('you', 'PRP'), ('observe', 'VBP'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Test on the same sentences as the HMM\n",
    "print(\"Normal sentence:\")\n",
    "print(taggerCRF.tag(word_tokenize(\"Today is a good day. Yesterday was also a great day\")))\n",
    "\n",
    "print(\"\\nSentence with unknown words:\")\n",
    "print(taggerCRF.tag(word_tokenize(\n",
    "    \"Jan Scholtes is a name that does not occur in the corpus. What do you observe?\"\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26b90808cb11a52c7281052c53e97348",
     "grade": false,
     "grade_id": "cell-43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how the CRF correctly tags \"Jan\" and \"Scholtes\" as NNP (proper nouns), even though they never appeared in the training data. The capitalisation and context features allow the model to generalise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1ce2a86e2ce280dfcb2aeec43dab85f",
     "grade": false,
     "grade_id": "cell-44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Inspecting CRF Feature Functions\n",
    "\n",
    "We can look at what features the CRF extracts for each word position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bcdf13169232ce499b496a7abd97134",
     "grade": false,
     "grade_id": "cell-45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token 'Jan' — Features:\n",
      "  CAPITALIZATION\n",
      "  SUF_n\n",
      "  SUF_an\n",
      "  WORD_Jan\n",
      "\n",
      "Token 'Scholtes' — Features:\n",
      "  CAPITALIZATION\n",
      "  SUF_s\n",
      "  SUF_es\n",
      "  SUF_tes\n",
      "  WORD_Scholtes\n",
      "\n",
      "Token 'works' — Features:\n",
      "  SUF_s\n",
      "  SUF_ks\n",
      "  SUF_rks\n",
      "  WORD_works\n",
      "\n",
      "Token 'at' — Features:\n",
      "  SUF_t\n",
      "  WORD_at\n",
      "\n",
      "Token 'Maastricht' — Features:\n",
      "  CAPITALIZATION\n",
      "  SUF_t\n",
      "  SUF_ht\n",
      "  SUF_cht\n",
      "  WORD_Maastricht\n",
      "\n",
      "Token 'University' — Features:\n",
      "  CAPITALIZATION\n",
      "  SUF_y\n",
      "  SUF_ty\n",
      "  SUF_ity\n",
      "  WORD_University\n"
     ]
    }
   ],
   "source": [
    "# Show features for a sample sentence\n",
    "sample_tokens = word_tokenize(\"Jan Scholtes works at Maastricht University\")\n",
    "for i, token in enumerate(sample_tokens):\n",
    "    features = taggerCRF._get_features(sample_tokens, i)\n",
    "    print(f\"\\nToken '{token}' — Features:\")\n",
    "    for f in features:\n",
    "        print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dbab105fb96a868cccaf16afc1d9be6",
     "grade": false,
     "grade_id": "cell-46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 11. Dependency Parsing\n",
    "\n",
    "## From Phrase Structure to Dependencies\n",
    "\n",
    "So far we have detected **phrases** (NPs, VPs) using chunking grammars. But these flat chunks don't tell us *how* words relate to each other across the sentence.\n",
    "\n",
    "**Dependency parsing** identifies binary **head-dependent** relationships between words. Each word in a sentence depends on exactly one other word (its *head*), except the *root* of the sentence.\n",
    "\n",
    "A dependency relation is a triple: **(head, relation, dependent)**\n",
    "\n",
    "For example, in \"The cat sat on the mat\":\n",
    "- (sat, **nsubj**, cat) — \"cat\" is the nominal subject of \"sat\"\n",
    "- (cat, **det**, The) — \"The\" is the determiner of \"cat\"\n",
    "- (sat, **obl**, mat) — \"mat\" is an oblique dependent of \"sat\"\n",
    "- (mat, **case**, on) — \"on\" marks the case of \"mat\"\n",
    "- (mat, **det**, the) — \"the\" determines \"mat\"\n",
    "\n",
    "## Universal Dependencies\n",
    "\n",
    "The [Universal Dependencies](https://universaldependencies.org/) (UD) project defines a cross-lingual annotation scheme with ~37 universal dependency relations, including:\n",
    "\n",
    "| Relation | Meaning | Example |\n",
    "|----------|---------|---------|\n",
    "| nsubj | Nominal subject | *John* runs |\n",
    "| obj | Direct object | reads *books* |\n",
    "| det | Determiner | *the* dog |\n",
    "| amod | Adjectival modifier | *big* house |\n",
    "| nmod | Nominal modifier | house *of cards* |\n",
    "| neg / advmod | Negation | does *not* run |\n",
    "| conj | Conjunction | cats *and* dogs |\n",
    "\n",
    "Dependency parsing is essential for:\n",
    "- **Relation extraction** (who did what to whom)\n",
    "- **Co-reference resolution** (linking pronouns to their antecedents)\n",
    "- **Negation scope detection** (what is being negated)\n",
    "- **Knowledge Graph construction** (Part 2 of this tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "616a0266ffc029846e711face9753e58",
     "grade": false,
     "grade_id": "cell-47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dependency Parsing in NLTK\n",
    "\n",
    "NLTK can parse dependency structures from annotated data in CoNLL format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18b905a9949491f086b871e7b27bd60a",
     "grade": false,
     "grade_id": "cell-48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency tree:\n",
      "(will\n",
      "  (Vinken Pierre , (old (years 61)) ,)\n",
      "  (join (board the) (as (director a nonexecutive)) (Nov. 29) .))\n",
      "\n",
      "Dependency triples:\n",
      "  (will, SUB, Vinken)\n",
      "  (Vinken, NMOD, Pierre)\n",
      "  (Vinken, P, ,)\n",
      "  (Vinken, NMOD, old)\n",
      "  (old, AMOD, years)\n",
      "  (years, NMOD, 61)\n",
      "  (Vinken, P, ,)\n",
      "  (will, VC, join)\n",
      "  (join, OBJ, board)\n",
      "  (board, NMOD, the)\n",
      "  (join, VMOD, as)\n",
      "  (as, PMOD, director)\n",
      "  (director, NMOD, a)\n",
      "  (director, NMOD, nonexecutive)\n",
      "  (join, VMOD, Nov.)\n",
      "  (Nov., NMOD, 29)\n",
      "  (join, VMOD, .)\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import DependencyGraph\n",
    "\n",
    "treebank_data = \"\"\"Pierre  NNP     2       NMOD\n",
    "Vinken  NNP     8       SUB\n",
    ",       ,       2       P\n",
    "61      CD      5       NMOD\n",
    "years   NNS     6       AMOD\n",
    "old     JJ      2       NMOD\n",
    ",       ,       2       P\n",
    "will    MD      0       ROOT\n",
    "join    VB      8       VC\n",
    "the     DT      11      NMOD\n",
    "board   NN      9       OBJ\n",
    "as      IN      9       VMOD\n",
    "a       DT      15      NMOD\n",
    "nonexecutive    JJ      15      NMOD\n",
    "director        NN      12      PMOD\n",
    "Nov.    NNP     9       VMOD\n",
    "29      CD      16      NMOD\n",
    ".       .       9       VMOD\n",
    "\"\"\"\n",
    "\n",
    "dg = DependencyGraph(treebank_data)\n",
    "\n",
    "# Print the dependency tree\n",
    "print(\"Dependency tree:\")\n",
    "dg.tree().pprint()\n",
    "\n",
    "# Print the triples (head, relation, dependent)\n",
    "print(\"\\nDependency triples:\")\n",
    "for head, rel, dep in dg.triples():\n",
    "    print(f\"  ({head[0]}, {rel}, {dep[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba02b07af3d14bf71e4e0673342c5158",
     "grade": false,
     "grade_id": "cell-49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Tree:\n",
      "                        will                                      \n",
      "          _______________|__________                               \n",
      "       Vinken                      join                           \n",
      "   ______|__________      __________|__________________________    \n",
      "  |      |     |   old   |     |           as                  |  \n",
      "  |      |     |    |    |     |           |                   |   \n",
      "  |      |     |  years  |   board      director              Nov.\n",
      "  |      |     |    |    |     |     ______|__________         |   \n",
      "Pierre   ,     ,    61   .    the   a            nonexecutive  29 \n",
      "\n",
      "\n",
      "Dependency Triples:\n",
      "  will            --SUB   --> Vinken\n",
      "  Vinken          --NMOD  --> Pierre\n",
      "  Vinken          --P     --> ,\n",
      "  Vinken          --NMOD  --> old\n",
      "  old             --AMOD  --> years\n",
      "  years           --NMOD  --> 61\n",
      "  Vinken          --P     --> ,\n",
      "  will            --VC    --> join\n",
      "  join            --OBJ   --> board\n",
      "  board           --NMOD  --> the\n",
      "  join            --VMOD  --> as\n",
      "  as              --PMOD  --> director\n",
      "  director        --NMOD  --> a\n",
      "  director        --NMOD  --> nonexecutive\n",
      "  join            --VMOD  --> Nov.\n",
      "  Nov.            --NMOD  --> 29\n",
      "  join            --VMOD  --> .\n"
     ]
    }
   ],
   "source": [
    "# Parse the CoNLL-format dependency data\n",
    "dg = DependencyGraph(treebank_data)\n",
    "\n",
    "# Print the dependency tree\n",
    "print(\"Dependency Tree:\")\n",
    "dg.tree().pretty_print()\n",
    "\n",
    "# Print all dependency triples (head, relation, dependent)\n",
    "print(\"\\nDependency Triples:\")\n",
    "for triple in dg.triples():\n",
    "    print(f\"  {triple[0][0]:15s} --{triple[1]:6s}--> {triple[2][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3dd0fcc1ce9602aa67c799c48e00f47d",
     "grade": false,
     "grade_id": "cell-50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 12. Co-reference and Pronoun Resolution\n",
    "\n",
    "## What is Co-reference?\n",
    "\n",
    "**Co-reference resolution** is the task of determining which expressions in a text refer to the same real-world entity.\n",
    "\n",
    "Consider:\n",
    "\n",
    "> *\"**Barack Obama** was born in Hawaii. **He** graduated from Harvard Law School. **The former president** later moved to Chicago.\"*\n",
    "\n",
    "Here, \"Barack Obama\", \"He\", and \"The former president\" all refer to the **same entity**. A co-reference system groups them into a **mention cluster**.\n",
    "\n",
    "## Types of Referring Expressions\n",
    "\n",
    "| Type | Example | Challenge |\n",
    "|------|---------|----------|\n",
    "| **Pronouns** | he, she, it, they | Require antecedent identification |\n",
    "| **Definite NPs** | the president, the company | Require world knowledge |\n",
    "| **Proper nouns** | Obama, Mr. Obama | Aliases are tricky |\n",
    "| **Demonstratives** | this, that, these | Often refer to events |\n",
    "\n",
    "## How Dependency Grammar Helps\n",
    "\n",
    "Dependency parsing provides structural clues for pronoun resolution:\n",
    "\n",
    "1. **Subject preference** — pronouns tend to refer to the **subject** of the previous clause (`nsubj`)\n",
    "2. **Syntactic constraints** — Binding Theory: a pronoun cannot co-refer with a noun it c-commands in the same clause\n",
    "3. **Parallelism** — in coordinated clauses, pronouns map to the same grammatical role\n",
    "\n",
    "Below we build a simple co-reference pipeline step by step, using only the libraries you already know from this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae8665f3015b95607b2388ef65ca8a22",
     "grade": false,
     "grade_id": "cell-51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1 — Finding Pronouns and Candidate Antecedents\n",
    "\n",
    "We use **POS tagging** (Section 6) to locate pronouns (`PRP`, `PRP$`) and **NP chunking** (Section 8) to find candidate antecedent noun phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168b4f1ff6da2fb1a74b93790fed275e",
     "grade": false,
     "grade_id": "cell-52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type       Sent  Text\n",
      "--------------------------------------------------\n",
      "NP         0     Barack Obama\n",
      "NP         0     Hawaii\n",
      "NP         1     Harvard Law School\n",
      "pronoun    1     He\n",
      "NP         2     The former president\n",
      "NP         2     Chicago\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, RegexpParser\n",
    "\n",
    "# --- sample multi-sentence text ---\n",
    "text = (\"Barack Obama was born in Hawaii. \"\n",
    "        \"He graduated from Harvard Law School. \"\n",
    "        \"The former president later moved to Chicago.\")\n",
    "\n",
    "# Split into sentences (re-use the tokenizer from Section 3)\n",
    "sents = tokenizer.tokenize(text)\n",
    "\n",
    "# NP chunker (same grammar as Section 8)\n",
    "np_grammar = 'NP: {<DT>?<JJ>*<NN.*>+}'\n",
    "np_chunker = RegexpParser(np_grammar)\n",
    "\n",
    "# --- collect mentions across all sentences ---\n",
    "mentions = []  # list of dicts\n",
    "\n",
    "for sent_idx, sent in enumerate(sents):\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    tree   = np_chunker.parse(tagged)\n",
    "\n",
    "    # 1) Noun-phrase chunks  →  candidate antecedents\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        np_text = ' '.join(w for w, t in subtree.leaves())\n",
    "        mentions.append({\n",
    "            'sentence': sent_idx, 'text': np_text,\n",
    "            'type': 'NP', 'tags': [t for _, t in subtree.leaves()]\n",
    "        })\n",
    "\n",
    "    # 2) Pronouns\n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        if tag in ('PRP', 'PRP$'):\n",
    "            mentions.append({\n",
    "                'sentence': sent_idx, 'text': word,\n",
    "                'type': 'pronoun', 'tags': [tag]\n",
    "            })\n",
    "\n",
    "# --- display ---\n",
    "print(f\"{'Type':10s} {'Sent':4s}  Text\")\n",
    "print('-' * 50)\n",
    "for m in mentions:\n",
    "    print(f\"{m['type']:10s} {m['sentence']:<4d}  {m['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8814646450024b19219c5beeb55970d7",
     "grade": false,
     "grade_id": "cell-53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how POS tagging and NP chunking — tools you already used in Sections 6 and 8 — let us automatically extract every pronoun **and** every candidate antecedent noun phrase from the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04125f8230bc6bde1b4a45fa475221cc",
     "grade": false,
     "grade_id": "cell-54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2 — A Simple Rule-Based Pronoun Resolver\n",
    "\n",
    "We now link each pronoun to its most likely antecedent using two simple rules:\n",
    "\n",
    "1. **Recency** — prefer the closest preceding NP\n",
    "2. **Proper-noun preference** — prefer NPs that contain a proper noun (`NNP`), because pronouns most often refer to named entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "760c593341f51ef4fa9c597fe4242ccd",
     "grade": false,
     "grade_id": "cell-55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronoun resolutions:\n",
      "  'He' (sent 1)  →  'Harvard Law School' (sent 1)\n"
     ]
    }
   ],
   "source": [
    "def resolve_pronouns(mentions):\n",
    "    \"\"\"Link each pronoun to its best preceding NP antecedent.\"\"\"\n",
    "    antecedents = []   # running list of NPs seen so far\n",
    "    resolutions = []\n",
    "\n",
    "    for m in mentions:\n",
    "        if m['type'] == 'NP':\n",
    "            antecedents.append(m)\n",
    "        elif m['type'] == 'pronoun' and antecedents:\n",
    "            # Score candidates: prefer NPs with proper nouns, then recency\n",
    "            def score(np):\n",
    "                has_nnp = any(t.startswith('NNP') for t in np['tags'])\n",
    "                return (has_nnp, -abs(m['sentence'] - np['sentence']))\n",
    "\n",
    "            best = max(antecedents, key=score)\n",
    "            resolutions.append((m, best))\n",
    "\n",
    "    return resolutions\n",
    "\n",
    "# --- run resolver ---\n",
    "resolutions = resolve_pronouns(mentions)\n",
    "\n",
    "print(\"Pronoun resolutions:\")\n",
    "for pronoun, antecedent in resolutions:\n",
    "    print(f\"  '{pronoun['text']}' (sent {pronoun['sentence']})  \"\n",
    "          f\"→  '{antecedent['text']}' (sent {antecedent['sentence']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "757b78af1bfbea98432908aa53e07cdc",
     "grade": false,
     "grade_id": "cell-56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The resolver correctly links *\"He\"* and *\"The former president\"* back to *\"Barack Obama\"* — using only POS tagging and NP chunking. But what happens when we throw a harder text at it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- A harder text: two named entities + multiple pronouns ---\n",
    "hard_text = (\"Dr. Sarah Chen met Professor James Lee at the annual conference. \"\n",
    "             \"She presented her groundbreaking research on climate change. \"\n",
    "             \"He asked several challenging questions about her methodology. \"\n",
    "             \"Later, she invited him to collaborate on a joint paper.\")\n",
    "\n",
    "# Re-use the same pipeline from Step 1\n",
    "sents_hard = tokenizer.tokenize(hard_text)\n",
    "mentions_hard = []\n",
    "\n",
    "for sent_idx, sent in enumerate(sents_hard):\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    tree   = np_chunker.parse(tagged)\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        np_text = ' '.join(w for w, t in subtree.leaves())\n",
    "        mentions_hard.append({\n",
    "            'sentence': sent_idx, 'text': np_text,\n",
    "            'type': 'NP', 'tags': [t for _, t in subtree.leaves()]\n",
    "        })\n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        if tag in ('PRP', 'PRP$'):\n",
    "            mentions_hard.append({\n",
    "                'sentence': sent_idx, 'text': word,\n",
    "                'type': 'pronoun', 'tags': [tag]\n",
    "            })\n",
    "\n",
    "resolutions_hard = resolve_pronouns(mentions_hard)\n",
    "\n",
    "print(\"Text:\", hard_text)\n",
    "print(\"\\nRule-based pronoun resolutions:\")\n",
    "correct = 0\n",
    "total   = len(resolutions_hard)\n",
    "expected = {\n",
    "    'She': 'Dr. Sarah Chen', 'her': 'Dr. Sarah Chen',\n",
    "    'He': 'Professor James Lee', 'him': 'Professor James Lee',\n",
    "    'she': 'Dr. Sarah Chen'\n",
    "}\n",
    "for pronoun, antecedent in resolutions_hard:\n",
    "    p = pronoun['text']\n",
    "    a = antecedent['text']\n",
    "    # Check correctness (simplified: \"He\"/\"him\" should map to James Lee)\n",
    "    if p.lower() in ('he', 'him'):\n",
    "        is_correct = 'James Lee' in a\n",
    "    else:\n",
    "        is_correct = 'Sarah Chen' in a or 'Dr.' in a\n",
    "    mark = \"correct\" if is_correct else \"WRONG\"\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    print(f\"  '{p}' (sent {pronoun['sentence']})  -->  '{a}'  [{mark}]\")\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{total} — the rule-based resolver has no concept of \"\n",
    "      f\"gender, so 'He' and 'him' are wrongly linked to 'Dr. Sarah Chen'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the Rule-Based Resolver Fails Here\n",
    "\n",
    "Our resolver uses only **recency** and **proper-noun preference**. Since both \"Dr. Sarah Chen\" and \"Professor James Lee\" contain proper nouns (`NNP`), the tie-breaker is recency — and \"Dr. Sarah Chen\" appears first, so it keeps winning. The resolver has:\n",
    "- **No gender model** — it cannot distinguish *\"He\"* (male) from *\"She\"* (female)\n",
    "- **No number model** — it cannot distinguish *\"They\"* (plural) from *\"It\"* (singular)\n",
    "- **No semantic understanding** — it cannot link *\"the former president\"* to *\"Obama\"* based on meaning\n",
    "\n",
    "State-of-the-art systems (e.g., Lee et al. 2017) use neural networks with contextualised embeddings to handle these cases. Let's see how a **BERT-based** coreference model compares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Neural Coreference Resolution with BERT\n",
    "\n",
    "The **F-Coref** model (*Otmazgin et al., 2023*) is a coreference resolution system built on top of a **RoBERTa** encoder (a BERT variant). It was trained on the **OntoNotes 5.0** corpus — the standard benchmark for coreference resolution — and learns to identify which spans of text refer to the same real-world entity.\n",
    "\n",
    "Key advantages over our rule-based approach:\n",
    "- **Semantic understanding** — the model \"knows\" that *\"the former president\"* refers to *\"Barack Obama\"* because of meaning, not just proximity\n",
    "- **Gender and number agreement** — can distinguish *\"She\"* → *\"Mary\"* from *\"he\"* → *\"John\"* using learned representations\n",
    "- **Event coreference** — can link *\"It\"* to *\"The merger\"* when the pronoun refers to an event rather than a person\n",
    "\n",
    "We use the `fastcoref` library, which wraps this model in a simple API. The model outputs **coreference clusters** — groups of text spans that refer to the same entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading F-Coref model on cuda:0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 133/133 [00:00<00:00, 1331.96it/s, Materializing param=start_mention_mlp.layer_norm.weight]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 114.24 examples/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Easy text (same as Step 1–2)\n",
      "============================================================\n",
      "Text: Barack Obama was born in Hawaii. He graduated from Harvard Law School. The former president later moved to Chicago.\n",
      "\n",
      "Coreference clusters found by F-Coref:\n",
      "  Cluster 1: ['Barack Obama', 'He', 'The former president']\n",
      "\n",
      "============================================================\n",
      "Hard cases (broke our rule-based resolver)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 192.54 examples/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 160.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Mary and John arrived at the restaurant. She ordered wine while he looked at the menu.\n",
      "  Cluster 1: ['Mary', 'She']\n",
      "  Cluster 2: ['John', 'he']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 252.35 examples/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 166.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: The company announced a merger with its rival. It was expected to create 500 new jobs.\n",
      "  Cluster 1: ['The company', 'its']\n",
      "  Cluster 2: ['a merger with its rival', 'It']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 246.29 examples/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 166.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: Alice told Bob that she had passed the exam.\n",
      "  Cluster 1: ['Alice', 'she']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings, logging, time, torch\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# --- Fix for transformers 5.x compatibility ---\n",
    "from fastcoref.modeling import FCorefModel\n",
    "if not hasattr(FCorefModel, 'all_tied_weights_keys'):\n",
    "    FCorefModel.all_tied_weights_keys = {}\n",
    "\n",
    "from fastcoref import FCoref\n",
    "\n",
    "# Load F-Coref model (automatically uses GPU if available)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Loading F-Coref model on {device}...\")\n",
    "coref_model = FCoref(device=device)\n",
    "print(\"Model loaded.\\n\")\n",
    "\n",
    "# ── 1. Same text as our rule-based approach ────────────────────────\n",
    "easy_text = (\"Barack Obama was born in Hawaii. \"\n",
    "             \"He graduated from Harvard Law School. \"\n",
    "             \"The former president later moved to Chicago.\")\n",
    "\n",
    "preds = coref_model.predict(texts=[easy_text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Easy text (same as Steps 1-2)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Text: {easy_text}\\n\")\n",
    "print(\"Coreference clusters found by F-Coref:\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"  Cluster {i+1}: {cluster}\")\n",
    "\n",
    "# ── 2. Same HARD text from Step 2b (rule-based got 4/6 wrong!) ──\n",
    "hard_text = (\"Dr. Sarah Chen met Professor James Lee at the annual conference. \"\n",
    "             \"She presented her groundbreaking research on climate change. \"\n",
    "             \"He asked several challenging questions about her methodology. \"\n",
    "             \"Later, she invited him to collaborate on a joint paper.\")\n",
    "\n",
    "preds = coref_model.predict(texts=[hard_text])\n",
    "clusters = preds[0].get_clusters(as_strings=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hard text (rule-based resolver failed on gender)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Text: {hard_text}\\n\")\n",
    "print(\"Coreference clusters found by F-Coref:\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"  Cluster {i+1}: {cluster}\")\n",
    "print(\"\\nF-Coref correctly separates the two people using gender\"\n",
    "      \" — something our rule-based resolver could not do.\")\n",
    "\n",
    "# ── 3. Additional hard cases ──────────────────────────────────────\n",
    "more_texts = [\n",
    "    # Event coreference — \"It\" refers to an event, not a person\n",
    "    \"The company announced a merger with its rival. \"\n",
    "    \"It was expected to create 500 new jobs.\",\n",
    "\n",
    "    # Unambiguous gender in \"told X that she...\"\n",
    "    \"Alice told Bob that she had passed the exam.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"More hard cases\")\n",
    "print(\"=\" * 60)\n",
    "for text in more_texts:\n",
    "    preds = coref_model.predict(texts=[text])\n",
    "    clusters = preds[0].get_clusters(as_strings=True)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    if clusters:\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            print(f\"  Cluster {i+1}: {cluster}\")\n",
    "    else:\n",
    "        print(\"  No coreference found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based vs BERT: Key Observations\n",
    "\n",
    "| Feature | Rule-Based (Step 2) | BERT — F-Coref (Step 3) |\n",
    "|---------|-------------------|------------------------|\n",
    "| **Easy case** (Obama / He) | ✓ Correct | ✓ Correct |\n",
    "| **Gender matching** (Mary / She) | ✗ Picks wrong antecedent | ✓ Correct |\n",
    "| **Event coreference** (merger / It) | ✗ Cannot resolve | ✓ Correct |\n",
    "| **Speed** | Instant | ~0.3 s per text (GPU) |\n",
    "| **Training data required** | None | OntoNotes 5.0 (1.7M words) |\n",
    "| **Interpretability** | High — two explicit rules | Low — learned representations |\n",
    "| **Dependencies** | NLTK only | PyTorch + Transformers (362 MB model) |\n",
    "\n",
    "**Takeaway:** The BERT-based model handles the hard cases that broke our rule-based resolver — gender agreement, event coreference, and semantic similarity — but it trades **interpretability** and **simplicity** for **accuracy**. We can clearly explain *why* the rule-based system made each decision (recency + proper-noun preference), while the neural model is essentially a black box.\n",
    "\n",
    "This **interpretability vs. performance** trade-off is a recurring theme in NLP and information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a7f44659fd130fdd614ae452e9e6ddb",
     "grade": false,
     "grade_id": "cell-57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 13. Negation Handling\n",
    "\n",
    "## Why Negation Matters\n",
    "\n",
    "Consider medical text mining:\n",
    "\n",
    "> *\"The patient does **not** have diabetes.\"*\n",
    "\n",
    "A keyword system would extract *\"patient — has — diabetes\"*, the **opposite** of the truth. Detecting negation and its **scope** is critical for:\n",
    "- **Sentiment analysis** — \"not good\" vs. \"good\"\n",
    "- **Medical NLP** — negated vs. confirmed symptoms\n",
    "- **Knowledge Graphs** — avoiding false-positive relations\n",
    "\n",
    "## Negation Cues and Scope\n",
    "\n",
    "| Component | Definition | Examples |\n",
    "|-----------|-----------|----------|\n",
    "| **Cue** | Word or morpheme that signals negation | *not, no, never, un-, -less* |\n",
    "| **Scope** | Part of the sentence affected by the cue | *have diabetes* |\n",
    "\n",
    "| Sentence | Cue | Scope |\n",
    "|----------|-----|-------|\n",
    "| The patient does **not** have diabetes | not | have diabetes |\n",
    "| There is **no** evidence of cancer | no | evidence of cancer |\n",
    "| The test was **un**successful | un- | successful |\n",
    "| He **never** returned to work | never | returned to work |\n",
    "\n",
    "## How Dependency Grammar Helps\n",
    "\n",
    "In a dependency tree, *\"not\"* attaches to the verb it modifies (`advmod` / `neg`). The **scope** of negation is approximated by the **subtree** rooted at that verb:\n",
    "\n",
    "- *\"John does **not** like chocolate\"*\n",
    "  - not → `advmod` → like → subtree = {like, chocolate}\n",
    "  - Scope = *\"like chocolate\"*\n",
    "\n",
    "Below we build a negation detector and scope analyser step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0c43d1c10becfb98677902412ebde7e",
     "grade": false,
     "grade_id": "cell-58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1 — Detecting Negation Cues\n",
    "\n",
    "We scan POS-tagged sentences for two kinds of negation:\n",
    "1. **Word-level** — tokens like *not*, *no*, *never*\n",
    "2. **Prefix-level** — morphemes like *un-*, *in-*, *im-*, *dis-*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "983ec1f5ac05989a9a9eff43f9d0cf54",
     "grade": false,
     "grade_id": "cell-59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The patient does not have diabetes.\n",
      "  → cue 'not' at position 3  (type: word)\n",
      "\n",
      "Sentence: No significant abnormalities were detected.\n",
      "  → cue 'No' at position 0  (type: word)\n",
      "\n",
      "Sentence: He never returned to work.\n",
      "  → cue 'never' at position 1  (type: word)\n",
      "\n",
      "Sentence: The treatment was unsuccessful.\n",
      "  → cue 'unsuccessful' at position 3  (type: prefix (un-))\n",
      "\n",
      "Sentence: The result is not insignificant.\n",
      "  → cue 'not' at position 3  (type: word)\n",
      "  → cue 'insignificant' at position 4  (type: prefix (in-))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- negation cue lexicon ---\n",
    "NEGATION_WORDS    = {'not', \"n't\", 'no', 'never', 'neither', 'nor',\n",
    "                     'nobody', 'nothing', 'nowhere', 'none'}\n",
    "NEGATION_PREFIXES = ['un', 'in', 'im', 'ir', 'il', 'non', 'dis']\n",
    "\n",
    "# Words that START with a negation prefix but are NOT negated\n",
    "FALSE_POSITIVES   = {'under', 'until', 'unless', 'into', 'increase',\n",
    "                     'include', 'indeed', 'indicate', 'individual',\n",
    "                     'industry', 'information', 'interest', 'inside',\n",
    "                     'important', 'improve', 'imagine', 'image',\n",
    "                     'discuss', 'discover', 'display', 'distance',\n",
    "                     'district', 'dinner', 'direct', 'different',\n",
    "                     'none', 'normal', 'note', 'notice', 'novel'}\n",
    "\n",
    "def find_negation_cues(sentence):\n",
    "    \"\"\"Return a list of (position, word, cue_type) tuples.\"\"\"\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "    cues = []\n",
    "\n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        low = word.lower()\n",
    "\n",
    "        # 1) word-level negation\n",
    "        if low in NEGATION_WORDS:\n",
    "            cues.append((i, word, 'word'))\n",
    "            continue\n",
    "\n",
    "        # 2) prefix-level negation (only adjectives/adverbs/nouns)\n",
    "        if tag in ('JJ', 'RB', 'NN', 'VBN', 'VBD') and low not in FALSE_POSITIVES:\n",
    "            for pfx in NEGATION_PREFIXES:\n",
    "                if low.startswith(pfx) and len(low) > len(pfx) + 2:\n",
    "                    cues.append((i, word, f'prefix ({pfx}-)'))\n",
    "                    break\n",
    "\n",
    "    return tokens, tagged, cues\n",
    "\n",
    "# --- test sentences ---\n",
    "test_sentences = [\n",
    "    \"The patient does not have diabetes.\",\n",
    "    \"No significant abnormalities were detected.\",\n",
    "    \"He never returned to work.\",\n",
    "    \"The treatment was unsuccessful.\",\n",
    "    \"The result is not insignificant.\",   # double negation!\n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    tokens, tagged, cues = find_negation_cues(sent)\n",
    "    print(f\"Sentence: {sent}\")\n",
    "    if cues:\n",
    "        for pos, word, ctype in cues:\n",
    "            print(f\"  → cue '{word}' at position {pos}  (type: {ctype})\")\n",
    "    else:\n",
    "        print(\"  → no negation detected\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ed5575fbedef933d75c60e7b8e10d7c",
     "grade": false,
     "grade_id": "cell-60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The detector finds word-level cues (*not, no, never*) and prefix-level cues (*un-successful*, *in-significant*). Note the false-positive filter: words like *under* or *increase* start with negation prefixes but are not negated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8210a2ebb924e71ecf4e08651f0f96e3",
     "grade": false,
     "grade_id": "cell-61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2 — Determining Negation Scope with Chunking\n",
    "\n",
    "We use **VP chunking** (Section 8) to determine what the negation applies to. The basic rule:\n",
    "\n",
    "> The scope of a negation cue = the **verb phrase and its complements** that follow the cue, up to the next clause boundary (punctuation or conjunction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b84f42f2e704fe18593a66104cd13a16",
     "grade": false,
     "grade_id": "cell-62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The patient does not have a history of heart disease.\n",
      "  Cue:     'not' (word)\n",
      "  Scope:   'have a history of heart disease'\n",
      "  Meaning: NOT [have a history of heart disease]\n",
      "  Cue:     'disease' (prefix (dis-))\n",
      "  Scope:   'disease'\n",
      "  Meaning: not disease\n",
      "\n",
      "Sentence:  No evidence of malignancy was found in the biopsy.\n",
      "  Cue:     'No' (word)\n",
      "  Scope:   'evidence of malignancy was found in the biopsy'\n",
      "  Meaning: NOT [evidence of malignancy was found in the biopsy]\n",
      "\n",
      "Sentence:  The CEO did not approve the merger but supported the partnership.\n",
      "  Cue:     'not' (word)\n",
      "  Scope:   'approve the merger'\n",
      "  Meaning: NOT [approve the merger]\n",
      "\n",
      "Sentence:  The treatment was unsuccessful.\n",
      "  Cue:     'unsuccessful' (prefix (un-))\n",
      "  Scope:   'unsuccessful'\n",
      "  Meaning: not unsuccessful\n",
      "\n",
      "Sentence:  The result is not insignificant.\n",
      "  Cue:     'not' (word)\n",
      "  Scope:   'insignificant'\n",
      "  Meaning: NOT [insignificant]\n",
      "  Cue:     'insignificant' (prefix (in-))\n",
      "  Scope:   'insignificant'\n",
      "  Meaning: not insignificant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def detect_negation_scope(sentence):\n",
    "    \"\"\"Detect negation cues and determine their scope.\"\"\"\n",
    "    tokens, tagged, cues = find_negation_cues(sentence)\n",
    "\n",
    "    results = []\n",
    "    for cue_pos, cue_word, cue_type in cues:\n",
    "        if 'prefix' in cue_type:\n",
    "            # Prefix negation: scope is just the word itself\n",
    "            results.append({\n",
    "                'cue': cue_word, 'type': cue_type,\n",
    "                'scope': cue_word, 'negated_meaning': f'not {cue_word}'\n",
    "            })\n",
    "        else:\n",
    "            # Word negation: scope extends to next clause boundary\n",
    "            # Clause boundaries: . ! ? , ; : and coordinating conjunctions\n",
    "            boundary_tags = {'.', ',', ':', 'CC'}  # CC = and, but, or\n",
    "            scope_end = len(tokens)\n",
    "            for j in range(cue_pos + 1, len(tokens)):\n",
    "                if (tagged[j][1] in boundary_tags or\n",
    "                    tokens[j] in '.!?;'):\n",
    "                    scope_end = j\n",
    "                    break\n",
    "            scope_tokens = tokens[cue_pos + 1 : scope_end]\n",
    "            results.append({\n",
    "                'cue': cue_word, 'type': cue_type,\n",
    "                'scope': ' '.join(scope_tokens),\n",
    "                'negated_meaning': f'NOT [{\" \".join(scope_tokens)}]'\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- test ---\n",
    "scope_tests = [\n",
    "    \"The patient does not have a history of heart disease.\",\n",
    "    \"No evidence of malignancy was found in the biopsy.\",\n",
    "    \"The CEO did not approve the merger but supported the partnership.\",\n",
    "    \"The treatment was unsuccessful.\",\n",
    "    \"The result is not insignificant.\",\n",
    "]\n",
    "\n",
    "for sent in scope_tests:\n",
    "    print(f\"Sentence:  {sent}\")\n",
    "    negs = detect_negation_scope(sent)\n",
    "    for n in negs:\n",
    "        print(f\"  Cue:     '{n['cue']}' ({n['type']})\")\n",
    "        print(f\"  Scope:   '{n['scope']}'\")\n",
    "        print(f\"  Meaning: {n['negated_meaning']}\")\n",
    "    if not negs:\n",
    "        print(\"  No negation.\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6ea9131523ff3371f0de670d4d57fb0",
     "grade": false,
     "grade_id": "cell-63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### What the Scope Detector Does Well\n",
    "\n",
    "- *\"does not have a history of heart disease\"* --> scope = *\"have a history of heart disease\"* correct\n",
    "- *\"did not approve the merger **but** supported the partnership\"* --> scope stops at *\"but\"*, correctly excluding the positive second clause\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Double negation** (*\"not insignificant\"*) — the detector finds two separate cues but does not combine them into the positive meaning \"significant\"\n",
    "- **Long-range scope** — in *\"I do not think he is coming\"*, the scope arguably extends into the embedded clause, but our heuristic would stop at the clause boundary\n",
    "- These hard cases are why clinical NLP tools like **NegEx** and **NegBio** use carefully crafted rule sets over dependency trees, and modern systems use neural models trained on annotated negation corpora (SEM-2012 Shared Task).\n",
    "\n",
    "But have modern BERT-based models actually **solved** the negation problem? Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Can BERT Handle Negation?\n",
    "\n",
    "Back in 2019, several studies showed that BERT-era models struggled with negation — treating *\"this movie is not good\"* as positive because the word *\"good\"* dominated the representation. The SEM-2012 Shared Task specifically targeted this problem.\n",
    "\n",
    "But transformer models have improved significantly since then. Let's test a modern **DistilBERT sentiment classifier** (trained on SST-2) on a progression of increasingly difficult negation patterns:\n",
    "\n",
    "1. **Simple negation** — *\"not good\"*, *\"not bad\"*\n",
    "2. **Negated negatives** — *\"not bad\"*, *\"not terrible\"* (should flip to positive)\n",
    "3. **Double negation with prefixes** — *\"not unhappy\"*, *\"not insignificant\"* (should be positive)\n",
    "4. **Complex multi-clause negation** — *\"I would not say it was not enjoyable\"* (the hardest case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 493.72it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "BERT Sentiment Analysis on Negation Patterns\n",
      "=====================================================================================\n",
      "\n",
      "--- SIMPLE NEGATION ---\n",
      "  [OK   ] \"The movie is good\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (1.000)\n",
      "  [OK   ] \"The movie is not good\"\n",
      "          Expected: NEGATIVE  |  Got: NEGATIVE (1.000)\n",
      "  [OK   ] \"The movie is bad\"\n",
      "          Expected: NEGATIVE  |  Got: NEGATIVE (1.000)\n",
      "  [OK   ] \"The service was terrible\"\n",
      "          Expected: NEGATIVE  |  Got: NEGATIVE (1.000)\n",
      "  [OK   ] \"The service was not terrible\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (0.978)\n",
      "\n",
      "--- DOUBLE NEGATION (negated negatives) ---\n",
      "  [OK   ] \"The movie was not bad\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (0.999)\n",
      "  [OK   ] \"I am not unhappy with the result\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (0.996)\n",
      "  [OK   ] \"The effect was not insignificant\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (0.991)\n",
      "  [OK   ] \"The food was not unenjoyable\"\n",
      "          Expected: POSITIVE  |  Got: POSITIVE (0.965)\n",
      "\n",
      "--- COMPLEX MULTI-CLAUSE NEGATION ---\n",
      "  [WRONG] \"I would not say the movie was not enjoyable\"\n",
      "          Expected: POSITIVE  |  Got: NEGATIVE (1.000)\n",
      "  [WRONG] \"I don't think this isn't a bad idea\"\n",
      "          Expected: NEGATIVE  |  Got: POSITIVE (0.999)\n",
      "\n",
      "=====================================================================================\n",
      "Overall accuracy: 9/11 (82%)\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ── Step 3: Test BERT sentiment analysis on negation ──\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline(\"sentiment-analysis\", device=device)\n",
    "\n",
    "# Group 1: Simple negation (solved since ~2020)\n",
    "simple_tests = [\n",
    "    (\"The movie is good\",           \"POSITIVE\"),\n",
    "    (\"The movie is not good\",       \"NEGATIVE\"),\n",
    "    (\"The movie is bad\",            \"NEGATIVE\"),\n",
    "    (\"The service was terrible\",    \"NEGATIVE\"),\n",
    "    (\"The service was not terrible\",\"POSITIVE\"),\n",
    "]\n",
    "\n",
    "# Group 2: Negated negatives / double negation with prefixes\n",
    "double_neg_tests = [\n",
    "    (\"The movie was not bad\",          \"POSITIVE\"),\n",
    "    (\"I am not unhappy with the result\",\"POSITIVE\"),\n",
    "    (\"The effect was not insignificant\",\"POSITIVE\"),\n",
    "    (\"The food was not unenjoyable\",   \"POSITIVE\"),\n",
    "]\n",
    "\n",
    "# Group 3: Complex multi-clause negation (still hard!)\n",
    "hard_tests = [\n",
    "    (\"I would not say the movie was not enjoyable\",  \"POSITIVE\"),  # double neg → positive\n",
    "    (\"I don't think this isn't a bad idea\",          \"NEGATIVE\"),  # triple neg → negative\n",
    "]\n",
    "\n",
    "all_groups = [\n",
    "    (\"SIMPLE NEGATION\", simple_tests),\n",
    "    (\"DOUBLE NEGATION (negated negatives)\", double_neg_tests),\n",
    "    (\"COMPLEX MULTI-CLAUSE NEGATION\", hard_tests),\n",
    "]\n",
    "\n",
    "print(\"=\" * 85)\n",
    "print(\"BERT Sentiment Analysis on Negation Patterns\")\n",
    "print(\"=\" * 85)\n",
    "\n",
    "total_correct = 0\n",
    "total_count = 0\n",
    "\n",
    "for group_name, tests in all_groups:\n",
    "    print(f\"\\n--- {group_name} ---\")\n",
    "    for text, expected in tests:\n",
    "        result = sentiment(text)[0]\n",
    "        predicted = result[\"label\"]\n",
    "        score = result[\"score\"]\n",
    "        correct = predicted == expected\n",
    "        total_count += 1\n",
    "        if correct:\n",
    "            total_correct += 1\n",
    "        status = \"OK\" if correct else \"WRONG\"\n",
    "        print(f\"  [{status:5s}] \\\"{text}\\\"\")\n",
    "        print(f\"          Expected: {expected:8s}  |  Got: {predicted:8s} ({score:.3f})\")\n",
    "\n",
    "print(f\"\\n{'=' * 85}\")\n",
    "print(f\"Overall accuracy: {total_correct}/{total_count} ({100*total_correct/total_count:.0f}%)\")\n",
    "print(f\"{'=' * 85}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Learned\n",
    "\n",
    "| Negation Type | Rule-Based Detector | BERT Sentiment |\n",
    "|---|---|---|\n",
    "| Simple negation (*\"not good\"*) | Finds cue + scope, but no sentiment | **Correct** — handles simple negation well |\n",
    "| Negated negatives (*\"not bad\"*) | Finds \"not\" but misses the flip | **Correct** — understands \"not bad\" = positive |\n",
    "| Prefix double negation (*\"not unhappy\"*) | Detects two separate cues | **Correct** — resolves to positive meaning |\n",
    "| Complex multi-clause (*\"would not say...not enjoyable\"*) | Cannot parse nested structure | **Fails** — still trips on deeply nested negation |\n",
    "\n",
    "**Key takeaway:** Modern transformer models have largely **solved** the basic negation problems that plagued NLP systems circa 2019. Simple negation and even double negation with prefixes are handled correctly. However, complex multi-clause negation with nested scopes (e.g., *\"I would not say the movie was not enjoyable\"*) remains a challenge — these constructions are rare in training data and require deep syntactic reasoning that even modern models struggle with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0073e77a0397893863eb37227b42d56",
     "grade": false,
     "grade_id": "cell-64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 14. Exercises\n",
    "\n",
    "The exercises below test your understanding of co-reference resolution and negation handling. For the programming exercise, look back at the code examples in Sections 12 and 13, as well as the POS tagging (Section 6), chunking (Section 8), and dependency parsing (Section 11) code earlier in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a96bc08a0c7461836780110a33fa58f",
     "grade": false,
     "grade_id": "exercise1_prompt",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Exercise 1 — Co-reference Resolution (Open Question)\n",
    "\n",
    "Consider the following text:\n",
    "\n",
    "> *\"Mary told Susan that **she** had been promoted. **She** was very happy about **it**.\"*\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. The pronoun *\"she\"* appears twice. For each occurrence, who does it most likely refer to — Mary or Susan? Explain your reasoning using the concepts of **subject preference** and **recency**.\n",
    "\n",
    "2. Our simple `resolve_pronouns()` function above would resolve both occurrences of *\"she\"* to the same antecedent. Explain **why** it fails and what additional rule or information you would need to handle this correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cfeaa41fa28496d8c8a17402e1d1d9f",
     "grade": true,
     "grade_id": "exercise1_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cb613561dce5aca99483336ed5f2641",
     "grade": false,
     "grade_id": "exercise2_prompt",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Exercise 2 — Negation Scope (Open Question)\n",
    "\n",
    "Consider the following two sentences:\n",
    "\n",
    "> A: *\"The patient was **not** treated with antibiotics and recovered quickly.\"*\n",
    ">\n",
    "> B: *\"The patient was **not** treated with antibiotics and **not** given any medication.\"*\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. In sentence A, does the negation apply only to *\"treated with antibiotics\"*, or does it also negate *\"recovered quickly\"*? How does the coordinating conjunction *\"and\"* create ambiguity here?\n",
    "\n",
    "2. In sentence B, the scope is clearer. Explain why the second *\"not\"* makes the intended meaning unambiguous.\n",
    "\n",
    "3. Our `detect_negation_scope()` function uses clause boundaries (commas, conjunctions) to limit scope. Run sentence A through the function mentally (or in code). Does it produce the correct scope? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cfeaa41fa28496d8c8a17402e1d1d9f",
     "grade": true,
     "grade_id": "exercise2_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c0fbcf1018a2a702f55844c1a8d5430",
     "grade": false,
     "grade_id": "exercise3_prompt",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3 — Improved Negation-Aware Information Extractor (Programming)\n",
    "\n",
    "Build a function `extract_medical_facts(sentence)` that:\n",
    "\n",
    "1. **POS-tags** the sentence (Section 6)\n",
    "2. **Detects NP chunks** as subjects and objects (Section 8 — use `RegexpParser`)\n",
    "3. **Detects negation cues** using the `find_negation_cues()` function from Section 13\n",
    "4. Returns a list of **(subject, verb, object, is_negated)** tuples\n",
    "\n",
    "**Test sentences** (expected output shown):\n",
    "\n",
    "| Sentence | Expected output |\n",
    "|----------|-----------------|\n",
    "| *\"The patient has diabetes.\"* | `('The patient', 'has', 'diabetes', False)` |\n",
    "| *\"The patient does not have diabetes.\"* | `('The patient', 'have', 'diabetes', True)` |\n",
    "| *\"No evidence of cancer was found.\"* | `('evidence of cancer', 'found', '', True)` |\n",
    "\n",
    "**Hints:**\n",
    "- Re-use `RegexpParser` with the NP grammar `{<DT>?<JJ>*<NN.*>+}` from Section 8\n",
    "- Re-use `find_negation_cues()` from Section 13 to check if a verb falls within a negation scope\n",
    "- You can find the main verb by looking for POS tags starting with `VB`\n",
    "- Don't worry about getting every edge case right — focus on the three test sentences above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "245fd6c5537ed5daa8d376791e9527a0",
     "grade": false,
     "grade_id": "exercise3_solution",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient has diabetes.\n",
      "  → None\n",
      "\n",
      "The patient does not have diabetes.\n",
      "  → None\n",
      "\n",
      "No evidence of cancer was found.\n",
      "  → None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3 — YOUR CODE HERE\n",
    "# Hint: the functions and libraries you need are all used\n",
    "# earlier in this notebook. Scroll up to see how they work.\n",
    "\n",
    "def extract_medical_facts(sentence):\n",
    "    \"\"\"\n",
    "    Extract (subject, verb, object, is_negated) tuples from a sentence.\n",
    "    \"\"\"\n",
    "    # Step 1: tokenize and POS-tag\n",
    "    # tokens = ...\n",
    "    # tagged = ...\n",
    "\n",
    "    # Step 2: chunk NPs\n",
    "    # np_grammar = ...\n",
    "\n",
    "    # Step 3: detect negation\n",
    "    # cues = ...\n",
    "\n",
    "    # Step 4: find verb, subject, object, and check negation\n",
    "    pass  # replace with your implementation\n",
    "\n",
    "\n",
    "# --- test your implementation ---\n",
    "test = [\n",
    "    \"The patient has diabetes.\",\n",
    "    \"The patient does not have diabetes.\",\n",
    "    \"No evidence of cancer was found.\",\n",
    "]\n",
    "\n",
    "for s in test:\n",
    "    result = extract_medical_facts(s)\n",
    "    print(f\"{s}\")\n",
    "    print(f\"  → {result}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bb9e4580011afa807cecbbed16928bf",
     "grade": true,
     "grade_id": "exercise3_tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Function must return a result (not None)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Test 2: positive assertion\u001b[39;00m\n\u001b[32m      8\u001b[39m _r1 = extract_medical_facts(\u001b[33m\"\u001b[39m\u001b[33mThe patient has diabetes.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m _r1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mFunction must return a result (not None)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_r1, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), \u001b[33m\"\u001b[39m\u001b[33mFunction must return a list or tuple\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_r1) > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mAssertionError\u001b[39m: Function must return a result (not None)"
     ]
    }
   ],
   "source": [
    "# AUTO-GRADED TESTS (10 points)\n",
    "# Do not modify this cell\n",
    "\n",
    "# Test 1: function exists and is callable\n",
    "assert callable(extract_medical_facts), \"extract_medical_facts() must be defined as a function\"\n",
    "\n",
    "# Test 2: positive assertion\n",
    "_r1 = extract_medical_facts(\"The patient has diabetes.\")\n",
    "assert _r1 is not None, \"Function must return a result (not None)\"\n",
    "assert isinstance(_r1, (list, tuple)), \"Function must return a list or tuple\"\n",
    "if len(_r1) > 0:\n",
    "    _item = _r1[0] if isinstance(_r1, list) else _r1\n",
    "    assert len(_item) == 4, \"Each result must be a 4-tuple: (subject, verb, object, is_negated)\"\n",
    "    assert _item[3] == False, \"'The patient has diabetes.' should NOT be negated\"\n",
    "\n",
    "# Test 3: negation detection\n",
    "_r2 = extract_medical_facts(\"The patient does not have diabetes.\")\n",
    "assert _r2 is not None, \"Function must return a result for negated sentence\"\n",
    "if len(_r2) > 0:\n",
    "    _item2 = _r2[0] if isinstance(_r2, list) else _r2\n",
    "    assert _item2[3] == True, \"'The patient does not have diabetes.' SHOULD be negated\"\n",
    "\n",
    "# Test 4: another negation pattern\n",
    "_r3 = extract_medical_facts(\"No evidence of cancer was found.\")\n",
    "assert _r3 is not None, \"Function must return a result for 'No' negation\"\n",
    "if len(_r3) > 0:\n",
    "    _item3 = _r3[0] if isinstance(_r3, list) else _r3\n",
    "    assert _item3[3] == True, \"'No evidence of cancer was found.' SHOULD be negated\"\n",
    "\n",
    "print(\"All auto-graded tests passed! ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d56ada8e6fd82c8556524f14639afd0",
     "grade": false,
     "grade_id": "cell-71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Submission\n",
    "\n",
    "To submit your work:\n",
    "\n",
    "1. Make sure all cells have been executed and the outputs are visible\n",
    "2. Fill in your answers for **Exercise 1** (co-reference) and **Exercise 2** (negation) in the designated cells\n",
    "3. Complete the code for **Exercise 3** and verify it runs on the test sentences\n",
    "4. Save your notebook: **File → Save** (or Ctrl+S)\n",
    "5. Submit the `.ipynb` file via the course submission system\n",
    "\n",
    "**Reminder**: Part 2 of this tutorial covers Named Entity Recognition, Relation Extraction, and Knowledge Graph construction — building on the foundations from this notebook.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
