{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkHS4-bywpqG"
      },
      "source": [
        "![Maastricht_University_logo.svg](data:image/svg+xml;base64,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)\n",
        "\n",
        "# Information Retrieval and Text Mining Course - Neural Reranking Tutorial\n",
        "Authors: Abderrahmane Issam and Jan Scholtes\n",
        "\n",
        "Version 2024-2025 V20250415\n",
        "\n",
        "#Notebook 4\n",
        "\n",
        "In this notebook we will learn how to use [Pyterrier](https://github.com/terrier-org/pyterrier), a Python framework that is built on top of the Java-based Terrier IR platform. Pyterrier can be used to index different formats of datasets and can be integrated with different models starting from classical approaches like BM25 up to neural models like ColBERT. We will learn how to use Pyterrier for indexing, search and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eq8R0OY6c_U"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k-DRUf1rUfP"
      },
      "source": [
        "### If you have a local GPU (Do the following steps in your local env):\n",
        "If you have a GPU and you want to run this notebook locally, then I suggest you set up a conda environement as follows:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name ir python=3.11.1 \\\\\n",
        "conda install -c conda-forge openjdk=11 \\\\\n",
        "pip install notebook\n",
        "```\n",
        "The second step is to start jupyter in your local machine as follows:\n",
        "```\n",
        "jupyter notebook \\\n",
        "    --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "    --port=8888 \\\n",
        "    --NotebookApp.port_retries=0\n",
        "```\n",
        "Then go to `connect to local runtime` (which you will find in the menu where you can change the runtime) and paste the jupter backend URL that tou got in the output of the previous command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9YW_CKdyp1W"
      },
      "source": [
        "If you are running this locally, then you only need to install packages once, otherwise, you will need to install them at the start of the instance and restart the runtime when required to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOuFzDx1MOnB"
      },
      "outputs": [],
      "source": [
        "!pip install python-terrier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKWUw0s5uQLc"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade \"git+https://github.com/terrierteam/pyterrier_colbert.git\" --use-pep517"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnZel0gn6klB"
      },
      "source": [
        "## Indexing and Search Using Pyterrier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOulTM8FuZ6G"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-gpu-cu12\n",
        "\n",
        "import faiss\n",
        "assert faiss.get_num_gpus() > 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy --upgrade --force-reinstall"
      ],
      "metadata": {
        "id": "t44uMpaPz8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XdkLDajxhxl"
      },
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "if not pt.java.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5BAIBa03bvQ"
      },
      "source": [
        "Pyterrier can create an index from different dataset formats including Pandas DataFrame which we demonstrate below. We will create a synthetic DataFrame of documents, as well as queries and qrels to use for evaluation. After indexing the documents, we create a BM25 model that we will use for search later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p66B8Vj05j1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Define Documents\n",
        "documents = pd.DataFrame([\n",
        "    {\"docno\": \"d1\", \"text\": \"PyTerrier is great for information retrieval.\"},\n",
        "    {\"docno\": \"d2\", \"text\": \"Terrier is a powerful information retrieval platform.\"},\n",
        "    {\"docno\": \"d3\", \"text\": \"Python is a popular programming language.\"},\n",
        "    {\"docno\": \"d4\", \"text\": \"This tutorial introduces PyTerrier basics.\"}\n",
        "])\n",
        "\n",
        "# 2. Define Queries\n",
        "queries = pd.DataFrame([\n",
        "    {\"query\": \"information retrieval\", \"qid\": \"q1\"},\n",
        "    {\"query\": \"programming tutorial\", \"qid\": \"q2\"}\n",
        "])\n",
        "\n",
        "# 3. Define Relevance Judgments (qrels)\n",
        "qrels = pd.DataFrame([\n",
        "    {\"qid\": \"q1\", \"docno\": \"d1\", \"label\": 1},\n",
        "    {\"qid\": \"q1\", \"docno\": \"d2\", \"label\": 0},\n",
        "    {\"qid\": \"q2\", \"docno\": \"d3\", \"label\": 1},\n",
        "    {\"qid\": \"q2\", \"docno\": \"d4\", \"label\": 1}\n",
        "])\n",
        "\n",
        "# 4. Indexing\n",
        "index_path = \"./index\"\n",
        "!rm -r \"./index\"    # Remove index if it exists\n",
        "\n",
        "indexer = pt.index.DFIndexer(index_path)\n",
        "index_ref = indexer.index(text=documents[\"text\"], docno=documents[\"docno\"])\n",
        "\n",
        "# 5. Retrieval (BM25)\n",
        "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eUhSsVi41bR"
      },
      "source": [
        "We can see the files were created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59FwuzR74zSl"
      },
      "outputs": [],
      "source": [
        "!ls -ltrh ./index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z9m-HZC5eqm"
      },
      "source": [
        "We can see statistics of our index as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IHuEfHo5W0Y"
      },
      "outputs": [],
      "source": [
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(index.getCollectionStatistics().toString())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = index.getLexicon()\n",
        "\n",
        "for entry in terms:\n",
        "    print(entry.getKey())"
      ],
      "metadata": {
        "id": "lpaKb2HAy2wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdPHTupu7L7D"
      },
      "source": [
        "### Exercise 1:\n",
        "The number of terms (13) is less than the number of words in all the 4 documents. Explain the reason for this."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here"
      ],
      "metadata": {
        "id": "DUAmPZEMq9j-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9NRiq17rUI"
      },
      "source": [
        "These are the terms identified by Pyterrier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnVLk2eb52Yj"
      },
      "outputs": [],
      "source": [
        "for kv in index.getLexicon():\n",
        "  print(\"%s -> %s\" % (kv.getKey(), kv.getValue().toString() ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjDLGnUD3KGc"
      },
      "source": [
        "We can search a Pyterrier index using BM25 with the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luy2PLR41pIF"
      },
      "outputs": [],
      "source": [
        "bm25.search(\"programming language\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwMqoQc6H-n"
      },
      "source": [
        "\n",
        "### Exercise2\n",
        "\n",
        "Define each column in the output of search above."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here."
      ],
      "metadata": {
        "id": "MVdWw-jsrAoA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLTBNBtL2ODV"
      },
      "source": [
        "Pyterrier offers a way to evaluate models using a different metrics. The list of possible metrics to use is available here: https://pyterrier.readthedocs.io/en/latest/experiments.html#evaluation-measures-objects. \\\\\n",
        "\n",
        "We can also see how `Experiment` accepts a DataFrame of queries and qrels which are used to compute the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUATv90115EO"
      },
      "outputs": [],
      "source": [
        "# 6. Evaluation Pipeline\n",
        "pt.Experiment([bm25], queries, qrels, eval_metrics=[\"map\", \"P_10\"], names=[\"BM25\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJeWweJI0Ae-"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Instead of BM25 use a TF_IDF model. Try using it to search for a query then pass it along with bm25 to `Experiment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xceGNabM0qwM"
      },
      "outputs": [],
      "source": [
        "# Answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckaiDTg43C_g"
      },
      "source": [
        "## Neural Reranking with ColBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuGjM_kV3ZG1"
      },
      "source": [
        "Below we use `pyterrier_colbert` which is a plugin for Pyterrier that makes it possible to use a ColBERT model for indexing and retrieval. We will use the [Vaswani NPL corpus](http://ir.dcs.gla.ac.uk/resources/test_collections/npl/), a corpus of 11,429 scientific abstract, with corresponding queries and relevance assessments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3piECYQzyr2M"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./colbertindex\n",
        "\n",
        "import pyterrier_colbert.indexing\n",
        "\n",
        "checkpoint=\"http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\"\n",
        "\n",
        "indexer = pyterrier_colbert.indexing.ColBERTIndexer(checkpoint, \"./\", \"colbertindex\", chunksize=3)\n",
        "indexer.index(pt.get_dataset(\"irds:vaswani\").get_corpus_iter())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2uGTZrytcY"
      },
      "outputs": [],
      "source": [
        "!ls -ltrh ./colbertindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Icwt63850or"
      },
      "outputs": [],
      "source": [
        "pyterrier_colbert_factory = indexer.ranking_factory()\n",
        "\n",
        "colbert_e2e = pyterrier_colbert_factory.end_to_end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybry5guU4fdb"
      },
      "source": [
        "We search using ColBERT as follows. `% 5` is used to retrieve the top 5 most relevant entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUHiew777u-p"
      },
      "outputs": [],
      "source": [
        "out = (colbert_e2e % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke0EQqSeAB8y"
      },
      "outputs": [],
      "source": [
        "out.loc[0, 'query_toks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLfKWXDwAXxg"
      },
      "outputs": [],
      "source": [
        "out.loc[0, 'query_embs'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ik7N5I486-"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "There are two new columns in the search results: `query_toks` and `query_embs`. Explain what they are and explain the shape of `query_embs`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here."
      ],
      "metadata": {
        "id": "4ApMuBnDrEse"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItyOEk1371Qt"
      },
      "outputs": [],
      "source": [
        "dataset = pt.datasets.get_dataset(\"vaswani\")\n",
        "index_path = \"./index\"\n",
        "\n",
        "!rm -rf ./index\n",
        "indexer = pt.TRECCollectionIndexer(index_path)\n",
        "\n",
        "indexer = indexer.index(dataset.get_corpus())\n",
        "\n",
        "bm25 = pt.BatchRetrieve(indexer, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2sMaSOnC3oE"
      },
      "source": [
        "In the following code we create a sentence transformer reranker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz3nxtVIt0DY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "crossmodel = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6', max_length=512)\n",
        "\n",
        "def _crossencoder_apply(df : pd.DataFrame):\n",
        "  return crossmodel.predict(list(zip(df['query'].values, df['text'].values)))\n",
        "\n",
        "cross_encT = pt.apply.doc_score(_crossencoder_apply, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTnCYtUmDCeH"
      },
      "source": [
        "We create a reranking pipeline that starts with BM25 as a retriever, and ends with using a sentence transformer (cross_encT) for reranking the retrieved documents. The reranking step requires the document text as input, which is not returned by default by bm25, and that is why we add `pt.text.get_text(dataset, 'text')` to retrieve the text documents and add them to the output of BM25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLn1pcbguEFE"
      },
      "outputs": [],
      "source": [
        "dataset = pt.get_dataset('irds:vaswani')\n",
        "cross_enc_rerank = bm25 >> pt.text.get_text(dataset, 'text') >> cross_encT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgYHDbpLym97"
      },
      "outputs": [],
      "source": [
        "out = (bm25 % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggpLB8xsuLfi"
      },
      "outputs": [],
      "source": [
        "out = (cross_enc_rerank % 5).search(\"chemical reactions\")\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHJZpudmGoBf"
      },
      "source": [
        "The following demonstrates how we can contruct IR pipelines using Pyterrier. The pipeline starts by using bm25 to retrieve relevant documents, which are then used by QueryExpantion transformer which expands the query by adding informative terms that are collected from the relevant documents. The last part runs bm25 with the new query. This process is called Pseudo Relevance Feedback (PRF)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzvolexLGTvT"
      },
      "outputs": [],
      "source": [
        "query_expansion = bm25 >> pt.rewrite.QueryExpansion(indexer) >> bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na2LRG7D6DmV"
      },
      "outputs": [],
      "source": [
        "pt.Experiment(\n",
        "    [bm25, query_expansion, colbert_e2e, cross_enc_rerank],\n",
        "    dataset.get_topics(),\n",
        "    dataset.get_qrels(),\n",
        "    eval_metrics=[\"map\", \"P_10\", \"mrt\"],\n",
        "    names = [\"BM25\", \"QE\", \"ColBERT\", \"BM25 >> CrossEnc\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prA5VNDsnyZo"
      },
      "source": [
        "On this small dataset, we can see that BM25 achieves better results than ColBERT. Adding Query Expansion improves MAP a little. But using PRF with ColBERT hurts (ColBERT-PRF) the performance while slowing down the inference because of the extra PRF step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK5XC3ZRD0bT"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Apply the same process as above on a dataset of your choice. You can find the list of datasets in Pyterrier here: https://pyterrier.readthedocs.io/en/latest/datasets.html#available-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH4cZR2uESN_"
      },
      "source": [
        "### Exercise 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjfgZfphEU5h"
      },
      "source": [
        "Add at least 2 other metrics and explain what each of them is trying to capture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noiY-9XlEQi1"
      },
      "outputs": [],
      "source": [
        "# Answer both exercise 5 and 6 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5lUPUg0FVr1"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "Follow the example in this [README](https://github.com/terrierteam/pyterrier_colbert/tree/ba5c86c0bc8da450dee361140541f35b5349a492) to implement Pseudo Relevance Feedback (PRF) with ColBERT. Describe how it works, and add ColBERT-PRF to `Experiment` to evaluate it against the other pipelines."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here"
      ],
      "metadata": {
        "id": "6y5EsrHwk0eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6imuGA8j3EF5"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "Implement a reranking pipeline with ColBERT and add it to `Experiment`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here"
      ],
      "metadata": {
        "id": "EhErbzvwr0Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKg5xc4M7qCr"
      },
      "source": [
        "## Arxiv Abstracts Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7YoCn027zTU"
      },
      "outputs": [],
      "source": [
        "!pip install setuptools==68.0.0       # you ca skip this if you are using a local instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZA0145agJz3"
      },
      "outputs": [],
      "source": [
        "!pip install arxiv==2.1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjYatix_7-jB"
      },
      "source": [
        "The following code will retrieve 1000 abstracts for the query \"nlp\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhHd1nCoAcw6"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "\n",
        "# Search for papers\n",
        "search = arxiv.Search(\n",
        "    query=\"nlp\",\n",
        "    max_results=1000,\n",
        "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msizIv3r8F07"
      },
      "source": [
        "We construct a dictionary of titles and abstracts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM2bzkxDBQo1"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "for result in search.results():\n",
        "    documents.append({\n",
        "        'title': result.title,\n",
        "        'abstract': result.summary,\n",
        "\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoj8xG1WuILx"
      },
      "outputs": [],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwkvkQmZHUb5"
      },
      "source": [
        "Rerun this in case you had to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkdP7YURHTZQ"
      },
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "if not pt.java.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z56iqtvA8LaD"
      },
      "source": [
        "To create an index, we need to to have a docno field which we create below, and a text field which is the abstract in this case. \\\\\n",
        "We use `DFIndexer` which allows us to create by passing a list ids and text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmIiaGl3CXWY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "index_path = './arxivindex'\n",
        "!rm -r './arxivindex'\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'docno': ['doc'+str(i) for i in range(len(documents))],\n",
        "    'text': [document['abstract'] for document in documents]\n",
        "})\n",
        "\n",
        "indexer = pt.DFIndexer(index_path)\n",
        "indexer.index(docno=df.docno, text=df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKoVc-Uq870G"
      },
      "source": [
        "We create a BM25 retrieval model for the Arxiv index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLlwtIQMvIQN"
      },
      "outputs": [],
      "source": [
        "bm25 = pt.BatchRetrieve(indexer, wmodel=\"BM25\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JKd8SP69LaZ"
      },
      "outputs": [],
      "source": [
        "(bm25 % 5).search(\"information retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv220WiL4dm9"
      },
      "outputs": [],
      "source": [
        "df[df['docno']=='doc670'].text.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQGIdbrBvoXd"
      },
      "source": [
        "### Exercise 9\n",
        "\n",
        "Create a ColBERT index using the Arxiv documents retrieved above and use it to search for some queries. Try to highlight how it is different from BM25 through the query results. You can also change the query we used to get arxiv pages."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}