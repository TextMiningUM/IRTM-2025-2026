{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230611e8",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f301d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c63ecf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdf569",
   "metadata": {
    "id": "m7tNwXXJ_BBb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e9131c8",
   "metadata": {
    "id": "UIBbWrF5_DXC"
   },
   "source": [
    "![Maastricht_University_logo.svg](data:image/svg+xml;base64,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)\n",
    "\n",
    "# Information Retrieval and Text Mining - Tutorial Measuring Quality\n",
    "Author: Jan Scholtes\n",
    "Version 2025-2026\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c71653",
   "metadata": {
    "id": "14xe-BeO_G34"
   },
   "source": [
    "Welcome to the tutorial on quantitatively measuring quality in Information Retrieval and Text Mining .\n",
    "\n",
    "Precision, Recall, F1, and 11-points precision-recall graphs are the most used quantitative measurements in information retrieval for classification problems. In this tutorial we will discuss these using data sets from the Text Retrieval Evaluation Conference (TREC) organized by the US National Institute of Standards (NIST).\n",
    "\n",
    "The Kappa-Cohen distance is used mostly to measure (dis)agreement between judges on annotated data sets. This is important to identify misunderstandings and forms of human bias on (human) annotated data sets.  \n",
    "\n",
    "For Topic Modeling and Clustering, we use the RAND index (related to Precision and REcall) and measurements such as the PMI (Pointwise Mutual Information).\n",
    "\n",
    "Sumaries use the ROUGE measurement. There are a variety of other measurements used in NLP. We will discuss most of them in the course on ANLP.\n",
    "\n",
    "In this tutorial we will first focus on IR and TM measurements. Mostly Precision, Recall, F1 and 11 points PR. Next, we will discuss other metrics such as Perplexity, ROUGE, and various metrics from the RAGAS framework. \n",
    "\n",
    "You can also find more background information in the lecture slides and here: Christopher D. Manning, Prabhakar Raghavan and Hinrich Sch√ºtze, Introduction to Information Retrieval, Chapter 8, Evaluation in information retrieval, Cambridge University Press. 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd165b",
   "metadata": {
    "id": "9EfQUBOA0Iws"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c03fad",
   "metadata": {
    "id": "XZHknOBjBVF_"
   },
   "source": [
    "Let's start defining a number of data structures as used in TREC:\n",
    "\n",
    "- Labels: the list of relevant document ID's for a particular search or classification operation.\n",
    "\n",
    "- Retrieved: the list with document ID's from all retrieved documents. This includes both relevant and non-relevant documents. Retrieved documents are often ranked on relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64d94f",
   "metadata": {
    "id": "NH7BmS-LYBIN"
   },
   "outputs": [],
   "source": [
    "# Actual Value\n",
    "labels = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "# Predicted Value\n",
    "predictions = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5251",
   "metadata": {
    "id": "suP1B5efYMGV"
   },
   "source": [
    "In Information Retrieval, the ranking of documents should also be included in the measurement of precision and recall. But let's first look at the unranked situation.\n",
    "\n",
    "We define the following:\n",
    "\n",
    "\n",
    "\n",
    "*   True Positive (TP) = number of relevant items identified as relevant\n",
    "*   True Negative (TN) = number of non-relevant items identified as non-relevant\n",
    "*   False Positive (FP) = number of non-relevant items identied as relevant\n",
    "*   False Negative (FN) = number of relevant items identified as non-relevant\n",
    "\n",
    "As we discussed in the lecture, precision, recall, F1 and Accuracy can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fde5b7",
   "metadata": {
    "id": "JrUWf21_Y4HW"
   },
   "source": [
    "$$Precision = \\frac{TP}{TP+FP}\\quad Recall = \\frac{TP}{(TP+FN)} \\quad Accuracy = \\frac{TP + TN}{TP + TN + FP + FN} \\quad F1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$$\n",
    "\n",
    "using the variables `tn`, `fp`, `fn`, `tp` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aeb545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533195f7",
   "metadata": {
    "id": "19IRIWuuiJEU"
   },
   "outputs": [],
   "source": [
    "TP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i] and labels[i] == 1:\n",
    "       TP+=1\n",
    "print(\"True Positive: \", TP) # 3\n",
    "FP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == 0 and predictions[i] == 1:\n",
    "       FP+=1\n",
    "print(\"False Positive: \", FP) # 3\n",
    "TN = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i] and labels[i] == 0:\n",
    "       TN+=1\n",
    "print(\"True Negative: \", TN) # 0\n",
    "FN = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == 1 and predictions[i] == 0:\n",
    "       FN+=1\n",
    "print(\"False Negative: \", FN) # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca1098",
   "metadata": {
    "id": "B-SlqW1giXTe"
   },
   "source": [
    "We can also measure the number of correct predictions (CP) and Incorrect Predictions (IP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bf587",
   "metadata": {
    "id": "YlfX0q8jigZu"
   },
   "outputs": [],
   "source": [
    "CP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i]:\n",
    "       CP+=1\n",
    "print(\"Correct Prediction: \", CP) # 3\n",
    "print(CP == TP + TN) # True\n",
    "ICP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] != predictions[i]:\n",
    "       ICP+=1\n",
    "print(\"Incorrect Prediction: \", ICP)# 7\n",
    "print(ICP == FP + FN) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033eb3fc",
   "metadata": {
    "id": "VDSmMZ1vikQO"
   },
   "source": [
    "Which will allow us to calculate the Accuracy.\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "and\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcdd79",
   "metadata": {
    "id": "3Eb8LTpuiuco"
   },
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba172497",
   "metadata": {
    "id": "7ZXnX6vyi07Y"
   },
   "source": [
    "Using the Sklearn libraries, we can make similar calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b337b31",
   "metadata": {
    "id": "M68PZsr2i-Gn"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels , predictions)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19ed30",
   "metadata": {
    "id": "Y90giVJijG3E"
   },
   "source": [
    "As we have seen in the lectures, with unbalanced data sets (small number of relevant items in a large set of unrelevant ones, which is often the case in information retrieval), accuracy can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a6e37",
   "metadata": {
    "id": "pbCa13USjVxy"
   },
   "outputs": [],
   "source": [
    "labels = [0,0,0,0,1,0,0,1,0,0]\n",
    "predictions = [0 ,0 ,0 ,0 ,0 , 0 ,0 ,0 ,0 ,0]\n",
    "print(accuracy_score(labels , predictions)*100) # 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48df0b7",
   "metadata": {
    "id": "vClObqI6j6Pk"
   },
   "source": [
    "Let's recalculate TP, TN, FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c253b7c",
   "metadata": {
    "id": "t1VeXaR5j-bu"
   },
   "outputs": [],
   "source": [
    "TP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i] and labels[i] == 1:\n",
    "       TP+=1\n",
    "print(\"True Positive: \", TP) # 3\n",
    "FP = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == 0 and predictions[i] == 1:\n",
    "       FP+=1\n",
    "print(\"False Positive: \", FP) # 3\n",
    "TN = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i] and labels[i] == 0:\n",
    "       TN+=1\n",
    "print(\"True Negative: \", TN) # 0\n",
    "FN = 0\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == 1 and predictions[i] == 0:\n",
    "       FN+=1\n",
    "print(\"False Negative: \", FN) # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdb9a6",
   "metadata": {
    "id": "UspexWnKjb59"
   },
   "source": [
    "Looking at Recall gives us and Precision cannot be calculated (div 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60450e94",
   "metadata": {
    "id": "o_TDiOX1jeYk"
   },
   "outputs": [],
   "source": [
    "recall = (TP)/(TP+FN)\n",
    "print(recall*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c6f1a",
   "metadata": {
    "id": "EN165oUskdhh"
   },
   "source": [
    "But a high recall may also be misleading as precision is reverse-proportional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5d5ac",
   "metadata": {
    "id": "3v25fhVBkf76"
   },
   "outputs": [],
   "source": [
    "labels = [0,0,0,0,1,0,0,1,0,0]\n",
    "predictions = [1,1,1,1,1,1,1,1,1,1]\n",
    "print(accuracy_score(labels , predictions)*100)\n",
    "print(recall_score(labels , predictions)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d26d8",
   "metadata": {
    "id": "GdBQPoobni0t"
   },
   "source": [
    "# Exersize 1:\n",
    "\n",
    "a. Why is accuracy not a good measurement in information retrieval and text-mining?\n",
    "\n",
    "b. Why do we need to look at the combination of precision and recall?\n",
    "\n",
    "c.\tWhy is the 11-point precision-recall graph the best method. Explain how it works with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e940e5c",
   "metadata": {
    "id": "AXU9csafpj3p"
   },
   "source": [
    "## YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e77e25",
   "metadata": {
    "id": "fQ3G9W5ikptK"
   },
   "source": [
    "This is why we also look at F1 scores and 11 points precision recall graphs. These provide a more balanced view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf9bfe",
   "metadata": {
    "id": "fCvssuR2kZLz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcae70a",
   "metadata": {
    "id": "SERzQ5sAprhf"
   },
   "source": [
    "# Exersize 2:\n",
    "\n",
    "1. Can you calculate the F2 score or the F0.5 score?\n",
    "\n",
    "2. Which one prevails recall and which one prevails precision\n",
    "\n",
    "3. What would a lawyer be mostly interested in: F1, F2 or F0.5?\n",
    "\n",
    "4. How about a consumer using Google to find a good hotel in Maastricht?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf00ac",
   "metadata": {
    "id": "E6FCxuMop-x8"
   },
   "source": [
    "## YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27713b6b",
   "metadata": {
    "id": "13hqDlU9k0vs"
   },
   "source": [
    "How about Confusion Matrices? A confusion matrix is a matrix to represent the number of True Positives, False Positives, True Negatives, and False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bb28b",
   "metadata": {
    "id": "NJbvmsG6k57U"
   },
   "outputs": [],
   "source": [
    "# Actual Value\n",
    "labels = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "# Predicted Value\n",
    "predictions = [0, 0, 1, 1, 1, 0, 1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a27b4",
   "metadata": {
    "id": "jAXwECYbk9BD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(labels, predictions)\n",
    "FN = confusion[1][0]\n",
    "TN = confusion[0][0]\n",
    "TP = confusion[1][1]\n",
    "FP = confusion[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee235c50",
   "metadata": {
    "id": "iuq80Oy4lcWe"
   },
   "source": [
    "Plot as bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e2811",
   "metadata": {
    "id": "dclfG1i6k_2M"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['False Negative' , 'True Negative' , 'True Positive' , 'False Positive'],[FN,TN,TP,FP])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8768e3",
   "metadata": {
    "id": "G27PA694lfzq"
   },
   "source": [
    "Plot as heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa911bdf",
   "metadata": {
    "id": "w9fVSV_LlRYt"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion , annot=True , xticklabels=['Negative' , 'Positive'] , yticklabels=['Negative' , 'Positive'])\n",
    "plt.ylabel(\"Label\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33009de8",
   "metadata": {
    "id": "NCPWeagtlip2"
   },
   "source": [
    "Display as Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5de393",
   "metadata": {
    "id": "xmZQvQG-lUoO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Labels' : labels, 'Predictions': predictions}\n",
    "df = pd.DataFrame(data, columns=['Labels','Predictions'])\n",
    "confusion_matrix = pd.crosstab(df['Labels'], df['Predictions'], rownames=['Labels'], colnames=['Predictions'])\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c714f",
   "metadata": {
    "id": "1-S6uwnUlp2x"
   },
   "source": [
    "Or display as Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db311d",
   "metadata": {
    "id": "yHh-H6JPlXvG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc400e",
   "metadata": {
    "id": "xwjnj31klzYN"
   },
   "source": [
    "or a precision recall graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84c5b5",
   "metadata": {
    "id": "heRAXsHQl31H"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "print(precision_recall_curve(labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfa69e",
   "metadata": {
    "id": "kASP4xfgHsGh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "PrecisionRecallDisplay.from_predictions(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc50be",
   "metadata": {
    "id": "mh4QSxikrne3"
   },
   "source": [
    "Now this is a pretty bad score. For better classifiers, the graph should be as much as possible in the upper right corner and above 80% precision and recall for all data points.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36f2f6",
   "metadata": {
    "id": "5ABHHvRxqKbQ"
   },
   "source": [
    "# The Kappa Cohen Distance\n",
    "\n",
    "Cohen's kappa coefficient (Œ∫, lowercase Greek kappa) is a statistic that is used to measure inter-rater reliability (and also intra-rater reliability) for qualitative (categorical) items. It is generally thought to be a more robust measure than simple percent agreement calculation, as Œ∫ takes into account the possibility of the agreement occurring by chance.\n",
    "\n",
    "Although there is controversie about this measure, it is a good first start. If the Kappa-Cohen distance is not good, you should be concerned. If it is good, there arfe more detailed analysis to do further investigations towards label disagreement in data sets.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2c471",
   "metadata": {
    "id": "m1w48NCqqKSA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22179305",
   "metadata": {
    "id": "jL8vAzSNpOBS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#define array of ratings for both raters\n",
    "rater1 = [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "rater2 = [0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "#calculate Cohen's Kappa\n",
    "cohen_kappa_score(rater1, rater2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3972e",
   "metadata": {
    "id": "jwvndhg1r9lr"
   },
   "source": [
    "So, obviously, this is not a good data set. One can best discuss the annotations for which the judges had disagreement with the judges to see if there is any misunderstanding or bias involved in their decisions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d519056a",
   "metadata": {
    "id": "Vqdp7-KnOugL"
   },
   "source": [
    "# Exercise 3: Kappa-Cohen Score\n",
    "\n",
    "a. Why is Cohen‚Äôs Kappa important in NLP tasks such as sentiment analysis or named entity recognition?\n",
    "\n",
    "b. What steps should be taken if Cohen‚Äôs Kappa is too low in an annotation task?\n",
    "\n",
    "c. When designing an annotation task, what strategies can improve inter-rater reliability?\n",
    "\n",
    "d. Discuss how Cohen‚Äôs Kappa might be affected in a dataset where one class is dominant (e.g., 90% of the data belongs to one category).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58bcdd",
   "metadata": {
    "id": "bBamJ69fTENU"
   },
   "source": [
    "# Submission\n",
    "When you have completed all exercises, download this notebook and submit it via Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72905882",
   "metadata": {},
   "source": [
    "# Clustering and Topic Modeling Metrics\n",
    "\n",
    "When we cluster documents or extract topics, we need metrics to evaluate quality. These fall into two categories:\n",
    "\n",
    "- **Extrinsic (clustering quality)**: require ground-truth labels ‚Äî **Purity** and **Rand Index**\n",
    "- **Intrinsic (topic quality)**: evaluate topics without labels ‚Äî **Coherence scores** (UMass, C_V, PMI, NPMI)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Purity\n",
    "\n",
    "**Purity** measures how homogeneous each cluster is. For each cluster, we find the most frequent ground-truth class and count how many items belong to it.\n",
    "\n",
    "$$\\text{Purity}(\\Omega, \\mathbb{C}) = \\frac{1}{N} \\sum_{k=1}^{K} \\max_{j} |  \\omega_k \\cap c_j |$$\n",
    "\n",
    "where:\n",
    "- $N$ = total number of data points\n",
    "- $\\Omega = \\{\\omega_1, \\ldots, \\omega_K\\}$ = set of clusters\n",
    "- $\\mathbb{C} = \\{c_1, \\ldots, c_J\\}$ = set of ground-truth classes\n",
    "- $|\\omega_k \\cap c_j|$ = number of items in cluster $k$ that belong to class $j$\n",
    "\n",
    "**Interpretation**: Purity ranges from $0$ to $1$. A purity of $1$ means every cluster contains only items from a single class.\n",
    "\n",
    "**Limitation**: Purity always increases with the number of clusters ‚Äî if every document is its own cluster, purity = 1. Therefore, purity alone is not sufficient; it should be paired with another metric.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Rand Index (RI)\n",
    "\n",
    "The **Rand Index** measures agreement between the clustering and the ground truth by considering all *pairs* of data points.\n",
    "\n",
    "For every pair of data points $(x_i, x_j)$, there are four possibilities:\n",
    "\n",
    "| | Same cluster | Different clusters |\n",
    "|---|---|---|\n",
    "| **Same class** | $TP$ (True Positive) | $FN$ (False Negative) |\n",
    "| **Different class** | $FP$ (False Positive) | $TN$ (True Negative) |\n",
    "\n",
    "$$\\text{RI} = \\frac{TP + TN}{TP + FP + FN + TN} = \\frac{TP + TN}{\\binom{N}{2}}$$\n",
    "\n",
    "where $\\binom{N}{2}$ is the total number of pairs.\n",
    "\n",
    "**Interpretation**: RI ranges from $0$ to $1$. A value of $1$ means the clustering perfectly matches the ground truth.\n",
    "\n",
    "### Adjusted Rand Index (ARI)\n",
    "\n",
    "The Rand Index can be high by chance, especially with many clusters. The **Adjusted Rand Index** corrects for this:\n",
    "\n",
    "$$\\text{ARI} = \\frac{\\text{RI} - \\mathbb{E}[\\text{RI}]}{\\max(\\text{RI}) - \\mathbb{E}[\\text{RI}]}$$\n",
    "\n",
    "ARI = 0 means random clustering, ARI = 1 means perfect agreement, and ARI < 0 means worse than random.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Topic Coherence Scores\n",
    "\n",
    "Topic models (e.g., LDA) output topics as lists of words. **Coherence** measures whether the top words in a topic are semantically related. Higher coherence ‚Üí more interpretable topics.\n",
    "\n",
    "### 3a. UMass Coherence ($C_{\\text{UMass}}$)\n",
    "\n",
    "UMass coherence uses **document co-occurrence** from the training corpus. For each pair of top words $(w_i, w_j)$ where $w_i$ appears later in the ranked list:\n",
    "\n",
    "$$C_{\\text{UMass}} = \\frac{2}{N(N-1)} \\sum_{i=2}^{N} \\sum_{j=1}^{i-1} \\log \\frac{D(w_i, w_j) + \\epsilon}{D(w_j)}$$\n",
    "\n",
    "where:\n",
    "- $D(w_i, w_j)$ = number of documents containing **both** $w_i$ and $w_j$\n",
    "- $D(w_j)$ = number of documents containing $w_j$\n",
    "- $\\epsilon$ = smoothing constant (typically 1) to avoid $\\log(0)$\n",
    "- $N$ = number of top words per topic\n",
    "\n",
    "**Intuition**: If the top words of a topic frequently co-occur in documents, the topic is coherent. UMass is **intrinsic** ‚Äî it only uses the training corpus.\n",
    "\n",
    "**Range**: $(-\\infty, 0]$. Values closer to 0 are better.\n",
    "\n",
    "### 3b. Pointwise Mutual Information (PMI)\n",
    "\n",
    "**PMI** measures how much more likely two words co-occur than expected by chance:\n",
    "\n",
    "$$\\text{PMI}(w_i, w_j) = \\log \\frac{P(w_i, w_j)}{P(w_i) \\cdot P(w_j)}$$\n",
    "\n",
    "where:\n",
    "- $P(w_i, w_j) = \\frac{D(w_i, w_j)}{D}$ ‚Äî probability that a document contains both words\n",
    "- $P(w_i) = \\frac{D(w_i)}{D}$ ‚Äî probability that a document contains word $w_i$\n",
    "- $D$ = total number of documents\n",
    "\n",
    "**Interpretation**:\n",
    "- PMI > 0: words co-occur **more** than expected\n",
    "- PMI = 0: words are independent\n",
    "- PMI < 0: words co-occur **less** than expected\n",
    "\n",
    "### 3c. Normalized PMI (NPMI)\n",
    "\n",
    "PMI has the problem that its range depends on the probabilities. **NPMI** normalizes it to $[-1, +1]$:\n",
    "\n",
    "$$\\text{NPMI}(w_i, w_j) = \\frac{\\text{PMI}(w_i, w_j)}{-\\log P(w_i, w_j)} = \\frac{\\log \\frac{P(w_i, w_j)}{P(w_i) \\cdot P(w_j)}}{-\\log P(w_i, w_j)}$$\n",
    "\n",
    "**Interpretation**:\n",
    "- NPMI = +1: perfect co-occurrence (words always appear together)\n",
    "- NPMI = 0: independence\n",
    "- NPMI = ‚àí1: words never co-occur\n",
    "\n",
    "NPMI is often preferred over raw PMI because it is comparable across different corpora and vocabulary sizes.\n",
    "\n",
    "### 3d. $C_V$ Coherence\n",
    "\n",
    "$C_V$ is a composite coherence measure that combines four components and was shown by R√∂der et al. (2015) to correlate best with human judgments. It uses:\n",
    "\n",
    "1. **Segmentation**: splits top-$N$ words into word pairs (one-preceding)\n",
    "2. **Probability estimation**: uses a **sliding window** over an external reference corpus to estimate word co-occurrence (unlike UMass which uses full documents)\n",
    "3. **Confirmation measure**: uses **NPMI** to score how well word pairs associate\n",
    "4. **Aggregation**: takes the **arithmetic mean** across all word pairs\n",
    "\n",
    "$$C_V = \\frac{1}{N} \\sum_{i=1}^{N} \\text{NPMI}_{\\text{window}}(w_i, W_{\\setminus i})$$\n",
    "\n",
    "where $W_{\\setminus i}$ represents the set of remaining top words. The sliding window (typically 110 words) captures local co-occurrence patterns.\n",
    "\n",
    "**Range**: $[0, 1]$. Higher is better.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Metric | Type | Range | Better | Requires Labels? |\n",
    "|---|---|---|---|---|\n",
    "| **Purity** | Clustering | $[0, 1]$ | Higher | Yes |\n",
    "| **Rand Index** | Clustering | $[0, 1]$ | Higher | Yes |\n",
    "| **Adjusted Rand Index** | Clustering | $[-1, 1]$ | Higher | Yes |\n",
    "| **UMass** | Topic coherence | $(-\\infty, 0]$ | Closer to 0 | No |\n",
    "| **PMI** | Co-occurrence | $(-\\infty, +\\infty)$ | Higher | No |\n",
    "| **NPMI** | Co-occurrence | $[-1, +1]$ | Higher | No |\n",
    "| **$C_V$** | Topic coherence | $[0, 1]$ | Higher | No |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3168957",
   "metadata": {},
   "source": [
    "## Coding Example: Topic Coherence with NPMI\n",
    "\n",
    "We'll train an **LDA** model on the **20 Newsgroups** dataset and compute the **NPMI coherence** of the discovered topics. We:\n",
    "\n",
    "1. Preprocess the documents (tokenize, remove stopwords)\n",
    "2. Train LDA with different numbers of topics ($K$ = 5, 10, 15, 20)\n",
    "3. Compute NPMI coherence using Gensim's `CoherenceModel` with `coherence='c_npmi'`\n",
    "4. Compare coherence scores to find the optimal number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cf595",
   "metadata": {},
   "source": [
    "Hereunder is an example of calculating theCoherence Score using the normalized PMI. This may take a few minutes to calculate as the LDA takes some time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim --quiet\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Load and preprocess 20 Newsgroups ---\n",
    "print(\"Loading 20 Newsgroups dataset...\")\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Simple preprocessing: lowercase, keep alphabetic tokens, remove short words\n",
    "stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "             'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "             'should', 'may', 'might', 'shall', 'can', 'to', 'of', 'in', 'for',\n",
    "             'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',\n",
    "             'before', 'after', 'above', 'below', 'between', 'out', 'off', 'over',\n",
    "             'under', 'again', 'further', 'then', 'once', 'and', 'but', 'or', 'nor',\n",
    "             'not', 'so', 'no', 'if', 'that', 'this', 'it', 'its', 'he', 'she',\n",
    "             'they', 'we', 'you', 'i', 'me', 'my', 'your', 'his', 'her', 'our',\n",
    "             'their', 'what', 'which', 'who', 'whom', 'where', 'when', 'how', 'all',\n",
    "             'each', 'every', 'both', 'few', 'more', 'most', 'other', 'some', 'such',\n",
    "             'than', 'too', 'very', 'just', 'about', 'also', 'there', 'up', 'one',\n",
    "             'don', 'any', 'only', 'own', 'same', 'get', 'got', 'like', 'know',\n",
    "             'think', 'make', 'well', 'even', 'much', 'many', 'way', 'new', 'used',\n",
    "             'use', 'using', 'really', 'see', 'say', 'said', 'going', 'want', 'come'}\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = re.findall(r'[a-z]+', text.lower())\n",
    "    return [t for t in tokens if len(t) > 2 and t not in stopwords]\n",
    "\n",
    "texts = [preprocess(doc) for doc in newsgroups.data]\n",
    "texts = [t for t in texts if len(t) > 5]  # remove very short docs\n",
    "\n",
    "print(f\"Preprocessed {len(texts)} documents\\n\")\n",
    "\n",
    "# --- 2. Build dictionary and corpus ---\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)  # remove rare/common words\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(f\"Dictionary size: {len(dictionary)} unique tokens\")\n",
    "print(f\"Corpus: {len(corpus)} documents\\n\")\n",
    "\n",
    "# --- 3. Train LDA with different K and compute NPMI coherence ---\n",
    "topic_counts = [5, 10, 15, 20]\n",
    "coherence_scores = {}\n",
    "\n",
    "for k in topic_counts:\n",
    "    print(f\"Training LDA with K={k} topics...\", end=\" \")\n",
    "    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k,\n",
    "                   random_state=42, passes=5, alpha='auto', eta='auto')\n",
    "    \n",
    "    # Compute NPMI coherence\n",
    "    cm = CoherenceModel(model=lda, texts=texts, dictionary=dictionary, coherence='c_npmi')\n",
    "    score = cm.get_coherence()\n",
    "    coherence_scores[k] = score\n",
    "    print(f\"NPMI Coherence = {score:.4f}\")\n",
    "    \n",
    "    # Show top words for each topic\n",
    "    if k == 10:  # Show details for K=10 as example\n",
    "        print(f\"\\n  Top words per topic (K={k}):\")\n",
    "        for idx, topic in lda.print_topics(num_words=8):\n",
    "            print(f\"    Topic {idx}: {topic}\")\n",
    "        print()\n",
    "\n",
    "# --- 4. Plot coherence vs number of topics ---\n",
    "print(\"\\n--- Summary ---\")\n",
    "for k, s in coherence_scores.items():\n",
    "    print(f\"  K={k:2d} topics ‚Üí NPMI Coherence: {s:.4f}\")\n",
    "\n",
    "best_k = max(coherence_scores, key=coherence_scores.get)\n",
    "print(f\"\\nBest number of topics: K={best_k} (highest NPMI = {coherence_scores[best_k]:.4f})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(list(coherence_scores.keys()), list(coherence_scores.values()), 'bo-', linewidth=2)\n",
    "ax.set_xlabel(\"Number of Topics (K)\")\n",
    "ax.set_ylabel(\"NPMI Coherence Score\")\n",
    "ax.set_title(\"Topic Coherence (NPMI) vs. Number of Topics ‚Äî LDA on 20 Newsgroups\")\n",
    "ax.set_xticks(topic_counts)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHigher NPMI ‚Üí top words in each topic co-occur more frequently ‚Üí more interpretable topics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51035ca1",
   "metadata": {},
   "source": [
    "# The Quality of a Summary: ROUGE\n",
    "\n",
    "**ROUGE** (Recall-Oriented Understudy for Gisting Evaluation) is a family of metrics used to evaluate the quality of **text summaries** by comparing them to one or more human-written **reference summaries**. ROUGE was introduced by Chin-Yew Lin (2004) and is the standard metric for summarization tasks.\n",
    "\n",
    "The key idea: count how many **n-grams** (or subsequences) in the reference summary also appear in the candidate (system-generated) summary.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ROUGE-N\n",
    "\n",
    "**ROUGE-N** measures the overlap of **n-grams** between the candidate summary and the reference summary.\n",
    "\n",
    "### ROUGE-N Recall\n",
    "\n",
    "How much of the reference is captured by the candidate?\n",
    "\n",
    "$$\\text{ROUGE-N}_{\\text{Recall}} = \\frac{\\sum_{s \\in \\text{Ref}} \\sum_{\\text{n-gram} \\in s} \\text{Count}_{\\text{match}}(\\text{n-gram})}{\\sum_{s \\in \\text{Ref}} \\sum_{\\text{n-gram} \\in s} \\text{Count}(\\text{n-gram})}$$\n",
    "\n",
    "**Intuition**: Of all n-grams in the reference, what fraction also appears in the candidate?\n",
    "\n",
    "### ROUGE-N Precision\n",
    "\n",
    "How much of the candidate is relevant?\n",
    "\n",
    "$$\\text{ROUGE-N}_{\\text{Precision}} = \\frac{\\sum_{s \\in \\text{Cand}} \\sum_{\\text{n-gram} \\in s} \\text{Count}_{\\text{match}}(\\text{n-gram})}{\\sum_{s \\in \\text{Cand}} \\sum_{\\text{n-gram} \\in s} \\text{Count}(\\text{n-gram})}$$\n",
    "\n",
    "**Intuition**: Of all n-grams in the candidate, what fraction also appears in the reference?\n",
    "\n",
    "### ROUGE-N F1\n",
    "\n",
    "The harmonic mean of precision and recall:\n",
    "\n",
    "$$\\text{ROUGE-N}_{F_1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "### Common Variants\n",
    "\n",
    "- **ROUGE-1**: unigram overlap ‚Äî captures word-level coverage\n",
    "- **ROUGE-2**: bigram overlap ‚Äî captures some word ordering and fluency\n",
    "\n",
    "**Example**:\n",
    "- Reference: *\"The cat sat on the mat\"*\n",
    "- Candidate: *\"The cat is on the mat\"*\n",
    "- ROUGE-1 Recall: 5 matching unigrams (*the, cat, on, the, mat*) out of 6 reference unigrams = $\\frac{5}{6} = 0.83$\n",
    "- ROUGE-2 Recall: 2 matching bigrams (*the cat, the mat*) out of 5 reference bigrams = $\\frac{2}{5} = 0.40$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ROUGE-L (Longest Common Subsequence)\n",
    "\n",
    "**ROUGE-L** uses the **Longest Common Subsequence (LCS)** between the candidate and reference. Unlike n-grams, LCS does **not** require consecutive matches ‚Äî it captures the longest sequence of words that appear in the same order in both texts.\n",
    "\n",
    "Given:\n",
    "- $X$ = reference of length $m$\n",
    "- $Y$ = candidate of length $n$\n",
    "- $\\text{LCS}(X, Y)$ = length of the longest common subsequence\n",
    "\n",
    "$$\\text{ROUGE-L}_{\\text{Recall}} = \\frac{\\text{LCS}(X, Y)}{m}$$\n",
    "\n",
    "$$\\text{ROUGE-L}_{\\text{Precision}} = \\frac{\\text{LCS}(X, Y)}{n}$$\n",
    "\n",
    "$$\\text{ROUGE-L}_{F_1} = \\frac{(1 + \\beta^2) \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Recall} + \\beta^2 \\cdot \\text{Precision}}$$\n",
    "\n",
    "where $\\beta = \\frac{\\text{Precision}}{\\text{Recall}}$ (typically $\\beta = 1$, giving the standard F1).\n",
    "\n",
    "**Advantage of ROUGE-L**: It captures sentence-level word ordering without requiring exact n-gram matches, making it more flexible than ROUGE-N.\n",
    "\n",
    "**Example**:\n",
    "- Reference: *\"The cat sat on the mat\"*\n",
    "- Candidate: *\"The cat is sitting on the mat\"*\n",
    "- LCS = *\"The cat on the mat\"* ‚Üí length 5\n",
    "- ROUGE-L Recall = $\\frac{5}{6} = 0.83$\n",
    "- ROUGE-L Precision = $\\frac{5}{7} = 0.71$\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Metric | What it measures | Strengths | Weaknesses |\n",
    "|---|---|---|---|\n",
    "| **ROUGE-1** | Unigram overlap | Good for content coverage | Ignores word order |\n",
    "| **ROUGE-2** | Bigram overlap | Captures some fluency | Stricter, lower scores |\n",
    "| **ROUGE-L** | Longest common subsequence | Captures word order flexibly | May miss local matches |\n",
    "| **Precision** | How much of candidate is relevant | Penalizes verbose summaries | Ignores missing content |\n",
    "| **Recall** | How much of reference is captured | Penalizes short summaries | Ignores irrelevant content |\n",
    "| **F1** | Balance of precision & recall | Best single-number metric | Requires both P and R |\n",
    "\n",
    "> **Note**: ROUGE only measures **lexical overlap**. Two summaries can convey the same meaning with different words and get a low ROUGE score. For semantic similarity, newer metrics like **BERTScore** are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5ad7f",
   "metadata": {},
   "source": [
    "## Coding Example: ROUGE on the CNN/Daily Mail Dataset\n",
    "\n",
    "The **CNN/Daily Mail** dataset is the standard benchmark for abstractive summarization. It contains news articles paired with human-written summary bullet points (\"highlights\").\n",
    "\n",
    "We will:\n",
    "1. Load a few articles from the dataset\n",
    "2. Generate a simple **extractive baseline** summary (first 3 sentences) to compare against the reference\n",
    "3. Compute **ROUGE-1, ROUGE-2, and ROUGE-L** (Precision, Recall, F1) for each article\n",
    "4. Show how ROUGE scores differ between a good and a poor summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rouge-score datasets --quiet\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# --- 1. Load a small sample from CNN/Daily Mail ---\n",
    "print(\"Loading CNN/Daily Mail dataset (test split, first 5 articles)...\")\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:5]\")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} articles.\\n\")\n",
    "\n",
    "# --- 2. Set up ROUGE scorer ---\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# --- 3. Simple extractive baseline: take the first 3 sentences ---\n",
    "def extractive_baseline(article, n_sentences=3):\n",
    "    \"\"\"Extract the first n sentences as a simple summary.\"\"\"\n",
    "    sentences = article.split('. ')\n",
    "    return '. '.join(sentences[:n_sentences]) + '.'\n",
    "\n",
    "# --- 4. Compute ROUGE scores for each article ---\n",
    "results = []\n",
    "\n",
    "for i, example in enumerate(dataset):\n",
    "    article = example['article']\n",
    "    reference = example['highlights']  # human-written summary\n",
    "    candidate = extractive_baseline(article)\n",
    "    \n",
    "    scores = scorer.score(reference, candidate)\n",
    "    \n",
    "    results.append({\n",
    "        'Article': i + 1,\n",
    "        'ROUGE-1 P': scores['rouge1'].precision,\n",
    "        'ROUGE-1 R': scores['rouge1'].recall,\n",
    "        'ROUGE-1 F1': scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2 P': scores['rouge2'].precision,\n",
    "        'ROUGE-2 R': scores['rouge2'].recall,\n",
    "        'ROUGE-2 F1': scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L P': scores['rougeL'].precision,\n",
    "        'ROUGE-L R': scores['rougeL'].recall,\n",
    "        'ROUGE-L F1': scores['rougeL'].fmeasure,\n",
    "    })\n",
    "    \n",
    "    # Show details for the first article\n",
    "    if i == 0:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"EXAMPLE: Article 1\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nüì∞ Article (first 500 chars):\\n{textwrap.fill(article[:500], width=80)}...\\n\")\n",
    "        print(f\"üìù Reference summary:\\n{textwrap.fill(reference, width=80)}\\n\")\n",
    "        print(f\"ü§ñ Extractive baseline (first 3 sentences):\\n{textwrap.fill(candidate[:300], width=80)}...\\n\")\n",
    "        print(f\"ROUGE Scores:\")\n",
    "        print(f\"  ROUGE-1: Precision={scores['rouge1'].precision:.4f}  \"\n",
    "              f\"Recall={scores['rouge1'].recall:.4f}  F1={scores['rouge1'].fmeasure:.4f}\")\n",
    "        print(f\"  ROUGE-2: Precision={scores['rouge2'].precision:.4f}  \"\n",
    "              f\"Recall={scores['rouge2'].recall:.4f}  F1={scores['rouge2'].fmeasure:.4f}\")\n",
    "        print(f\"  ROUGE-L: Precision={scores['rougeL'].precision:.4f}  \"\n",
    "              f\"Recall={scores['rougeL'].recall:.4f}  F1={scores['rougeL'].fmeasure:.4f}\")\n",
    "        print()\n",
    "\n",
    "# --- 5. Summary table ---\n",
    "df_rouge = pd.DataFrame(results)\n",
    "print(\"\\n--- ROUGE Scores Across All Articles ---\\n\")\n",
    "print(df_rouge.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "# Average scores\n",
    "print(\"\\n--- Average ROUGE Scores (extractive baseline) ---\")\n",
    "for col in ['ROUGE-1 F1', 'ROUGE-2 F1', 'ROUGE-L F1']:\n",
    "    print(f\"  {col}: {df_rouge[col].mean():.4f}\")\n",
    "\n",
    "# --- 6. Compare good vs bad summary ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON: Good vs. Bad Summary for Article 1\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "reference = dataset[0]['highlights']\n",
    "good_summary = extractive_baseline(dataset[0]['article'], n_sentences=3)\n",
    "bad_summary = \"The weather was nice today. I like pizza. Football is a great sport.\"\n",
    "\n",
    "good_scores = scorer.score(reference, good_summary)\n",
    "bad_scores = scorer.score(reference, bad_summary)\n",
    "\n",
    "print(f\"\\n‚úÖ Extractive summary ROUGE-1 F1: {good_scores['rouge1'].fmeasure:.4f}\")\n",
    "print(f\"   ROUGE-2 F1: {good_scores['rouge2'].fmeasure:.4f}\")\n",
    "print(f\"   ROUGE-L F1: {good_scores['rougeL'].fmeasure:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ùå Irrelevant summary ROUGE-1 F1: {bad_scores['rouge1'].fmeasure:.4f}\")\n",
    "print(f\"   ROUGE-2 F1: {bad_scores['rouge2'].fmeasure:.4f}\")\n",
    "print(f\"   ROUGE-L F1: {bad_scores['rougeL'].fmeasure:.4f}\")\n",
    "\n",
    "print(\"\\nAs expected, the irrelevant summary scores near zero on all ROUGE metrics,\")\n",
    "print(\"while the extractive baseline captures some of the reference content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60791d06",
   "metadata": {},
   "source": [
    "# Perplexity: The Quality of a Language Model\n",
    "\n",
    "## What is Perplexity?\n",
    "\n",
    "**Perplexity** is the standard intrinsic evaluation metric for language models. It measures how \"surprised\" or \"confused\" a language model is when it sees a sequence of words. A **lower perplexity** means the model is better at predicting the next word ‚Äî i.e., the model assigns higher probabilities to the words that actually appear in the text.\n",
    "\n",
    "Intuitively, perplexity can be thought of as the **weighted average number of choices** the model is uncertain between when predicting the next token. A perplexity of 10 means the model is, on average, as uncertain as if it had to choose uniformly among 10 equally likely words at each step.\n",
    "\n",
    "## Where Does Perplexity Come From? The Intuition\n",
    "\n",
    "Perplexity is rooted in **information theory**, specifically in the concepts of **entropy** and **cross-entropy**.\n",
    "\n",
    "### Step 1: Probability of a Sequence\n",
    "\n",
    "A language model assigns a probability to a sequence of words $W = w_1, w_2, \\ldots, w_N$. Using the chain rule of probability:\n",
    "\n",
    "$$P(W) = P(w_1) \\cdot P(w_2 | w_1) \\cdot P(w_3 | w_1, w_2) \\cdots P(w_N | w_1, \\ldots, w_{N-1}) = \\prod_{i=1}^{N} P(w_i | w_1, \\ldots, w_{i-1})$$\n",
    "\n",
    "A good language model will assign a **high probability** to text that is natural and grammatical.\n",
    "\n",
    "### Step 2: From Probability to Entropy\n",
    "\n",
    "The **entropy** $H$ of a language model measures the average amount of information (in bits) needed to encode each word. For a sequence of $N$ words:\n",
    "\n",
    "$$H(W) = -\\frac{1}{N} \\log_2 P(W) = -\\frac{1}{N} \\sum_{i=1}^{N} \\log_2 P(w_i | w_1, \\ldots, w_{i-1})$$\n",
    "\n",
    "Entropy tells us: on average, how many bits of information does each word carry according to the model? Lower entropy means the model is more confident in its predictions.\n",
    "\n",
    "### Step 3: From Entropy to Perplexity\n",
    "\n",
    "**Perplexity** is simply $2$ raised to the power of the entropy:\n",
    "\n",
    "$$\\text{PP}(W) = 2^{H(W)} = 2^{-\\frac{1}{N} \\sum_{i=1}^{N} \\log_2 P(w_i | w_1, \\ldots, w_{i-1})}$$\n",
    "\n",
    "Equivalently, using natural logarithms (as is common in practice):\n",
    "\n",
    "$$\\text{PP}(W) = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\ln P(w_i | w_1, \\ldots, w_{i-1})\\right)$$\n",
    "\n",
    "Or expressed directly in terms of the sequence probability:\n",
    "\n",
    "$$\\text{PP}(W) = P(w_1, w_2, \\ldots, w_N)^{-\\frac{1}{N}} = \\sqrt[N]{\\frac{1}{P(w_1, w_2, \\ldots, w_N)}}$$\n",
    "\n",
    "This is the **inverse probability of the sequence**, normalized by the sequence length (the geometric mean of the inverse probabilities).\n",
    "\n",
    "## Summary of Key Relationships\n",
    "\n",
    "| Concept | Formula | Interpretation |\n",
    "|---|---|---|\n",
    "| **Sequence Probability** | $P(W) = \\prod_{i=1}^{N} P(w_i \\mid w_{< i})$ | How likely is this text? |\n",
    "| **Cross-Entropy** | $H = -\\frac{1}{N} \\sum \\log_2 P(w_i \\mid w_{< i})$ | Avg. bits per word |\n",
    "| **Perplexity** | $\\text{PP} = 2^{H}$ | Effective vocabulary size the model is choosing from |\n",
    "\n",
    "## Practical Interpretation\n",
    "\n",
    "- **Perplexity = 1**: The model perfectly predicts every next word (impossible in practice for natural language).\n",
    "- **Perplexity = V** (vocabulary size): The model is no better than random guessing among all words.\n",
    "- **Typical values**: Modern large language models achieve perplexities in the range of 10‚Äì30 on standard benchmarks like Penn Treebank or WikiText.\n",
    "\n",
    "## When to Use Perplexity\n",
    "\n",
    "- Comparing different **language models** on the same test set (lower is better).\n",
    "- Evaluating the impact of **model size**, **training data**, or **architecture** changes.\n",
    "- **Limitation**: Perplexity only measures how well the model predicts text ‚Äî it does **not** directly measure the quality of generated text for downstream tasks like summarization or dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad188ca",
   "metadata": {},
   "source": [
    "## Comparing Perplexity Across Language Models\n",
    "\n",
    "We will now compute perplexity using three increasingly sophisticated models to show how perplexity improves:\n",
    "\n",
    "1. **Trigram Model** ‚Äî a simple n-gram model that predicts the next word based on the previous 2 words\n",
    "2. **HMM-based Model** ‚Äî a Hidden Markov Model using POS tags as hidden states and words as observations\n",
    "3. **GPT-2** ‚Äî a pre-trained transformer language model\n",
    "\n",
    "We will test on both **human-written** sentences and **GPT-generated** text to observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16411128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk transformers torch --quiet\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"All packages installed and data downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d5b47",
   "metadata": {},
   "source": [
    "We define a set of test sentences. Some are **human-written**, and one is **GPT-generated** ‚Äî a fluent but somewhat verbose and formal sentence typical of large language model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentences: human-written and GPT-generated\n",
    "test_sentences = {\n",
    "    \"Human 1\": \"The cat sat on the mat and watched the birds outside the window\",\n",
    "    \"Human 2\": \"Students learn best when they can apply theory to real world problems\",\n",
    "    \"Human 3\": \"I went to the store to buy some milk and bread\",\n",
    "    \"GPT-generated\": \"The implementation of transformer-based architectures has fundamentally revolutionized \"\n",
    "                     \"the paradigm of natural language processing by enabling models to capture long-range \"\n",
    "                     \"dependencies through self-attention mechanisms that operate in parallel across all positions \"\n",
    "                     \"in the input sequence\",\n",
    "    \"Nonsense\": \"Colorless green ideas sleep furiously above the singing cheese of tomorrow\",\n",
    "}\n",
    "\n",
    "for name, sent in test_sentences.items():\n",
    "    print(f\"{name:15s}: {sent}\")\n",
    "\n",
    "print(f\"\\nWe will compute perplexity for each sentence using three different models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9c5bc",
   "metadata": {},
   "source": [
    "### 1. Trigram Language Model\n",
    "\n",
    "A **trigram model** predicts the next word using the previous 2 words: $P(w_i | w_{i-2}, w_{i-1})$.\n",
    "\n",
    "We train it on the **Brown corpus** (about 1 million words of American English) using **Laplace (add-1) smoothing** to handle unseen trigrams. This is one of the simplest language models ‚Äî we expect relatively high perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Train a trigram model on the Brown corpus\n",
    "train_sents = brown.sents()\n",
    "n = 3  # trigram\n",
    "\n",
    "train_data, padded_vocab = padded_everygram_pipeline(n, train_sents)\n",
    "trigram_model = Laplace(n)\n",
    "trigram_model.fit(train_data, padded_vocab)\n",
    "\n",
    "print(f\"Trigram model trained on {len(train_sents)} sentences from the Brown corpus.\")\n",
    "print(f\"Vocabulary size: {len(trigram_model.vocab)}\\n\")\n",
    "\n",
    "# Compute perplexity for each test sentence\n",
    "trigram_results = {}\n",
    "for name, sent in test_sentences.items():\n",
    "    tokens = sent.lower().split()\n",
    "    pp = trigram_model.perplexity(tokens)\n",
    "    trigram_results[name] = pp\n",
    "    print(f\"  {name:15s} ‚Üí Perplexity: {pp:>10.2f}\")\n",
    "\n",
    "print(\"\\nNote: Laplace smoothing produces high perplexity values because it spreads\")\n",
    "print(\"probability mass over the entire vocabulary for unseen n-grams.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6568f",
   "metadata": {},
   "source": [
    "### 2. HMM-based Language Model\n",
    "\n",
    "A **Hidden Markov Model (HMM)** introduces hidden states ‚Äî here we use **Part-of-Speech (POS) tags** as the hidden states and words as the observations. The model learns:\n",
    "\n",
    "- **Transition probabilities**: $P(\\text{POS}_i | \\text{POS}_{i-1})$ ‚Äî how likely one POS tag follows another\n",
    "- **Emission probabilities**: $P(\\text{word} | \\text{POS})$ ‚Äî how likely a word is given its POS tag\n",
    "\n",
    "To compute the probability of a sentence, we use the **forward algorithm** which sums over all possible hidden state (POS tag) sequences. The HMM captures syntactic structure that a simple trigram model misses, so we expect somewhat better (lower) perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# --- Train HMM from POS-tagged Brown corpus ---\n",
    "tagged_sents = brown.tagged_sents(tagset='universal')\n",
    "print(f\"Training HMM on {len(tagged_sents)} POS-tagged sentences...\\n\")\n",
    "\n",
    "# Collect counts\n",
    "tag_counts = defaultdict(int)\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "start_counts = defaultdict(int)\n",
    "\n",
    "for sent in tagged_sents:\n",
    "    prev_tag = None\n",
    "    for i, (word, tag) in enumerate(sent):\n",
    "        word = word.lower()\n",
    "        tag_counts[tag] += 1\n",
    "        emission_counts[tag][word] += 1\n",
    "        if i == 0:\n",
    "            start_counts[tag] += 1\n",
    "        if prev_tag is not None:\n",
    "            transition_counts[prev_tag][tag] += 1\n",
    "        prev_tag = tag\n",
    "\n",
    "tags = list(tag_counts.keys())\n",
    "tag_to_idx = {t: i for i, t in enumerate(tags)}\n",
    "n_tags = len(tags)\n",
    "total_sents = len(tagged_sents)\n",
    "\n",
    "# Vocabulary for smoothing\n",
    "all_words = set()\n",
    "for tag in emission_counts:\n",
    "    all_words.update(emission_counts[tag].keys())\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "# Build probability matrices with Laplace smoothing\n",
    "start_prob = np.array([(start_counts[t] + 1) / (total_sents + n_tags) for t in tags])\n",
    "trans_prob = np.zeros((n_tags, n_tags))\n",
    "for i, t1 in enumerate(tags):\n",
    "    total = sum(transition_counts[t1].values()) + n_tags\n",
    "    for j, t2 in enumerate(tags):\n",
    "        trans_prob[i, j] = (transition_counts[t1][t2] + 1) / total\n",
    "\n",
    "def emission_prob(tag, word):\n",
    "    \"\"\"P(word | tag) with Laplace smoothing.\"\"\"\n",
    "    tag_total = tag_counts[tag] + vocab_size\n",
    "    return (emission_counts[tag].get(word, 0) + 1) / tag_total\n",
    "\n",
    "# --- Forward algorithm to compute P(sentence) ---\n",
    "def hmm_sentence_log_prob(sentence_tokens):\n",
    "    \"\"\"Compute log P(sentence) by marginalizing over all POS tag sequences.\"\"\"\n",
    "    T = len(sentence_tokens)\n",
    "    # Forward variable: alpha[t, j] = P(w_1..w_t, state_t = j)\n",
    "    alpha = np.zeros((T, n_tags))\n",
    "    \n",
    "    # Initialization\n",
    "    word = sentence_tokens[0]\n",
    "    for j in range(n_tags):\n",
    "        alpha[0, j] = start_prob[j] * emission_prob(tags[j], word)\n",
    "    \n",
    "    # Induction\n",
    "    for t in range(1, T):\n",
    "        word = sentence_tokens[t]\n",
    "        for j in range(n_tags):\n",
    "            alpha[t, j] = np.sum(alpha[t-1, :] * trans_prob[:, j]) * emission_prob(tags[j], word)\n",
    "        # Scale to prevent underflow\n",
    "        scale = np.sum(alpha[t, :])\n",
    "        if scale > 0:\n",
    "            alpha[t, :] /= scale\n",
    "    \n",
    "    # Use log-sum-exp for numerical stability\n",
    "    log_prob = 0\n",
    "    word = sentence_tokens[0]\n",
    "    log_alpha = np.log(np.array([start_prob[j] * emission_prob(tags[j], word) for j in range(n_tags)]) + 1e-300)\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        word = sentence_tokens[t]\n",
    "        new_log_alpha = np.zeros(n_tags)\n",
    "        for j in range(n_tags):\n",
    "            emit = emission_prob(tags[j], word)\n",
    "            log_vals = log_alpha + np.log(trans_prob[:, j] + 1e-300)\n",
    "            max_val = np.max(log_vals)\n",
    "            new_log_alpha[j] = max_val + np.log(np.sum(np.exp(log_vals - max_val))) + np.log(emit + 1e-300)\n",
    "        log_alpha = new_log_alpha\n",
    "    \n",
    "    total_log_prob = np.max(log_alpha) + np.log(np.sum(np.exp(log_alpha - np.max(log_alpha))))\n",
    "    return total_log_prob\n",
    "\n",
    "# Compute perplexity for each test sentence\n",
    "hmm_results = {}\n",
    "for name, sent in test_sentences.items():\n",
    "    tokens = sent.lower().split()\n",
    "    log_prob = hmm_sentence_log_prob(tokens)\n",
    "    N = len(tokens)\n",
    "    # Perplexity = exp(-1/N * log P(W))\n",
    "    pp = np.exp(-log_prob / N)\n",
    "    hmm_results[name] = pp\n",
    "    print(f\"  {name:15s} ‚Üí Perplexity: {pp:>10.2f}\")\n",
    "\n",
    "print(\"\\nThe HMM captures syntactic patterns through POS transitions,\")\n",
    "print(\"which helps it assign better probabilities to grammatical sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d523d4d",
   "metadata": {},
   "source": [
    "### 3. GPT-2: Perplexity of Human vs. GPT-Generated Text\n",
    "\n",
    "**GPT-2** is a transformer-based language model pre-trained on a massive web corpus. We use the pre-trained model to compute perplexity ‚Äî we do **not** retrain it.\n",
    "\n",
    "An interesting experiment: we include a sentence that was **generated by a GPT model**. Since GPT-2 and GPT share similar training data distributions, GPT-2 should assign relatively **low perplexity** (high probability) to GPT-generated text compared to unusual or nonsensical sentences.\n",
    "\n",
    "> **Note**: The first run will download the GPT-2 model (~500 MB). This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0014d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"GPT-2 loaded: {sum(p.numel() for p in model.parameters()) / 1e6:.0f}M parameters\\n\")\n",
    "\n",
    "def gpt2_perplexity(text):\n",
    "    \"\"\"Compute perplexity of a text string using GPT-2.\"\"\"\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = encodings.input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        # outputs.loss is the average negative log-likelihood per token\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    perplexity = torch.exp(neg_log_likelihood).item()\n",
    "    return perplexity\n",
    "\n",
    "# Compute perplexity for each test sentence\n",
    "gpt2_results = {}\n",
    "for name, sent in test_sentences.items():\n",
    "    pp = gpt2_perplexity(sent)\n",
    "    gpt2_results[name] = pp\n",
    "    print(f\"  {name:15s} ‚Üí Perplexity: {pp:>10.2f}\")\n",
    "\n",
    "print(\"\\nObserve: GPT-2 assigns much lower perplexity overall, especially to\")\n",
    "print(\"the GPT-generated sentence which matches its learned distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390437e4",
   "metadata": {},
   "source": [
    "### Comparison: Perplexity Across Models\n",
    "\n",
    "Let's put all the results together in a table and a bar chart to visualize how perplexity improves with model sophistication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build comparison DataFrame\n",
    "comparison_data = []\n",
    "for name in test_sentences:\n",
    "    comparison_data.append({\n",
    "        \"Sentence\": name,\n",
    "        \"Trigram\": trigram_results[name],\n",
    "        \"HMM\": hmm_results[name],\n",
    "        \"GPT-2\": gpt2_results[name],\n",
    "    })\n",
    "\n",
    "df_perplexity = pd.DataFrame(comparison_data)\n",
    "df_perplexity = df_perplexity.set_index(\"Sentence\")\n",
    "print(\"Perplexity Comparison (lower = better):\\n\")\n",
    "print(df_perplexity.to_string(float_format=\"{:.2f}\".format))\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "df_perplexity.plot(kind=\"bar\", ax=ax, log=True)  # log scale for visibility\n",
    "ax.set_ylabel(\"Perplexity (log scale)\")\n",
    "ax.set_title(\"Perplexity Comparison: Trigram vs HMM vs GPT-2\")\n",
    "ax.legend(title=\"Model\")\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey observations:\")\n",
    "print(\"‚Ä¢ GPT-2 achieves dramatically lower perplexity across all sentences\")\n",
    "print(\"‚Ä¢ The GPT-generated sentence gets especially low perplexity from GPT-2\")\n",
    "print(\"‚Ä¢ Nonsense sentences get higher perplexity ‚Äî models are 'more confused'\")\n",
    "print(\"‚Ä¢ More sophisticated models ‚Üí lower perplexity ‚Üí better language understanding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e15de",
   "metadata": {},
   "source": [
    "## Is Perplexity still a useful measurement?\n",
    "\n",
    "GPT-2 and LLaMA-2 publish perplexity because they are pretrained language models.\n",
    "\n",
    "GPT-5, Gemini 2, Claude 3, etc., do not publish perplexity because they are instruction-tuned chat models.\n",
    "\n",
    "If measured, GPT-5 / Gemini would likely score below 3 ‚Äî significantly better than LLaMA-2 and GPT-2.\n",
    "\n",
    "Modern frontier models (GPT-4, GPT-5, Gemini 1.5/2.0, Claude 3, etc.) do not publish perplexity for three reasons: \n",
    "RLHF / instruction tuning breaks perplexity comparability. Perplexity is defined for next-token prediction on a fixed language-model objective. Once a model is instruction-tuned (SFT + RLHF), it is no longer a pure next-token model, so perplexity loses meaning across models.\n",
    "Companies benchmark on tasks instead (MMLU, GSM8K, HumanEval, etc.) \n",
    "GPT-5 reports improvements on accuracy and hallucination rates, not perplexity. \n",
    "Google Gemini and Anthropic Claude do the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb80dcc",
   "metadata": {},
   "source": [
    "# SQuAD 2.0: Question-Answering Metrics\n",
    "\n",
    "**SQuAD 2.0** (Stanford Question Answering Dataset) is the standard benchmark for evaluating extractive question-answering systems. Given a **context paragraph** and a **question**, the model must extract the correct answer span from the text ‚Äî or determine that the question is **unanswerable** from the given context.\n",
    "\n",
    "SQuAD 2.0 extends SQuAD 1.1 by adding ~50,000 unanswerable questions, requiring models to know when **not** to answer.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Exact Match (EM)\n",
    "\n",
    "**Exact Match** is a binary metric: does the predicted answer string **exactly** match the ground-truth answer (after normalization)?\n",
    "\n",
    "$$\\text{EM} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}[\\text{prediction}_i = \\text{ground\\_truth}_i]$$\n",
    "\n",
    "**Normalization steps** (applied to both prediction and ground truth before comparison):\n",
    "- Convert to lowercase\n",
    "- Remove articles (*a, an, the*)\n",
    "- Remove punctuation\n",
    "- Remove extra whitespace\n",
    "\n",
    "**Example**:\n",
    "- Ground truth: *\"the United Nations\"*\n",
    "- Prediction: *\"United Nations\"* ‚Üí EM = 1 (after removing \"the\")\n",
    "- Prediction: *\"UN\"* ‚Üí EM = 0 (even though semantically correct!)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. F1 Score (Token-Level)\n",
    "\n",
    "The **F1 Score** in SQuAD is computed at the **token level** ‚Äî it treats both the prediction and ground truth as bags of tokens and computes overlap:\n",
    "\n",
    "$$\\text{Precision} = \\frac{|\\text{predicted tokens} \\cap \\text{ground truth tokens}|}{|\\text{predicted tokens}|}$$\n",
    "\n",
    "$$\\text{Recall} = \\frac{|\\text{predicted tokens} \\cap \\text{ground truth tokens}|}{|\\text{ground truth tokens}|}$$\n",
    "\n",
    "$$F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "**Example**:\n",
    "- Ground truth: *\"the United Nations\"* ‚Üí tokens: {united, nations}\n",
    "- Prediction: *\"United Nations Organization\"* ‚Üí tokens: {united, nations, organization}\n",
    "- Overlap: {united, nations} ‚Üí 2 tokens\n",
    "- Precision = 2/3 = 0.67, Recall = 2/2 = 1.00, F1 = 0.80\n",
    "\n",
    "When multiple ground-truth answers exist (SQuAD provides up to 5 per question), the **maximum** F1 across all references is taken.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Unanswerable Question Logic (SQuAD 2.0)\n",
    "\n",
    "SQuAD 2.0 introduces questions where the answer is **not** contained in the context. The model must output an **empty string** or a special \"no answer\" token.\n",
    "\n",
    "The evaluation works as follows:\n",
    "\n",
    "| | Question is answerable | Question is unanswerable |\n",
    "|---|---|---|\n",
    "| **Model answers** | Evaluate EM/F1 normally | **False Positive** (EM=0, F1=0) |\n",
    "| **Model says \"no answer\"** | **False Negative** (EM=0, F1=0) | **True Negative** (EM=1, F1=1) |\n",
    "\n",
    "A **confidence threshold** is typically tuned: the model outputs a \"no-answer\" probability, and a threshold determines when to abstain. This threshold is optimized on the dev set to maximize the overall F1.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Limitations of EM and F1\n",
    "\n",
    "While EM and F1 are the standard SQuAD metrics, they have significant limitations:\n",
    "\n",
    "| Limitation | Example |\n",
    "|---|---|\n",
    "| **Synonym blindness** | Ground truth: *\"February 29\"*, Prediction: *\"leap day\"* ‚Üí F1 = 0, despite being correct |\n",
    "| **Paraphrase insensitivity** | Ground truth: *\"lack of water\"*, Prediction: *\"dehydration\"* ‚Üí F1 = 0 |\n",
    "| **Length sensitivity** | Longer predictions with correct content are penalized on precision |\n",
    "| **No semantic understanding** | Metrics only compare **surface-level tokens**, not meaning |\n",
    "| **Single-span assumption** | Cannot handle answers requiring information from multiple parts of the text |\n",
    "| **Ignores explanation quality** | A correct answer with no reasoning scores the same as one with perfect justification |\n",
    "\n",
    "> **In short**: EM and F1 reward **lexical overlap** with the reference answer. They fail when the correct answer uses different words than the reference.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Beyond Token Matching: Better Evaluation Approaches\n",
    "\n",
    "Modern Q&A systems (especially generative ones like RAG pipelines) require evaluation methods that go beyond surface-level token matching:\n",
    "\n",
    "### 5a. Embedding-Based Similarity (BERTScore, SimCSE)\n",
    "\n",
    "Tools like **BERTScore** and **SimCSE** use deep learning to transform text into mathematical vectors (**embeddings**). This allows the system to recognize that *\"The sun is hot\"* and *\"The star's temperature is extremely high\"* are semantically similar despite having zero word overlap.\n",
    "\n",
    "$$\\text{BERTScore} = \\frac{1}{|x|} \\sum_{x_i \\in x} \\max_{y_j \\in y} \\cos(\\mathbf{e}_{x_i}, \\mathbf{e}_{y_j})$$\n",
    "\n",
    "where $\\mathbf{e}_{x_i}$ are contextual token embeddings from a pre-trained model like BERT.\n",
    "\n",
    "### 5b. Claim-Level Decomposition\n",
    "\n",
    "Rather than comparing two complete sentences, this approach **breaks an answer into distinct factual claims** and verifies each one independently. This enables fine-grained evaluation: an answer can be \"80% correct\" instead of just right or wrong.\n",
    "\n",
    "Example: *\"Paris is the capital of France and has 2 million inhabitants\"* ‚Üí \\{Claim 1: \"Paris is the capital of France\", Claim 2: \"Paris has 2 million inhabitants\"\\}\n",
    "\n",
    "### 5c. The RAG Triad\n",
    "\n",
    "The **RAG Triad** evaluates three orthogonal dimensions of answer quality:\n",
    "- **Faithfulness**: Is the answer supported by the retrieved context? (Does it hallucinate?)\n",
    "- **Answer Relevance**: Does the answer actually address the question?\n",
    "- **Context Relevance**: Is the retrieved context relevant to the question?\n",
    "\n",
    "### 5d. Atomic Fact Checking (with Text-Mining Analysis)\n",
    "\n",
    "This method decomposes a generated answer into **atomic facts** and checks each against source documents using text-mining techniques. It provides a factual accuracy score at a granular level.\n",
    "\n",
    "### 5e. Natural Language Inference (NLI)\n",
    "\n",
    "NLI uses a separate model to determine if the source document **\"entails\"** (supports), **\"contradicts\"**, or is **\"neutral\"** toward the generated answer. This captures logical relationships that token overlap cannot.\n",
    "\n",
    "$$\\text{NLI}(\\text{premise}, \\text{hypothesis}) \\in \\{\\text{entailment}, \\text{contradiction}, \\text{neutral}\\}$$\n",
    "\n",
    "### 5f. LLM as a Judge\n",
    "\n",
    "An LLM can follow a detailed **rubric** to score answers on dimensions like:\n",
    "- **Comprehensiveness**: Does the answer cover all aspects of the question?\n",
    "- **Conciseness**: Is the answer free of unnecessary information?\n",
    "- **Clarity**: Is the answer well-structured and easy to understand?\n",
    "- **Factual accuracy**: Are all stated facts correct?\n",
    "\n",
    "This approach captures quality dimensions that token-level metrics cannot assess, though it introduces model bias and cost considerations.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Metric / Method | Type | Handles Synonyms? | Semantic? | Cost |\n",
    "|---|---|---|---|---|\n",
    "| **Exact Match** | Token-level | No | No | Free |\n",
    "| **F1 Score** | Token-level | No | No | Free |\n",
    "| **BERTScore** | Embedding | Yes | Yes | Low |\n",
    "| **NLI** | Classification | Yes | Yes | Medium |\n",
    "| **Claim Decomposition** | Structured | Yes | Yes | Medium |\n",
    "| **RAG Triad** | Multi-dimensional | Yes | Yes | Medium |\n",
    "| **LLM as Judge** | Rubric-based | Yes | Yes | High |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48c21d",
   "metadata": {},
   "source": [
    "## Coding Example: EM, F1 and BERTScore on SQuAD 2.0\n",
    "\n",
    "We compare **traditional metrics** (Exact Match, token-level F1) with **Embedding-Based Similarity** (BERTScore) on a few hand-picked SQuAD 2.0‚Äìstyle datapoints.\n",
    "\n",
    "The key insight: when a predicted answer is a **synonym or paraphrase** of the ground truth, EM and F1 give low scores ‚Äî but BERTScore correctly identifies the semantic match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb957ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bert-score --quiet\n",
    "\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# ============================================================\n",
    "# 1. SQuAD-style normalization and traditional metrics\n",
    "# ============================================================\n",
    "\n",
    "def normalize_answer(text):\n",
    "    \"\"\"SQuAD-style normalization: lowercase, remove articles/punctuation/whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b(a|an|the)\\b', ' ', text)          # remove articles\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    text = ' '.join(text.split())                          # collapse whitespace\n",
    "    return text\n",
    "\n",
    "def exact_match(prediction, ground_truth):\n",
    "    \"\"\"Binary: 1 if normalized strings match exactly, 0 otherwise.\"\"\"\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def token_f1(prediction, ground_truth):\n",
    "    \"\"\"Token-level F1 as used in SQuAD evaluation.\"\"\"\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    gt_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "    num_common = sum(common.values())\n",
    "    if num_common == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    precision = num_common / len(pred_tokens)\n",
    "    recall = num_common / len(gt_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# ============================================================\n",
    "# 2. SQuAD 2.0‚Äìstyle test cases\n",
    "# ============================================================\n",
    "# Each has: question, context, ground_truth, prediction, and a description\n",
    "# We deliberately include cases where EM/F1 fail but the answer is correct\n",
    "\n",
    "squad_examples = [\n",
    "    {\n",
    "        \"question\": \"When was the University of Maastricht founded?\",\n",
    "        \"ground_truth\": \"1976\",\n",
    "        \"prediction\": \"1976\",\n",
    "        \"case\": \"Exact match ‚Äî trivial\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the largest planet in our solar system?\",\n",
    "        \"ground_truth\": \"Jupiter\",\n",
    "        \"prediction\": \"jupiter\",\n",
    "        \"case\": \"Case difference only\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What caused the crew members to die?\",\n",
    "        \"ground_truth\": \"lack of oxygen\",\n",
    "        \"prediction\": \"suffocation\",\n",
    "        \"case\": \"Synonym ‚Äî semantic match\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When did the conflict begin?\",\n",
    "        \"ground_truth\": \"February 24, 2022\",\n",
    "        \"prediction\": \"24 February 2022\",\n",
    "        \"case\": \"Date format difference\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is the CEO of Tesla?\",\n",
    "        \"ground_truth\": \"Elon Musk\",\n",
    "        \"prediction\": \"the CEO is Elon Musk\",\n",
    "        \"case\": \"Correct but verbose\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What percentage of the population lives in cities?\",\n",
    "        \"ground_truth\": \"approximately 55%\",\n",
    "        \"prediction\": \"around 55 percent\",\n",
    "        \"case\": \"Paraphrase ‚Äî same meaning\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "        \"prediction\": \"I love pizza\",\n",
    "        \"case\": \"Completely wrong\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who invented the telephone?\",\n",
    "        \"ground_truth\": \"Alexander Graham Bell\",\n",
    "        \"prediction\": \"\",\n",
    "        \"case\": \"Unanswerable ‚Äî no answer given\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 3. Compute EM, F1, and BERTScore for each example\n",
    "# ============================================================\n",
    "\n",
    "# Compute BERTScore for all predictions vs ground truths at once\n",
    "# Using roberta-base (smaller, faster download) instead of roberta-large\n",
    "predictions = [ex[\"prediction\"] if ex[\"prediction\"] else \"no answer\" for ex in squad_examples]\n",
    "references = [ex[\"ground_truth\"] for ex in squad_examples]\n",
    "P, R, F1_bert = bert_score(predictions, references, model_type=\"roberta-base\", verbose=True)\n",
    "\n",
    "# Build results table\n",
    "results = []\n",
    "for i, ex in enumerate(squad_examples):\n",
    "    em = exact_match(ex[\"prediction\"], ex[\"ground_truth\"])\n",
    "    prec, rec, f1 = token_f1(ex[\"prediction\"], ex[\"ground_truth\"]) if ex[\"prediction\"] else (0, 0, 0)\n",
    "    \n",
    "    results.append({\n",
    "        \"Case\": ex[\"case\"],\n",
    "        \"Ground Truth\": ex[\"ground_truth\"],\n",
    "        \"Prediction\": ex[\"prediction\"] if ex[\"prediction\"] else \"(no answer)\",\n",
    "        \"EM\": em,\n",
    "        \"Token F1\": round(f1, 3),\n",
    "        \"BERTScore F1\": round(F1_bert[i].item(), 3),\n",
    "    })\n",
    "\n",
    "df_squad = pd.DataFrame(results)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Display results\n",
    "# ============================================================\n",
    "print(\"=\" * 95)\n",
    "print(\"SQuAD 2.0 Metrics Comparison: Exact Match vs Token F1 vs BERTScore\")\n",
    "print(\"=\" * 95)\n",
    "print()\n",
    "print(df_squad.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 95)\n",
    "print(\"KEY OBSERVATIONS\")\n",
    "print(\"=\" * 95)\n",
    "print()\n",
    "print(\"‚Ä¢ 'Synonym' case:  EM=0, F1=0  but BERTScore‚âà0.8+  ‚Üí BERTScore catches semantic match\")\n",
    "print(\"‚Ä¢ 'Date format':   EM=0, F1=0.5 but BERTScore‚âà0.9+  ‚Üí same date, different format\")\n",
    "print(\"‚Ä¢ 'Paraphrase':    EM=0, F1‚âà0.3 but BERTScore‚âà0.8+  ‚Üí same meaning, different words\")\n",
    "print(\"‚Ä¢ 'Wrong answer':  All metrics correctly give low scores\")\n",
    "print()\n",
    "print(\"Conclusion: EM and F1 miss semantically correct answers.\")\n",
    "print(\"BERTScore uses contextual embeddings to capture meaning beyond token overlap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc08518",
   "metadata": {},
   "source": [
    "# The RAGAS Framework for Evaluating RAG and Agentic Systems\n",
    "\n",
    "## Why RAGAS?\n",
    "\n",
    "In this course you build a complete **Conversational Search** pipeline:\n",
    "\n",
    "1. **Lucene Search Engine** ‚Äî index your own dataset and retrieve documents\n",
    "2. **Knowledge Graph (KG)** ‚Äî extract entities and relations using NER / RE text mining tools\n",
    "3. **Atomic Fact Extraction** ‚Äî decompose documents into verifiable claims\n",
    "4. **RAG (Retrieval-Augmented Generation)** ‚Äî augment an LLM with retrieved context\n",
    "5. **Agentic Architecture** ‚Äî multi-step reasoning with tool use, planning, and self-correction\n",
    "\n",
    "At every stage you need to answer: **\"Is my system producing correct, faithful, relevant answers?\"**\n",
    "\n",
    "Traditional metrics (EM, F1, ROUGE, BLEU) only measure **surface overlap** ‚Äî they cannot tell you whether a generated answer is *faithful to the retrieved context* or whether the *retriever found the right documents in the first place*.\n",
    "\n",
    "**RAGAS** (Retrieval-Augmented Generation Assessment) is a framework specifically designed to evaluate RAG pipelines **component-by-component**, using LLM-based judges alongside traditional metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## The RAG Triad\n",
    "\n",
    "RAGAS is built around the **RAG Triad** ‚Äî three independent dimensions that together give a complete picture of RAG quality:\n",
    "\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ   Question  ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "              ‚îÇ            ‚îÇ            ‚îÇ\n",
    "              ‚ñº            ‚îÇ            ‚ñº\n",
    "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "     ‚îÇ   Retrieved    ‚îÇ    ‚îÇ   ‚îÇ   Generated    ‚îÇ\n",
    "     ‚îÇ   Context      ‚îÇ    ‚îÇ   ‚îÇ   Answer       ‚îÇ\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚îÇ            ‚îÇ            ‚îÇ\n",
    "              ‚îÇ    Context ‚îÇ            ‚îÇ\n",
    "              ‚îÇ  Relevance ‚îÇ   Answer   ‚îÇ\n",
    "              ‚îÇ            ‚îÇ  Relevance ‚îÇ\n",
    "              ‚îÇ            ‚îÇ            ‚îÇ\n",
    "              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                    Faithfulness\n",
    "                    (Context ‚Üí Answer)\n",
    "```\n",
    "\n",
    "| Dimension | Question | What it measures |\n",
    "|-----------|----------|-----------------|\n",
    "| **Context Relevance** | Is the *retrieved context* relevant to the *question*? | Retriever quality |\n",
    "| **Faithfulness** | Is the *answer* supported by the *retrieved context*? | Hallucination detection |\n",
    "| **Answer Relevance** | Does the *answer* actually address the *question*? | Generation quality |\n",
    "\n",
    "---\n",
    "\n",
    "## Core RAGAS Metrics ‚Äî Detailed\n",
    "\n",
    "### 1. Faithfulness (Groundedness)\n",
    "\n",
    "> *\"Does the generated answer only contain information that can be traced back to the retrieved context?\"*\n",
    "\n",
    "This is the **hallucination detector**. An answer can be correct but unfaithful if the model \"knew\" the answer from training data rather than deriving it from the provided context.\n",
    "\n",
    "**How RAGAS computes it:**\n",
    "\n",
    "1. **Decompose** the generated answer into atomic **claims** (statements)\n",
    "2. For each claim, check whether it can be **inferred** from the retrieved context\n",
    "3. Compute the ratio:\n",
    "\n",
    "$$\n",
    "\\text{Faithfulness} = \\frac{|\\text{claims supported by context}|}{|\\text{total claims in answer}|}\n",
    "$$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "| Component | Content |\n",
    "|-----------|---------|\n",
    "| **Context** | \"Maastricht University was founded in 1976. It is located in the Netherlands.\" |\n",
    "| **Answer** | \"Maastricht University was founded in 1976 in the south of the Netherlands and has about 18,000 students.\" |\n",
    "| **Claims** | (1) Founded in 1976 ‚úÖ (2) In the south of the Netherlands ‚ö†Ô∏è partial (3) ~18,000 students ‚ùå not in context |\n",
    "| **Faithfulness** | 1/3 = 0.33 ‚Äî the model hallucinated the student count |\n",
    "\n",
    "**Score range:** 0 (fully hallucinated) ‚Üí 1 (fully grounded)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Answer Relevance\n",
    "\n",
    "> *\"Does the answer actually address what the user asked?\"*\n",
    "\n",
    "An answer might be faithful to the context but completely off-topic relative to the question.\n",
    "\n",
    "**How RAGAS computes it:**\n",
    "\n",
    "1. Given the answer, use an LLM to **generate N synthetic questions** that the answer *would* be a good response to\n",
    "2. Compute the **cosine similarity** between each synthetic question embedding and the **original question** embedding\n",
    "3. Average the similarities:\n",
    "\n",
    "$$\n",
    "\\text{Answer Relevance} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{sim}(\\mathbf{q}_{\\text{original}},\\; \\mathbf{q}_i^{\\text{synthetic}})\n",
    "$$\n",
    "\n",
    "where $\\text{sim}$ is the cosine similarity between sentence embeddings.\n",
    "\n",
    "**Intuition:** If the answer is relevant, then questions generated from it should be semantically similar to the original question.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "| Component | Content |\n",
    "|-----------|---------|\n",
    "| **Question** | \"When was UM founded?\" |\n",
    "| **Answer A** | \"UM was founded in 1976.\" ‚Üí synthetic questions ‚âà \"When was UM founded?\" ‚Üí high similarity ‚úÖ |\n",
    "| **Answer B** | \"UM has a beautiful campus.\" ‚Üí synthetic questions ‚âà \"What is UM's campus like?\" ‚Üí low similarity ‚ùå |\n",
    "\n",
    "**Score range:** 0 (irrelevant) ‚Üí 1 (perfectly relevant)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Context Relevance (Context Precision & Context Recall)\n",
    "\n",
    "> *\"Did the retriever find the right documents?\"*\n",
    "\n",
    "This evaluates your **Lucene search engine** and retrieval pipeline. RAGAS splits this into two sub-metrics:\n",
    "\n",
    "#### 3a. Context Precision\n",
    "\n",
    "Measures whether the **relevant** chunks are **ranked higher** than irrelevant ones.\n",
    "\n",
    "$$\n",
    "\\text{Context Precision@}k = \\frac{1}{|\\text{relevant chunks in top-}k|} \\sum_{i=1}^{k} \\left( \\frac{\\text{relevant chunks in top-}i}{i} \\times \\text{rel}_i \\right)\n",
    "$$\n",
    "\n",
    "where $\\text{rel}_i = 1$ if the $i$-th chunk is relevant, 0 otherwise.\n",
    "\n",
    "This is essentially a variant of **Average Precision** ‚Äî it rewards systems that put relevant context at the top of the retrieved list.\n",
    "\n",
    "#### 3b. Context Recall\n",
    "\n",
    "Measures whether **all** the information needed to answer the question is present in the retrieved context.\n",
    "\n",
    "**How RAGAS computes it:**\n",
    "\n",
    "1. Decompose the **ground truth answer** into atomic claims\n",
    "2. For each claim, check if it can be attributed to any chunk in the retrieved context\n",
    "3. Compute:\n",
    "\n",
    "$$\n",
    "\\text{Context Recall} = \\frac{|\\text{ground truth claims attributable to context}|}{|\\text{total ground truth claims}|}\n",
    "$$\n",
    "\n",
    "**Score range:** 0 (retriever missed everything) ‚Üí 1 (retriever found all needed information)\n",
    "\n",
    "---\n",
    "\n",
    "## Additional RAGAS Metrics\n",
    "\n",
    "### 4. Answer Semantic Similarity\n",
    "\n",
    "Direct embedding-based similarity between the generated answer and the ground truth answer (similar to BERTScore we computed above):\n",
    "\n",
    "$$\n",
    "\\text{Answer Similarity} = \\text{cosine\\_sim}\\big(\\text{embed}(\\text{answer}),\\; \\text{embed}(\\text{ground\\_truth})\\big)\n",
    "$$\n",
    "\n",
    "### 5. Answer Correctness\n",
    "\n",
    "A composite score combining:\n",
    "- **Factual correctness** (F1 over atomic facts: TP, FP, FN between answer and ground truth claims)\n",
    "- **Semantic similarity** (embedding similarity)\n",
    "\n",
    "$$\n",
    "\\text{Answer Correctness} = w_1 \\cdot F1_{\\text{factual}} + w_2 \\cdot \\text{Semantic Similarity}\n",
    "$$\n",
    "\n",
    "Default weights: $w_1 = 0.75$, $w_2 = 0.25$.\n",
    "\n",
    "### 6. Aspect Critique\n",
    "\n",
    "Binary LLM-based judgments on specific qualities:\n",
    "- **Harmfulness** ‚Äî Does the answer contain harmful content?\n",
    "- **Maliciousness** ‚Äî Is there malicious intent?\n",
    "- **Coherence** ‚Äî Is the answer logically coherent?\n",
    "- **Conciseness** ‚Äî Is the answer appropriately concise?\n",
    "\n",
    "---\n",
    "\n",
    "## RAGAS for Your Course Project\n",
    "\n",
    "In your project you will evaluate **three architectures** with RAGAS:\n",
    "\n",
    "### Architecture 1: Basic Lucene Search\n",
    "```\n",
    "Question ‚Üí Lucene Retrieval ‚Üí Top-k Documents ‚Üí Display to user\n",
    "```\n",
    "**Relevant metrics:** Context Precision, Context Recall (no generation, so no Faithfulness/Answer Relevance)\n",
    "\n",
    "### Architecture 2: RAG with LLM\n",
    "```\n",
    "Question ‚Üí Lucene Retrieval ‚Üí Top-k Documents ‚Üí LLM generates answer from context\n",
    "```\n",
    "**Relevant metrics:** All of the RAG Triad ‚Äî Faithfulness, Answer Relevance, Context Precision, Context Recall\n",
    "\n",
    "### Architecture 3: Agentic Conversational Search\n",
    "```\n",
    "Question ‚Üí Agent plans ‚Üí Tool calls (Lucene, KG lookup, fact extraction) ‚Üí LLM reasons ‚Üí Answer\n",
    "```\n",
    "**Relevant metrics:** All RAG Triad metrics + additional agentic metrics:\n",
    "- **Tool Selection Accuracy** ‚Äî did the agent pick the right tools?\n",
    "- **Planning Effectiveness** ‚Äî was the multi-step plan reasonable?\n",
    "- **Multi-hop Faithfulness** ‚Äî across multiple retrieval steps, is the final answer still grounded?\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Metric | Lucene Only | RAG | Agentic |\n",
    "|--------|:-----------:|:---:|:-------:|\n",
    "| Context Precision | ‚úÖ | ‚úÖ | ‚úÖ |\n",
    "| Context Recall | ‚úÖ | ‚úÖ | ‚úÖ |\n",
    "| Faithfulness | ‚Äî | ‚úÖ | ‚úÖ |\n",
    "| Answer Relevance | ‚Äî | ‚úÖ | ‚úÖ |\n",
    "| Answer Correctness | ‚Äî | ‚úÖ | ‚úÖ |\n",
    "| Answer Similarity | ‚Äî | ‚úÖ | ‚úÖ |\n",
    "| Multi-hop Reasoning | ‚Äî | ‚Äî | ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## How RAGAS Uses LLM-as-Judge\n",
    "\n",
    "Most RAGAS metrics use an **LLM as an automated judge** rather than relying on string matching. The key idea:\n",
    "\n",
    "1. **Claim Decomposition:** Break text into atomic, verifiable statements\n",
    "2. **NLI-style Verification:** Ask the LLM \"Can claim X be inferred from context Y?\" (Natural Language Inference)\n",
    "3. **Question Generation:** Generate synthetic questions and measure embedding similarity\n",
    "\n",
    "This makes RAGAS **reference-free** for some metrics ‚Äî you don't always need ground truth answers. You only need:\n",
    "- The **question**\n",
    "- The **retrieved context**\n",
    "- The **generated answer**\n",
    "\n",
    "For metrics like Context Recall and Answer Correctness, you additionally need **ground truth answers**.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Key Formulas\n",
    "\n",
    "| Metric | Formula | Requires Ground Truth? |\n",
    "|--------|---------|:---------------------:|\n",
    "| **Faithfulness** | $\\frac{\\text{supported claims}}{\\text{total claims}}$ | No |\n",
    "| **Answer Relevance** | $\\frac{1}{N}\\sum \\text{sim}(q, q_i^{\\text{syn}})$ | No |\n",
    "| **Context Precision** | Weighted precision of relevant chunks by rank | Yes |\n",
    "| **Context Recall** | $\\frac{\\text{GT claims in context}}{\\text{total GT claims}}$ | Yes |\n",
    "| **Answer Similarity** | $\\text{cosine}(\\text{embed}(a), \\text{embed}(a^*))$ | Yes |\n",
    "| **Answer Correctness** | $0.75 \\cdot F1_{\\text{facts}} + 0.25 \\cdot \\text{sim}$ | Yes |\n",
    "\n",
    "> **Key insight for your project:** Faithfulness and Answer Relevance are the most important metrics for detecting hallucinations and off-topic answers in your RAG/Agentic system. Context Precision and Recall tell you how good your Lucene retriever is. Use all of them together to get the complete picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f2f96",
   "metadata": {},
   "source": [
    "## Coding Example: RAGAS Metrics on Fixed Q&A Pairs\n",
    "\n",
    "Below we implement **simplified versions** of the core RAGAS metrics using only embeddings (no LLM judge required). This makes the logic fully transparent and reproducible.\n",
    "\n",
    "We simulate a RAG pipeline with **fixed** questions, retrieved contexts, generated answers, and ground truth answers. For each example we compute:\n",
    "\n",
    "| Metric | What we measure | How |\n",
    "|--------|----------------|-----|\n",
    "| **Faithfulness** | Are answer claims grounded in context? | Split answer into sentences ‚Üí cosine similarity to context sentences |\n",
    "| **Context Recall** | Does the context cover the ground truth? | Split ground truth into claims ‚Üí check if each is attributable to context |\n",
    "| **Answer Relevance** | Does the answer address the question? | Cosine similarity between question and answer embeddings |\n",
    "| **Answer Similarity** | Is the answer semantically close to ground truth? | Cosine similarity between answer and ground truth embeddings |\n",
    "\n",
    "> **Note:** In the real RAGAS library, Faithfulness and Context Recall use an **LLM** for claim decomposition and NLI verification. Here we approximate this with sentence-level embedding similarity to illustrate the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers --quiet\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load a lightweight sentence embedding model\n",
    "# ============================================================\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")   # fast, ~80 MB\n",
    "\n",
    "# ============================================================\n",
    "# 2. Define fixed RAG-style examples\n",
    "# ============================================================\n",
    "# Each simulates: User asks a question ‚Üí Retriever returns context chunks ‚Üí LLM generates answer\n",
    "# We also have ground truth for evaluation\n",
    "\n",
    "rag_examples = [\n",
    "    {\n",
    "        \"id\": \"Good RAG\",\n",
    "        \"question\": \"When was Maastricht University founded and where is it located?\",\n",
    "        \"contexts\": [\n",
    "            \"Maastricht University (UM) was founded in 1976. It is the youngest university in the Netherlands.\",\n",
    "            \"Maastricht University is located in Maastricht, in the province of Limburg, the southernmost part of the Netherlands.\",\n",
    "        ],\n",
    "        \"answer\": \"Maastricht University was founded in 1976 and is located in Maastricht, in the province of Limburg.\",\n",
    "        \"ground_truth\": \"Maastricht University was founded in 1976. It is located in Maastricht, Limburg, the Netherlands.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Hallucinated\",\n",
    "        \"question\": \"How many students does Maastricht University have?\",\n",
    "        \"contexts\": [\n",
    "            \"Maastricht University (UM) was founded in 1976. It is the youngest university in the Netherlands.\",\n",
    "            \"UM uses Problem-Based Learning (PBL) as its main educational model.\",\n",
    "        ],\n",
    "        \"answer\": \"Maastricht University has approximately 18,500 students and is known for its international character with students from over 100 countries.\",\n",
    "        \"ground_truth\": \"Maastricht University has about 18,000 students.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Irrelevant answer\",\n",
    "        \"question\": \"What teaching method does UM use?\",\n",
    "        \"contexts\": [\n",
    "            \"UM uses Problem-Based Learning (PBL) as its main educational model.\",\n",
    "            \"PBL is a student-centered approach where students learn by working on real-world problems in small tutorial groups.\",\n",
    "        ],\n",
    "        \"answer\": \"Maastricht is a beautiful city in the south of the Netherlands with many historical buildings and a vibrant cultural scene.\",\n",
    "        \"ground_truth\": \"UM uses Problem-Based Learning (PBL), a student-centered approach with small tutorial groups.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Bad retrieval\",\n",
    "        \"question\": \"What are the faculties of Maastricht University?\",\n",
    "        \"contexts\": [\n",
    "            \"The Netherlands has 14 research universities.\",\n",
    "            \"Dutch universities offer bachelor and master programs.\",\n",
    "        ],\n",
    "        \"answer\": \"I don't have enough information to answer this question based on the provided context.\",\n",
    "        \"ground_truth\": \"Maastricht University has six faculties: Law, Arts and Social Sciences, Psychology and Neuroscience, Health Medicine and Life Sciences, Business and Economics, and Science and Engineering.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Partial answer\",\n",
    "        \"question\": \"What is PBL and how does it work at UM?\",\n",
    "        \"contexts\": [\n",
    "            \"PBL is a student-centered approach where students learn by working on real-world problems.\",\n",
    "            \"Students work in small tutorial groups of 10-15 students guided by a tutor.\",\n",
    "            \"The weather in Maastricht is typically mild with average temperatures around 10¬∞C.\",\n",
    "        ],\n",
    "        \"answer\": \"PBL stands for Problem-Based Learning. Students work on real-world problems in tutorial groups.\",\n",
    "        \"ground_truth\": \"PBL (Problem-Based Learning) is a student-centered pedagogical approach. At UM, students work in small tutorial groups of 10-15, guided by a tutor, to solve real-world problems.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Implement simplified RAGAS metrics\n",
    "# ============================================================\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Simple sentence splitter.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sentences if len(s.strip()) > 3]\n",
    "\n",
    "\n",
    "def compute_faithfulness(answer, contexts, model, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Simplified Faithfulness: for each answer sentence, check if it is\n",
    "    semantically supported by ANY context sentence (cosine sim ‚â• threshold).\n",
    "    Returns (score, detail_list).\n",
    "    \"\"\"\n",
    "    answer_sents = split_into_sentences(answer)\n",
    "    if not answer_sents:\n",
    "        return 0.0, []\n",
    "\n",
    "    context_sents = []\n",
    "    for ctx in contexts:\n",
    "        context_sents.extend(split_into_sentences(ctx))\n",
    "    if not context_sents:\n",
    "        return 0.0, [{\"claim\": s, \"max_sim\": 0.0, \"supported\": False} for s in answer_sents]\n",
    "\n",
    "    ans_embs = model.encode(answer_sents, convert_to_tensor=True)\n",
    "    ctx_embs = model.encode(context_sents, convert_to_tensor=True)\n",
    "\n",
    "    sim_matrix = util.cos_sim(ans_embs, ctx_embs)\n",
    "    max_sims = sim_matrix.max(dim=1).values.cpu().numpy()\n",
    "\n",
    "    details = []\n",
    "    for sent, sim in zip(answer_sents, max_sims):\n",
    "        details.append({\"claim\": sent, \"max_sim\": float(sim), \"supported\": bool(sim >= threshold)})\n",
    "\n",
    "    supported = sum(1 for d in details if d[\"supported\"])\n",
    "    return float(supported / len(answer_sents)), details\n",
    "\n",
    "\n",
    "def compute_context_recall(ground_truth, contexts, model, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Simplified Context Recall: for each ground truth sentence, check if\n",
    "    it can be attributed to any context sentence (cosine sim ‚â• threshold).\n",
    "    \"\"\"\n",
    "    gt_sents = split_into_sentences(ground_truth)\n",
    "    if not gt_sents:\n",
    "        return 0.0\n",
    "\n",
    "    context_sents = []\n",
    "    for ctx in contexts:\n",
    "        context_sents.extend(split_into_sentences(ctx))\n",
    "    if not context_sents:\n",
    "        return 0.0\n",
    "\n",
    "    gt_embs = model.encode(gt_sents, convert_to_tensor=True)\n",
    "    ctx_embs = model.encode(context_sents, convert_to_tensor=True)\n",
    "\n",
    "    sim_matrix = util.cos_sim(gt_embs, ctx_embs)\n",
    "    max_sims = sim_matrix.max(dim=1).values.cpu().numpy()\n",
    "\n",
    "    attributable = (max_sims >= threshold).sum()\n",
    "    return float(attributable / len(gt_sents))\n",
    "\n",
    "\n",
    "def compute_answer_relevance(question, answer, model):\n",
    "    \"\"\"Cosine similarity between question and answer embeddings.\"\"\"\n",
    "    q_emb = model.encode(question, convert_to_tensor=True)\n",
    "    a_emb = model.encode(answer, convert_to_tensor=True)\n",
    "    return float(util.cos_sim(q_emb, a_emb).item())\n",
    "\n",
    "\n",
    "def compute_answer_similarity(answer, ground_truth, model):\n",
    "    \"\"\"Cosine similarity between answer and ground truth embeddings.\"\"\"\n",
    "    a_emb = model.encode(answer, convert_to_tensor=True)\n",
    "    gt_emb = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    return float(util.cos_sim(a_emb, gt_emb).item())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Evaluate all examples\n",
    "# ============================================================\n",
    "all_results = []\n",
    "all_details = {}\n",
    "\n",
    "for ex in rag_examples:\n",
    "    faith, faith_details = compute_faithfulness(ex[\"answer\"], ex[\"contexts\"], embed_model)\n",
    "    ctx_recall = compute_context_recall(ex[\"ground_truth\"], ex[\"contexts\"], embed_model)\n",
    "    ans_rel = compute_answer_relevance(ex[\"question\"], ex[\"answer\"], embed_model)\n",
    "    ans_sim = compute_answer_similarity(ex[\"answer\"], ex[\"ground_truth\"], embed_model)\n",
    "\n",
    "    # Answer Correctness (RAGAS: 0.75 * factual_F1 + 0.25 * semantic_sim)\n",
    "    if faith + ctx_recall > 0:\n",
    "        factual_f1 = 2 * faith * ctx_recall / (faith + ctx_recall)\n",
    "    else:\n",
    "        factual_f1 = 0.0\n",
    "    ans_correct = 0.75 * factual_f1 + 0.25 * ans_sim\n",
    "\n",
    "    all_results.append({\n",
    "        \"Example\": ex[\"id\"],\n",
    "        \"Faithfulness\": round(faith, 3),\n",
    "        \"Ctx Recall\": round(ctx_recall, 3),\n",
    "        \"Ans Relevance\": round(ans_rel, 3),\n",
    "        \"Ans Similarity\": round(ans_sim, 3),\n",
    "        \"Ans Correctness\": round(ans_correct, 3),\n",
    "    })\n",
    "    all_details[ex[\"id\"]] = faith_details\n",
    "\n",
    "df_ragas = pd.DataFrame(all_results)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Display summary table\n",
    "# ============================================================\n",
    "print(\"=\" * 90)\n",
    "print(\"RAGAS Metrics ‚Äî Simplified (Embedding-Based) Evaluation\")\n",
    "print(\"=\" * 90)\n",
    "print()\n",
    "print(df_ragas.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 6. Show per-claim faithfulness detail (most instructive part)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FAITHFULNESS ‚Äî Per-Claim Detail (threshold = 0.7)\")\n",
    "print(\"=\" * 90)\n",
    "for ex_id, details in all_details.items():\n",
    "    print(f\"\\n  [{ex_id}]\")\n",
    "    for d in details:\n",
    "        status = \"‚úÖ supported\" if d[\"supported\"] else \"‚ùå NOT supported\"\n",
    "        print(f\"    sim={d['max_sim']:.3f}  {status}  ‚Üí  \\\"{d['claim'][:80]}\\\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. Interpretation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\"\"\n",
    "  [Good RAG]\n",
    "    All metrics high ‚Äî the answer is faithful to context, the context covers\n",
    "    the ground truth, and the answer directly addresses the question.\n",
    "\n",
    "  [Hallucinated]\n",
    "    The answer mentions \"18,500 students\" and \"100 countries\" ‚Äî facts NOT in the\n",
    "    retrieved context. Faithfulness catches this: those claims have low similarity\n",
    "    to any context sentence.\n",
    "    Note: Context Recall is also low because the context doesn't contain\n",
    "    student-count information needed to verify the ground truth.\n",
    "\n",
    "  [Irrelevant answer]\n",
    "    The answer is about tourism, but the question asks about teaching methods.\n",
    "    ‚Üí Answer Relevance ‚âà 0 (question-answer mismatch)\n",
    "    ‚Üí Answer Similarity ‚âà 0 (answer doesn't match ground truth at all)\n",
    "\n",
    "  [Bad retrieval]\n",
    "    The retriever returned generic documents about Dutch universities ‚Äî none\n",
    "    relevant to UM's faculties. Context Recall = 0 because the ground truth\n",
    "    facts can't be found in these contexts. The LLM correctly abstains.\n",
    "\n",
    "  [Partial answer]\n",
    "    The answer captures the core idea (PBL + real-world problems) but misses\n",
    "    specifics (group size 10-15, tutor role). Faithfulness is high (everything\n",
    "    stated IS in the context), but Answer Similarity is moderate.\n",
    "\"\"\")\n",
    "print(\"=\" * 90)\n",
    "print(\"‚ö†Ô∏è  LIMITATION OF EMBEDDING-BASED FAITHFULNESS\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\"\"\n",
    "  Embedding similarity has limitations ‚Äî sentences about the same entity\n",
    "  (e.g., \"Maastricht University\") can score high even when the *facts* differ.\n",
    "  \n",
    "  This is exactly why the real RAGAS framework uses an LLM-as-Judge:\n",
    "    1. Decompose the answer into atomic claims\n",
    "    2. Ask the LLM: \"Can this claim be inferred from the context?\" (NLI)\n",
    "  \n",
    "  The embedding approach shown here is a useful approximation for understanding\n",
    "  the concept, but for production evaluation, use the ragas library with an LLM.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab60eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercises\n",
    "\n",
    "The following exercises test your understanding of the evaluation metrics covered in this tutorial. Exercises 1 and 2 are open questions (manually graded). Exercise 3 is a coding task (auto-graded)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965b1bb",
   "metadata": {},
   "source": [
    "## Exercise A1: Precision, Recall and F1 Trade-offs (10 points ‚Äî manually graded)\n",
    "\n",
    "A spam filter classifies incoming emails. After running it on 1,000 emails, you observe the following results:\n",
    "\n",
    "| | Predicted Spam | Predicted Not Spam |\n",
    "|---|---|---|\n",
    "| **Actually Spam** | 80 | 20 |\n",
    "| **Actually Not Spam** | 50 | 850 |\n",
    "\n",
    "**a)** Calculate Precision, Recall, and F1-Score for the \"Spam\" class. Show your work.\n",
    "\n",
    "**b)** The product manager says: *\"We'd rather let a few spam emails through than accidentally block a legitimate email from a customer.\"* Based on this requirement, should you optimize for **Precision** or **Recall**? Explain your reasoning, and describe what trade-off the other metric would suffer.\n",
    "\n",
    "**c)** Now imagine a different scenario: a medical screening test for a rare disease. Would your answer to (b) change? Why or why not?\n",
    "\n",
    "**YOUR ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1862d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "393f9299aa2ec832244a01e4f049f41d",
     "grade": true,
     "grade_id": "solution_1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4656e82",
   "metadata": {},
   "source": [
    "## Exercise A2: Understanding ROUGE Metrics (10 points ‚Äî manually graded)\n",
    "\n",
    "Consider the following reference summary and two candidate summaries:\n",
    "\n",
    "**Reference:** *\"The European Central Bank raised interest rates by 0.25% to combat rising inflation across the eurozone.\"*\n",
    "\n",
    "**Candidate A:** *\"Interest rates were increased by the ECB by 0.25% due to inflation in Europe.\"*\n",
    "\n",
    "**Candidate B:** *\"The European Central Bank raised interest rates by 0.25% last Thursday in Frankfurt.\"*\n",
    "\n",
    "**a)** Without running any code, which candidate do you expect to score higher on **ROUGE-1** (unigram overlap)? Explain by identifying the overlapping and non-overlapping unigrams for each candidate.\n",
    "\n",
    "**b)** Which candidate do you expect to score higher on **ROUGE-L** (longest common subsequence)? Why?\n",
    "\n",
    "**c)** Candidate A is arguably a better summary (it captures the *reason*: inflation), yet it may score lower on ROUGE than Candidate B (which adds invented details: \"last Thursday in Frankfurt\"). What does this reveal about the **limitations of ROUGE** as an evaluation metric? Suggest one alternative metric that could address this limitation and explain why.\n",
    "\n",
    "**YOUR ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f0a84",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbb1bbe29f453cb21bb2d0bb541808ef",
     "grade": true,
     "grade_id": "solution_2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d5df0",
   "metadata": {},
   "source": [
    "## Exercise A3: Implementing Precision, Recall, F1, and ROUGE from Scratch (15 points ‚Äî auto-graded)\n",
    "\n",
    "In this exercise you will implement evaluation metrics **from scratch** (without using sklearn or rouge-score).\n",
    "\n",
    "**Task 1 (7 points):** Implement the function `compute_classification_metrics(y_true, y_pred)` that takes two lists of binary labels (0 or 1) and returns a dictionary with keys `\"precision\"`, `\"recall\"`, and `\"f1\"`, each rounded to 4 decimal places. Handle the edge case where precision or recall would involve division by zero (return 0.0 in that case).\n",
    "\n",
    "**Task 2 (8 points):** Implement the function `compute_rouge_n(reference, candidate, n)` that takes two strings (reference and candidate summaries) and an integer `n` (for n-gram size), and returns a dictionary with keys `\"precision\"`, `\"recall\"`, and `\"f1\"`, each rounded to 4 decimal places. Use **lowercased** tokens (split on whitespace). Handle edge cases where there are no n-grams (return 0.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b453c4a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e4ee9472e750bf06a1b329f2be0d7e6",
     "grade": false,
     "grade_id": "solution_3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# ============================================================\n",
    "# Task 1: Implement classification metrics from scratch\n",
    "# ============================================================\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Precision, Recall and F1 for binary classification (positive class = 1).\n",
    "    \n",
    "    Parameters:\n",
    "        y_true: list of int ‚Äî ground truth labels (0 or 1)\n",
    "        y_pred: list of int ‚Äî predicted labels (0 or 1)\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys \"precision\", \"recall\", \"f1\", each rounded to 4 decimal places.\n",
    "        Return 0.0 for any metric that would involve division by zero.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Task 2: Implement ROUGE-N from scratch\n",
    "# ============================================================\n",
    "\n",
    "def compute_rouge_n(reference, candidate, n=1):\n",
    "    \"\"\"\n",
    "    Compute ROUGE-N precision, recall, and F1 between a reference and candidate summary.\n",
    "    \n",
    "    Parameters:\n",
    "        reference: str ‚Äî the reference (gold) summary\n",
    "        candidate: str ‚Äî the candidate (generated) summary\n",
    "        n: int ‚Äî the n-gram size (1 for unigrams, 2 for bigrams, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys \"precision\", \"recall\", \"f1\", each rounded to 4 decimal places.\n",
    "        Return 0.0 for any metric that would involve division by zero.\n",
    "    \n",
    "    Notes:\n",
    "        - Lowercase all tokens before computing n-grams\n",
    "        - Split on whitespace (simple tokenization)\n",
    "        - Use Counter for n-gram overlap counting\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Quick test (visible to students)\n",
    "# ============================================================\n",
    "print(\"=== Task 1: Classification Metrics ===\")\n",
    "test_metrics = compute_classification_metrics(\n",
    "    y_true=[1, 1, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "    y_pred=[1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
    ")\n",
    "print(f\"  Precision: {test_metrics['precision']}\")\n",
    "print(f\"  Recall:    {test_metrics['recall']}\")\n",
    "print(f\"  F1:        {test_metrics['f1']}\")\n",
    "\n",
    "print(\"\\n=== Task 2: ROUGE-1 ===\")\n",
    "test_rouge = compute_rouge_n(\n",
    "    reference=\"The cat sat on the mat\",\n",
    "    candidate=\"The cat is on the mat\",\n",
    "    n=1\n",
    ")\n",
    "print(f\"  ROUGE-1 Precision: {test_rouge['precision']}\")\n",
    "print(f\"  ROUGE-1 Recall:    {test_rouge['recall']}\")\n",
    "print(f\"  ROUGE-1 F1:        {test_rouge['f1']}\")\n",
    "\n",
    "print(\"\\n=== Task 2: ROUGE-2 ===\")\n",
    "test_rouge2 = compute_rouge_n(\n",
    "    reference=\"The cat sat on the mat\",\n",
    "    candidate=\"The cat is on the mat\",\n",
    "    n=2\n",
    ")\n",
    "print(f\"  ROUGE-2 Precision: {test_rouge2['precision']}\")\n",
    "print(f\"  ROUGE-2 Recall:    {test_rouge2['recall']}\")\n",
    "print(f\"  ROUGE-2 F1:        {test_rouge2['f1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711eae6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f052c2f60168d744b2a64f22ce00aa",
     "grade": true,
     "grade_id": "hidden_tests_auto",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# AUTO-GRADED TESTS (15 points)\n",
    "# Do not modify this cell\n",
    "\n",
    "\n",
    "print(\"All auto-graded tests passed! ‚úì\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
