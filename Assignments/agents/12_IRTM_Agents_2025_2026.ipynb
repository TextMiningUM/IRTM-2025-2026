{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230611e8",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f301d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c63ecf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcc583",
   "metadata": {},
   "source": [
    "![Maastricht_University_logo.svg](data:image/svg+xml;base64,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)\n",
    "\n",
    "\n",
    "# Information Retrieval and Text Mining Course\n",
    "## Tutorial 12 — Conversational Search: Agentic Approaches\n",
    "\n",
    "**Author:** Jan Scholtes\n",
    "\n",
    "**Edition 2025-2026**\n",
    "\n",
    "Department of Advanced Computer Sciences — Maastricht University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610c0d3",
   "metadata": {},
   "source": [
    "Welcome to Tutorial 12 on **Agentic Approaches for Conversational Search**. AI has been interested in Agents for quite some time. Already in 1995's *Artificial Intelligence: A Modern Approach* ([AIMA](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach)) by Russell and Norvig, an 'agent' is defined as anything that (i) senses its environment, (ii) perceives inputs, (iii) responds through reasoning, and (iv) acts upon the environment. Today, LLMs make many of these original agent goals practical.\n",
    "\n",
    "In this tutorial we explore how **LLM-based agents** extend standard Retrieval-Augmented Generation (RAG) to create truly autonomous conversational search systems. The topics covered are:\n",
    "\n",
    "1. **Why Agentic Architecture?** — limitations of standard RAG vs. agent-based search.\n",
    "2. **The 7 Components of an LLM-Based Agent** — perception, memory, action interface, goal management, reasoning & planning, learning, verification & guardrails.\n",
    "3. **Perception** — LLMs as multimodal input processors.\n",
    "4. **Memory** — short-term, long-term (FAISS), and episodic memory.\n",
    "5. **Action Interface & Tools** — the ReAct paradigm (Reason + Act).\n",
    "6. **Goal & Task Management, Reasoning & Planning** — planner + worker agents.\n",
    "7. **Verification & Guardrails** — critic agents, fact-checking, safety filters.\n",
    "8. **Multi-Agent Orchestration** — manager/specialists, debate/committee, shared blackboard.\n",
    "9. **Agent Interoperability & Standards** — MCP, A2A, LangGraph, OpenAI Agents SDK.\n",
    "10. **Challenges & Future Directions** — safety, evaluation, multimodal search.\n",
    "\n",
    "At the end you will find the **Exercises** section with graded assignments.\n",
    "\n",
    "> **Note:** This course is about Information Retrieval, Text Mining, and Conversational Search — not about programming skills. The code cells below show you *how* agentic architectures work in practice using the **OpenAI Agents SDK**. Focus on understanding the **concepts** and **results**.\n",
    "\n",
    "> **Important:** This tutorial requires an **OpenAI API key** with billing enabled. The cost is typically €1–€3 for the entire tutorial when using `gpt-4o-mini`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3f70b",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "\n",
    "We install all required packages in a single cell. Run this cell once at the beginning of your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89580fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess, sys\n",
    "\n",
    "packages = [\n",
    "    \"openai>=1.40.0\",\n",
    "    \"openai-agents\",\n",
    "    \"faiss-cpu\",\n",
    "    \"tiktoken\",\n",
    "    \"numpy\",\n",
    "]\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3235b7",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "\n",
    "All imports are grouped here so the notebook is easy to set up and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "import getpass\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "\n",
    "# OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI Agents SDK\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "# FAISS for vector memory\n",
    "import faiss\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2be8c2",
   "metadata": {},
   "source": [
    "## Setting Up the OpenAI API Key\n",
    "\n",
    "To run this tutorial, you need an **OpenAI API key** with an activated billing method. Follow these steps:\n",
    "\n",
    "1. **Create an OpenAI account** at [https://platform.openai.com/](https://platform.openai.com/)\n",
    "2. **Create a new API key** at [https://platform.openai.com/settings/organization/api-keys](https://platform.openai.com/settings/organization/api-keys)\n",
    "3. **Add credits / enable billing** at [https://platform.openai.com/settings/organization/billing/overview](https://platform.openai.com/settings/organization/billing/overview) (typically €1–€3 for this tutorial with `gpt-4o-mini`)\n",
    "\n",
    "⚠️ **Never share your API key or commit it to version control.** The cell below will prompt you securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a402cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Setup — enter your key when prompted (input is hidden)\n",
    "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "assert \"OPENAI_API_KEY\" in os.environ and os.environ[\"OPENAI_API_KEY\"], \\\n",
    "    \"Please set OPENAI_API_KEY as an environment variable.\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Quick verification — list a few available models\n",
    "models = client.models.list()\n",
    "print(\"API key verified! Available models (first 5):\")\n",
    "print([m.id for m in models.data][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ae62a",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Why Agentic Architecture for Search?\n",
    "\n",
    "## Standard RAG Is Not Enough\n",
    "\n",
    "Standard RAG follows a rigid, linear pipeline: **Query → Retrieve → Generate**. While effective for simple factual questions, it has fundamental limitations:\n",
    "\n",
    "| Limitation | Description |\n",
    "|---|---|\n",
    "| **Static Retrieval** | No self-correction if the wrong documents are fetched. The system cannot decide to search again with different terms. |\n",
    "| **Context Fragmentation** | Struggles with long-term reasoning across many conversation turns or across multiple sources. |\n",
    "| **Lack of Proactivity** | Cannot independently call tools, verify facts, or ask clarifying questions. |\n",
    "| **One-Shot Reasoning** | Answers in a single pass — no iterative refinement, no multi-hop reasoning. |\n",
    "\n",
    "## What Agentic Architecture Achieves\n",
    "\n",
    "| Dimension | RAG + LLM | Agentic Search |\n",
    "|---|---|---|\n",
    "| **Workflow** | Fixed pipeline | Dynamic, adaptive loops |\n",
    "| **Decision Making** | None — follows fixed steps | Autonomous — decides what to do next |\n",
    "| **Data Sources** | Pre-configured retriever | Can discover and query multiple sources |\n",
    "| **Verification** | None built-in | Self-checking, critic agents, guardrails |\n",
    "\n",
    "## Applications Only Possible with Agents\n",
    "\n",
    "1. **Autonomous Research & Synthesis** — multi-hop queries across domains (e.g., \"Map the landscape of autonomous agents in legal tech between 2023–2025\")\n",
    "2. **End-to-End Troubleshooting** — diagnose problems, call APIs, execute fixes\n",
    "3. **Strategic Decision Support** — break down complex business questions into sub-analyses\n",
    "4. **Forensics & Compliance Monitoring** — real-time pattern detection across large text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d887c8",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. From LLM to Agent — The 7 Components\n",
    "\n",
    "LLMs become agents when placed in a loop with memory, goals, reasoning, actions, and feedback. To go from a stand-alone LLM to an agent, we wrap the LLM with seven components:\n",
    "\n",
    "| # | Component | Description |\n",
    "|---|---|---|\n",
    "| 1 | **Perception** | Text, speech, images, structured data — multimodal input processing |\n",
    "| 2 | **Memory** | Short-term (context window), long-term (vector DBs like FAISS/Pinecone), episodic (interaction logs) |\n",
    "| 3 | **Action Interface / Tools** | API calls, code execution, database queries — follows the **ReAct** paradigm (Reason + Act) |\n",
    "| 4 | **Goal / Task Management** | Natural-language goals, decomposition into subgoals, dynamic reprioritization |\n",
    "| 5 | **Reasoning & Planning** | CoT (Chain-of-Thought), ToT (Tree-of-Thought), SoT (Skeleton-of-Thought), explicit planners, control loops |\n",
    "| 6 | **Learning & Adaptation** | Fine-tuning, RLHF (Reinforcement Learning from Human Feedback), process-based rewards |\n",
    "| 7 | **Verification & Guardrails** | Fact-checking modules, safety filters, external critics, debate agents |\n",
    "\n",
    "### Why LLMs as Agents?\n",
    "\n",
    "- **Natural language interface** — text is expressive enough to encode plans, decisions, and feedback\n",
    "- **General world knowledge** — no handcrafted rules needed\n",
    "- **Few-shot adaptability** — can adapt behaviour via prompting\n",
    "- **Scalability** — once an agent loop is defined, it works across domains\n",
    "\n",
    "### The Symbiosis\n",
    "\n",
    "LLMs make many 1990s agent dreams practical. Conversely, agentic architectures fix LLM shortcomings (hallucinations, no tool access, limited context, one-shot reasoning, no self-critique).\n",
    "\n",
    "We will now demonstrate each component with working code using the **OpenAI Agents SDK**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fe81b",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Perception\n",
    "\n",
    "LLMs naturally handle diverse inputs expressed as text: instructions, structured data, dialogue. Multimodal models extend this to images, audio, and video. With today's LLMs, input processing functionality is built-in: chatting, speech, images, document uploads (including tables in XLS and OCR for images and bitmap PDFs).\n",
    "\n",
    "Until the introduction of ChatGPT (November 30, 2022), this was absolutely NOT trivial. Most NLP models before that time failed to deliver this functionality reliably.\n",
    "\n",
    "Let's demonstrate the LLM's perception capabilities by giving it mixed natural language + structured data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perception: LLM as multimodal text processor\n",
    "prompt = \"\"\"You will receive:\n",
    "- Natural language instruction\n",
    "- A tiny piece of structured data\n",
    "\n",
    "Explain what the user wants, then compute the answer.\n",
    "\n",
    "User instruction: \"Compute the mean and max of these scores.\"\n",
    "Scores (JSON): [7.5, 8.0, 9.0]\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=prompt,\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc6cd3",
   "metadata": {},
   "source": [
    "**Observation:** The LLM seamlessly processes the mixed natural-language instruction and structured JSON data. It understands *what* the user wants (compute statistics) and *how* to do it (arithmetic). This demonstrates the **perception** component — the agent's ability to understand diverse input formats without special parsers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a8646",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Memory\n",
    "\n",
    "Stand-alone LLMs are **stateless**. Once the prompt ends, they forget everything. For an agent to function, we need external memory of several kinds:\n",
    "\n",
    "| Type | Description | Implementation |\n",
    "|---|---|---|\n",
    "| **Short-term** | Current conversation history | Context window of the LLM |\n",
    "| **Long-term** | Persistent, retrievable knowledge | External vector databases (FAISS, Pinecone, Chroma) |\n",
    "| **Episodic** | Logs of prior interactions with timestamps | Structured logs retrievable by time/context |\n",
    "| **Semantic** | Retrieved knowledge chunks | RAG (Retrieval-Augmented Generation) |\n",
    "\n",
    "Let's demonstrate each type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a27d03",
   "metadata": {},
   "source": [
    "## 4.1 Short-Term Memory\n",
    "\n",
    "Short-term memory is maintained through the conversation context. The OpenAI Agents SDK provides `SQLiteSession` to persist session state locally. The agent remembers what was said earlier in the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10515de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import SQLiteSession\n",
    "\n",
    "chat_agent = Agent(\n",
    "    name=\"ShortTermAssistant\",\n",
    "    instructions=\"You are a concise assistant. Remember details from this conversation.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "session = SQLiteSession(\"irtm-demo-session\")\n",
    "\n",
    "# Turn 1: introduce ourselves\n",
    "result1 = await Runner.run(\n",
    "    chat_agent,\n",
    "    \"My name is Alex and I work on legal NLP.\",\n",
    "    session=session,\n",
    ")\n",
    "print(\"Turn 1:\", result1.final_output)\n",
    "\n",
    "# Turn 2: test whether the agent remembers\n",
    "result2 = await Runner.run(\n",
    "    chat_agent,\n",
    "    \"What is my research area, and what is my name?\",\n",
    "    session=session,\n",
    ")\n",
    "print(\"\\nTurn 2:\", result2.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae884b9e",
   "metadata": {},
   "source": [
    "**Observation:** The agent remembers \"Alex\" and \"legal NLP\" from Turn 1 when asked about it in Turn 2. This short-term memory is maintained by the `SQLiteSession`, which automatically manages the conversation history within the context window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad1cdb",
   "metadata": {},
   "source": [
    "## 4.2 Long-Term Memory (FAISS Vector Store)\n",
    "\n",
    "An example of long-term memory is using **FAISS** to store information as vector embeddings in an external index. This goes beyond the limited context window and allows the agent to recall facts from arbitrarily many past interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df892ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-term memory with FAISS\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "def embed(texts):\n",
    "    \"\"\"Embed a list of texts using OpenAI's embedding API.\"\"\"\n",
    "    res = client.embeddings.create(model=embedding_model, input=texts)\n",
    "    return np.array([d.embedding for d in res.data], dtype=\"float32\")\n",
    "\n",
    "# Create FAISS index (inner-product similarity)\n",
    "dim = len(embed([\"test\"])[0])\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "memory_texts: list[str] = []\n",
    "\n",
    "def add_memory(text: str):\n",
    "    \"\"\"Store a fact in long-term vector memory.\"\"\"\n",
    "    vec = embed([text])\n",
    "    index.add(vec)\n",
    "    memory_texts.append(text)\n",
    "\n",
    "def search_memory(query: str, k: int = 3):\n",
    "    \"\"\"Retrieve the k most relevant facts from long-term memory.\"\"\"\n",
    "    if index.ntotal == 0:\n",
    "        return []\n",
    "    qvec = embed([query])\n",
    "    scores, ids = index.search(qvec, min(k, index.ntotal))\n",
    "    return [(memory_texts[i], float(scores[0][j])) for j, i in enumerate(ids[0]) if i >= 0]\n",
    "\n",
    "# Populate memory with some facts\n",
    "add_memory(\"Jan Scholtes teaches Information Retrieval and Text Mining at Maastricht University.\")\n",
    "add_memory(\"The course covers retrieval models, text classification, topic modeling, and agentic search.\")\n",
    "add_memory(\"FAISS is a library from Meta for efficient similarity search in dense vector collections.\")\n",
    "\n",
    "# Search for a relevant fact\n",
    "results = search_memory(\"What course is taught at Maastricht University?\")\n",
    "print(\"Long-term memory search results:\")\n",
    "for text, score in results:\n",
    "    print(f\"  ({score:.4f}) {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0adb5",
   "metadata": {},
   "source": [
    "## 4.3 Episodic Memory\n",
    "\n",
    "In human cognition, **episodic memory** (Tulving, 1983) stores personal experiences tied to time and context. LLMs have **no built-in episodic memory** — the model weights do not update after each conversation.\n",
    "\n",
    "However, we can *approximate* episodic memory by logging interactions with timestamps and metadata. This gives us a time-ordered personal history that can be searched later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a041e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate episodic memory with timestamped logs\n",
    "conversation_log = []\n",
    "\n",
    "def log_event(event: str):\n",
    "    \"\"\"Log an event with a UTC timestamp.\"\"\"\n",
    "    timestamp = datetime.now(timezone.utc).isoformat()\n",
    "    conversation_log.append(f\"{timestamp} — {event}\")\n",
    "\n",
    "# Log some events\n",
    "log_event(\"Started tutorial notebook\")\n",
    "log_event(\"Added three long-term memory entries about the IRTM course\")\n",
    "log_event(\"Searched long-term memory for course information\")\n",
    "\n",
    "print(\"Episodic memory log:\")\n",
    "for entry in conversation_log:\n",
    "    print(f\"  {entry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c7abe",
   "metadata": {},
   "source": [
    "**Key Takeaway on Memory:**\n",
    "\n",
    "| Memory Type | LLM Capability | Agent Enhancement |\n",
    "|---|---|---|\n",
    "| Short-term | Context window (limited tokens) | Session persistence (SQLiteSession) |\n",
    "| Long-term | None — stateless | Vector databases (FAISS, Pinecone) |\n",
    "| Episodic | None — no autobiographical timeline | Timestamped interaction logs |\n",
    "| Semantic | Training data (static, cut-off) | RAG with live retrieval |\n",
    "\n",
    "Without agentic memory wrappers, LLMs forget everything between sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0406b4",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Action Interface & Tools\n",
    "\n",
    "The key difference between an LLM and an Agent is that **an Agent actually does things** — it doesn't just talk. We need:\n",
    "\n",
    "- **Tool calling** — APIs, Python execution, database queries\n",
    "- **Plugins / function calling** — as in OpenAI's tool APIs\n",
    "- **Environment interaction** — robotics controllers, operating systems\n",
    "\n",
    "With tools, the agent can reach **beyond its own limitations**. This follows the **ReAct paradigm** (Yao et al., 2022): the agent alternates between *Reasoning* (thinking about what to do) and *Acting* (calling tools):\n",
    "\n",
    "**Thought** → **Action** (tool call) → **Observation** → repeat until **Answer**\n",
    "\n",
    "Let's define some tools and create a ReAct-style agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools that the agent can call\n",
    "\n",
    "@function_tool\n",
    "def safe_calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a simple arithmetic expression using +, -, *, / and parentheses.\n",
    "    Used as a tool by the agent instead of letting the LLM 'hallucinate' arithmetic.\n",
    "    \"\"\"\n",
    "    import math\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(ch not in allowed for ch in expression):\n",
    "        return \"Error: disallowed characters.\"\n",
    "    try:\n",
    "        value = eval(expression, {\"__builtins__\": {}}, {\"math\": math})\n",
    "        return str(value)\n",
    "    except Exception as e:\n",
    "        return f\"Error while evaluating: {e}\"\n",
    "\n",
    "@function_tool\n",
    "def store_memory(text: str) -> str:\n",
    "    \"\"\"Store a fact in the shared long-term vector memory.\"\"\"\n",
    "    add_memory(text)\n",
    "    log_event(f\"Stored in memory: {text}\")\n",
    "    return f\"Stored: {text}\"\n",
    "\n",
    "@function_tool\n",
    "def retrieve_memory(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant facts from the shared long-term vector memory.\"\"\"\n",
    "    results = search_memory(query, k=3)\n",
    "    if not results:\n",
    "        return \"No relevant memories found.\"\n",
    "    return \"\\n\".join(f\"- {text} (score={score:.3f})\" for text, score in results)\n",
    "\n",
    "print(\"Tools defined: safe_calculator, store_memory, retrieve_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ccb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct agent: Reason + Act in a loop\n",
    "tool_agent = Agent(\n",
    "    name=\"ReActDemoAgent\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are an LLM-based agent for the Information Retrieval and Text Mining course \n",
    "at Maastricht University. You can:\n",
    "- Store important facts in long-term memory (store_memory).\n",
    "- Retrieve memories (retrieve_memory).\n",
    "- Use a calculator (safe_calculator).\n",
    "Think step-by-step (Reason), then decide whether to call a tool (Act).\n",
    "Explain briefly what you're doing in natural language.\"\"\",\n",
    "    tools=[safe_calculator, store_memory, retrieve_memory],\n",
    ")\n",
    "\n",
    "session_tools = SQLiteSession(\"tools-demo\")\n",
    "\n",
    "# Query 1: Store a fact\n",
    "q1 = \"Please remember that my research topic is 'Information extraction for legal case law.'\"\n",
    "r1 = await Runner.run(tool_agent, q1, session=session_tools)\n",
    "print(f\"Q1: {q1}\")\n",
    "print(f\"A1: {r1.final_output}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Query 2: Retrieve memory + compute\n",
    "q2 = \"What is my research topic? Also compute (17 * 23 - 5) / 4.\"\n",
    "r2 = await Runner.run(tool_agent, q2, session=session_tools)\n",
    "print(f\"Q2: {q2}\")\n",
    "print(f\"A2: {r2.final_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a33ca",
   "metadata": {},
   "source": [
    "**Observation:** The agent demonstrates the **ReAct pattern** — it reasons about what it needs to do, then calls the appropriate tools. For the memory question, it uses `retrieve_memory`. For arithmetic, it uses `safe_calculator` instead of trying to compute in its head (where it might hallucinate). This shows how the **Action Interface** extends the LLM's capabilities beyond text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f1413",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Goal & Task Management, Reasoning & Planning\n",
    "\n",
    "## Goal Management\n",
    "\n",
    "In classical AI (Russell & Norvig's BDI architecture), goal management involves:\n",
    "- **Beliefs** = what the agent knows (state of the world)\n",
    "- **Desires** = what the agent wants (possible goals)\n",
    "- **Intentions** = what the agent is committed to pursue (active goals)\n",
    "\n",
    "### Why Is Goal Management Hard?\n",
    "\n",
    "- **Conflicting goals**: \"Be on time\" vs. \"Drive slowly for safety\"\n",
    "- **Dynamic environments**: A goal set earlier might no longer make sense\n",
    "- **Scalability**: Adding new goals often required rewriting arbitration logic\n",
    "- **No meta-goals**: Classical agents couldn't reflect and reprioritize\n",
    "\n",
    "### Goal Management with LLMs\n",
    "\n",
    "LLM-based systems handle goals differently:\n",
    "- **Natural language goals** — users express them freely (\"Plan my trip under €500\")\n",
    "- **Goal decomposition** — LLMs break high-level goals into subgoals\n",
    "- **Dynamic reprioritization** — frameworks like AutoGPT re-evaluate at each step\n",
    "- **Arbitration strategies**: rule-based filters, scoring functions, human-in-the-loop\n",
    "\n",
    "## Reasoning Frameworks\n",
    "\n",
    "LLMs are \"local optimizers\" — they generate the next most likely token. Multi-step tasks require explicit planning scaffolds:\n",
    "\n",
    "| Framework | Description |\n",
    "|---|---|\n",
    "| **CoT** (Chain-of-Thought) | \"Think step by step\" — linear reasoning chain |\n",
    "| **ToT** (Tree-of-Thought) | Explore multiple reasoning paths, evaluate and prune |\n",
    "| **SoT** (Skeleton-of-Thought) | Generate outline first, then fill in details |\n",
    "| **Self-Consistency** | Run same question multiple times, compare outputs |\n",
    "| **ReAct** | Alternate between Reasoning and Acting (tool calls) |\n",
    "\n",
    "## Control Loop\n",
    "\n",
    "The agentic control loop follows a cybernetic cycle: **Plan → Act → Observe → Reflect → Repeat**\n",
    "\n",
    "Let's demonstrate this with a **Planner + Worker** architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal & Task Management: Planner + Worker architecture\n",
    "planner = Agent(\n",
    "    name=\"Planner\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a planning agent.\n",
    "Given a high-level goal, break it into 3–7 ordered, concrete sub-tasks.\n",
    "Output numbered steps.\"\"\",\n",
    ")\n",
    "\n",
    "worker = Agent(\n",
    "    name=\"Worker\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You execute plans step-by-step.\n",
    "You may call tools to do calculations or retrieve memory.\n",
    "After each step, briefly say what you did.\"\"\",\n",
    "    tools=[safe_calculator, retrieve_memory],\n",
    ")\n",
    "\n",
    "goal = \"\"\"Create 3 bullet points that explain to MSc AI students\n",
    "how LLMs and agentic systems complement each other. \n",
    "Then compute the average of exam scores [7.5, 8.0, 9.0].\"\"\"\n",
    "\n",
    "# Step 1: Plan\n",
    "print(\">>> Planning phase\")\n",
    "plan_result = await Runner.run(planner, goal)\n",
    "plan = plan_result.final_output\n",
    "print(plan)\n",
    "\n",
    "print(\"\\n>>> Execution phase\")\n",
    "# Step 2: Execute the plan\n",
    "exec_result = await Runner.run(worker, f\"Execute this plan:\\n{plan}\")\n",
    "print(exec_result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b135e",
   "metadata": {},
   "source": [
    "**Observation:** This demonstrates the **control loop** — the Planner decomposes the high-level goal into concrete steps, and the Worker executes them sequentially, using tools when needed. This separation of planning and execution is a key pattern in agentic architectures.\n",
    "\n",
    "Note how this mirrors classical AI planning (STRIPS, PDDL) but uses natural language for everything — goals, plans, and actions. The LLM's general knowledge eliminates the need for handcrafted domain models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db0533",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Verification & Guardrails\n",
    "\n",
    "In multi-step agent loops, errors can **propagate and compound**. This is especially dangerous in high-stakes contexts (law, medicine, finance). We need:\n",
    "\n",
    "| Component | Purpose |\n",
    "|---|---|\n",
    "| **Fact-checking modules** | Retrieval-Augmented Verification (RAV): decompose answers into atomic claims, verify each against retrieved evidence |\n",
    "| **Safety filters** | Ethical guardrails (hate speech), legal guardrails (GDPR, copyright), domain-specific constraints |\n",
    "| **External critics** | Self-consistency checks, debate agents, Reflexion frameworks (self-review of past mistakes) |\n",
    "\n",
    "Let's create a **Critic Agent** that reviews another agent's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: Critic agent reviews the Worker's output\n",
    "critic = Agent(\n",
    "    name=\"Critic\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a verification and safety critic.\n",
    "Given an answer produced by another agent, you:\n",
    "1. Check factual and mathematical consistency.\n",
    "2. Point out likely hallucinations or unjustified claims.\n",
    "3. Enforce classroom-appropriate tone (no hate, self-harm, etc.).\n",
    "\n",
    "Respond in JSON with keys:\n",
    "- \"overall_ok\": boolean\n",
    "- \"issues\": list of strings (empty if no issues)\n",
    "- \"suggested_fix\": revised answer if needed, or null if ok\"\"\",\n",
    ")\n",
    "\n",
    "answer_to_check = exec_result.final_output  # from the worker above\n",
    "critic_result = await Runner.run(\n",
    "    critic,\n",
    "    f\"Review this answer for factual accuracy and safety:\\n\\n{answer_to_check}\",\n",
    ")\n",
    "print(\"Critic's assessment:\")\n",
    "print(critic_result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611fd04",
   "metadata": {},
   "source": [
    "**Observation:** The Critic agent acts as an independent verifier. It checks whether the Worker's output is factually correct, mathematically consistent, and safe. In production systems, this pattern prevents hallucinations from reaching the user.\n",
    "\n",
    "This illustrates the concept of **agents checking other agents' work** — a key design pattern for reliable multi-step pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed8bcd",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Multi-Agent Orchestration\n",
    "\n",
    "## When and Why?\n",
    "\n",
    "Multi-agent systems become valuable when tasks require more structure, reliability, or specialised reasoning than a single model can provide:\n",
    "\n",
    "- **Specialisation** — different agents focus on different competencies (planner, researcher, writer, verifier)\n",
    "- **Redundancy** — multiple agents critique each other's work, reducing hallucinations\n",
    "- **Inspectable structure** — explicit, auditable reasoning steps\n",
    "\n",
    "**However**, multi-agent systems come at a cost: more computation, more complexity, harder debugging. Only use them when the added orchestration genuinely improves performance.\n",
    "\n",
    "## Orchestration Patterns\n",
    "\n",
    "| Pattern | Description |\n",
    "|---|---|\n",
    "| **Hierarchical (Manager + Specialists)** | A central manager routes queries to specialist agents |\n",
    "| **Pipeline** | Task flows through agents in sequence (planner → researcher → writer → editor) |\n",
    "| **Debate / Committee** | Multiple agents answer independently; a judge reconciles |\n",
    "| **Shared Blackboard** | Agents contribute to a common memory store others can read |\n",
    "\n",
    "Let's demonstrate three patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86572ad2",
   "metadata": {},
   "source": [
    "## 8.1 Manager + Specialists (Hierarchical Pattern)\n",
    "\n",
    "We create:\n",
    "- A `MathAgent` with calculator tools\n",
    "- A `SearchAgent` that focuses on Information Retrieval explanations\n",
    "- A `ManagerAgent` that routes questions to the right specialist via handoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e384c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent I: Manager + Specialists\n",
    "\n",
    "# Specialist 1: Math\n",
    "math_agent = Agent(\n",
    "    name=\"MathAgent\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a precise math tutor. Show your reasoning,\n",
    "but if you are unsure, say so and be conservative.\"\"\",\n",
    "    tools=[safe_calculator],\n",
    ")\n",
    "\n",
    "# Specialist 2: IR/NLP\n",
    "ir_agent = Agent(\n",
    "    name=\"IRSearchAgent\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are an expert in Information Retrieval and Text Mining.\n",
    "You explain concepts such as embeddings, retrieval models (BM25, dense retrieval),\n",
    "text classification, topic modeling, and conversational search.\n",
    "Keep answers concise and suitable for MSc AI students.\"\"\",\n",
    ")\n",
    "\n",
    "# Manager: routes to specialists\n",
    "@function_tool\n",
    "def ask_math_agent(question: str) -> str:\n",
    "    \"\"\"Forward a math question to the Math specialist agent.\"\"\"\n",
    "    import asyncio\n",
    "    result = asyncio.get_event_loop().run_until_complete(\n",
    "        Runner.run(math_agent, question)\n",
    "    )\n",
    "    return result.final_output\n",
    "\n",
    "@function_tool\n",
    "def ask_ir_agent(question: str) -> str:\n",
    "    \"\"\"Forward an IR/NLP question to the IR specialist agent.\"\"\"\n",
    "    import asyncio\n",
    "    result = asyncio.get_event_loop().run_until_complete(\n",
    "        Runner.run(ir_agent, question)\n",
    "    )\n",
    "    return result.final_output\n",
    "\n",
    "manager = Agent(\n",
    "    name=\"ManagerAgent\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a routing manager. Given a user question, decide:\n",
    "- If it's about math/calculations → use ask_math_agent\n",
    "- If it's about IR, NLP, text mining → use ask_ir_agent\n",
    "- If mixed → use both and combine the answers\n",
    "Explain which agent you chose and why.\"\"\",\n",
    "    tools=[ask_math_agent, ask_ir_agent],\n",
    ")\n",
    "\n",
    "# Test with different types of questions\n",
    "questions = [\n",
    "    \"Compute the standard deviation of [7.5, 8.0, 9.0].\",\n",
    "    \"Explain how embeddings help retrieve similar legal cases.\",\n",
    "    \"For exam grading, I have scores [6, 7, 9]. What is the average, and how could an IR system help me analyse student answers?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"=== USER: {q} ===\")\n",
    "    r = await Runner.run(manager, q)\n",
    "    print(r.final_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92393c",
   "metadata": {},
   "source": [
    "## 8.2 Debate / Committee Pattern\n",
    "\n",
    "Two independent agents answer the same question. A `JudgeAgent` then critiques both answers and produces a final, hopefully better, response. This illustrates **external critics/evaluators**, **ensemble methods**, and **self-consistency**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent II: Debate / Committee\n",
    "\n",
    "answerer_a = Agent(\n",
    "    name=\"AnswererA\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are an optimistic, creative assistant.\n",
    "Explain things intuitively, even if you need to guess a bit.\"\"\",\n",
    ")\n",
    "\n",
    "answerer_b = Agent(\n",
    "    name=\"AnswererB\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a cautious, conservative assistant.\n",
    "Avoid speculation; admit when something is unclear.\"\"\",\n",
    ")\n",
    "\n",
    "judge = Agent(\n",
    "    name=\"JudgeAgent\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a critical judge.\n",
    "Given a user question and two candidate answers:\n",
    "1. Identify strengths and weaknesses of each.\n",
    "2. Flag any likely hallucinations or mistakes.\n",
    "3. Produce a final, improved answer combining the best of both.\"\"\",\n",
    ")\n",
    "\n",
    "question = \"How can multi-agent LLM systems reduce hallucinations in legal document summarisation tasks?\"\n",
    "\n",
    "# Get two independent answers\n",
    "ans_a = await Runner.run(answerer_a, question)\n",
    "ans_b = await Runner.run(answerer_b, question)\n",
    "\n",
    "# Judge evaluates both\n",
    "judge_prompt = f\"\"\"User question: {question}\n",
    "\n",
    "Answer A (optimistic):\n",
    "{ans_a.final_output}\n",
    "\n",
    "Answer B (cautious):\n",
    "{ans_b.final_output}\n",
    "\n",
    "Please evaluate both and produce a final consolidated answer.\"\"\"\n",
    "\n",
    "verdict = await Runner.run(judge, judge_prompt)\n",
    "print(\"=== JUDGE'S FINAL ANSWER ===\")\n",
    "print(verdict.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737c75f",
   "metadata": {},
   "source": [
    "## 8.3 Shared Memory / Blackboard Pattern\n",
    "\n",
    "All agents can write notes to a shared long-term memory (FAISS index) and read from it. This mimics a classical **blackboard architecture** where agents coordinate through a common workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb528f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Agent III: Shared Memory / Blackboard\n",
    "\n",
    "@function_tool\n",
    "def write_to_blackboard(note: str) -> str:\n",
    "    \"\"\"Any agent can post a note to the shared vector memory.\"\"\"\n",
    "    add_memory(note)\n",
    "    log_event(f\"Blackboard note: {note}\")\n",
    "    return \"Note written to shared blackboard.\"\n",
    "\n",
    "@function_tool\n",
    "def read_from_blackboard(query: str) -> str:\n",
    "    \"\"\"Any agent can retrieve relevant notes from the shared vector memory.\"\"\"\n",
    "    res = search_memory(query, k=5)\n",
    "    if not res:\n",
    "        return \"No relevant notes on the blackboard.\"\n",
    "    return \"\\n\".join(f\"- {text} (score={score:.3f})\" for text, score in res)\n",
    "\n",
    "researcher = Agent(\n",
    "    name=\"Researcher\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a research agent. Gather key points about a topic\n",
    "and write them to the shared blackboard using write_to_blackboard.\"\"\",\n",
    "    tools=[write_to_blackboard],\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    name=\"Writer\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"You are a writing agent. Read relevant notes from the \n",
    "shared blackboard using read_from_blackboard, then produce a well-structured\n",
    "summary paragraph.\"\"\",\n",
    "    tools=[read_from_blackboard],\n",
    ")\n",
    "\n",
    "# Phase 1: Researcher gathers and writes notes\n",
    "print(\">>> Research phase\")\n",
    "r_res = await Runner.run(\n",
    "    researcher,\n",
    "    \"Gather key points about how LLMs and agentic systems complement each other in the context of conversational search. Write at least 3 notes to the blackboard.\",\n",
    ")\n",
    "print(r_res.final_output)\n",
    "\n",
    "# Phase 2: Writer reads blackboard and synthesizes\n",
    "print(\"\\n>>> Writing phase\")\n",
    "r_write = await Runner.run(\n",
    "    writer,\n",
    "    \"Read the blackboard for notes about LLMs and agentic systems. Produce a concise summary suitable for MSc AI students.\",\n",
    ")\n",
    "print(r_write.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc4a85",
   "metadata": {},
   "source": [
    "**Observation:** In the Blackboard pattern, agents coordinate through a shared memory store rather than directly communicating. The Researcher writes facts; the Writer reads them and synthesizes. This pattern is particularly useful for complex pipelines where intermediate results need to be shared across multiple agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da026660",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Agent Interoperability & Standards\n",
    "\n",
    "As agentic systems proliferate, **interoperability** becomes crucial. Several standards and protocols are emerging:\n",
    "\n",
    "## Agent Orchestration Frameworks\n",
    "\n",
    "| Framework | Developer | Key Features |\n",
    "|---|---|---|\n",
    "| **OpenAI Agents SDK** | OpenAI | Tool calling, sessions, handoffs (used in this tutorial) |\n",
    "| **LangGraph** | LangChain | Graph-based agent workflows, state machines |\n",
    "| **Google ADK** | Google | Agent Development Kit with sub-agent routing |\n",
    "| **Mistral Agents API** | Mistral | Agent orchestration for Mistral models |\n",
    "| **N8n** | Open source | Visual multi-agent design and orchestration |\n",
    "| **Amazon Bedrock** | AWS | Managed agent orchestration on AWS |\n",
    "\n",
    "## Agent Communication Protocols\n",
    "\n",
    "| Protocol | Purpose |\n",
    "|---|---|\n",
    "| **MCP** (Model Context Protocol) | Defines how LLMs interface with **tools** — search internet, access databases, orchestrate workflows. Standardizes the tool layer. |\n",
    "| **A2A** (Agent-to-Agent) | Defines how agents **discover and communicate** with each other. Includes *Agent Cards* (JSON metadata: name, capabilities, skills). |\n",
    "| **ANP** (Agent Network Protocol) | Handles network identities for agents |\n",
    "| **ACP** (Agent Communication Protocol) | Standardizes messaging format between agents |\n",
    "\n",
    "### Example: Google ADK Multi-Agent Setup\n",
    "\n",
    "```python\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "billing_agent = LlmAgent(name=\"Billing\", description=\"Handles billing inquiries.\")\n",
    "support_agent = LlmAgent(name=\"Support\", description=\"Handles technical support.\")\n",
    "\n",
    "coordinator = LlmAgent(\n",
    "    name=\"HelpDeskCoordinator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Route user requests to the appropriate specialist.\",\n",
    "    sub_agents=[billing_agent, support_agent],\n",
    ")\n",
    "```\n",
    "\n",
    "### Example: A2A Agent Card\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"LegalResearchAgent\",\n",
    "  \"description\": \"Searches legal databases and summarizes case law.\",\n",
    "  \"url\": \"https://legal-agent.example.com\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"capabilities\": { \"streaming\": true, \"pushNotifications\": false },\n",
    "  \"skills\": [\n",
    "    { \"name\": \"case_search\", \"description\": \"Search for relevant legal cases\" },\n",
    "    { \"name\": \"statute_lookup\", \"description\": \"Look up statutes by jurisdiction\" }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037b08d",
   "metadata": {},
   "source": [
    "## Agent Evaluation & Benchmarks\n",
    "\n",
    "How do we know if agents actually work? Several benchmarks have emerged:\n",
    "\n",
    "| Benchmark | What It Tests | Current Best |\n",
    "|---|---|---|\n",
    "| **WebArena** | Browser-based tasks (navigate, fill forms, search) | ~68% success |\n",
    "| **TheAgentCompany** | Virtual company with 175 employee tasks | ~43% solved |\n",
    "| **MultiAgentBench** | Multi-agent coordination tasks | Active research |\n",
    "\n",
    "These numbers show that **agent systems are still far from reliable** in complex real-world tasks. The gap between demo performance and production reliability remains significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43209ab2",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Challenges & Future Directions\n",
    "\n",
    "## Current Challenges\n",
    "\n",
    "| Challenge | Description |\n",
    "|---|---|\n",
    "| **Accuracy & Hallucinations** | Human-in-the-loop needed for high-stakes decisions |\n",
    "| **Tool Misuse & Safety** | Sandboxing, whitelisting, audit trails required |\n",
    "| **Bias & Fairness** | RLHF alignment doesn't guarantee fairness; testing for discriminatory outputs |\n",
    "| **Privacy** | Agents handle sensitive data — need strict data governance |\n",
    "| **Transparency** | Reveal AI identity, log reasoning/sources for accountability |\n",
    "| **Human Oversight** | Augment, not replace — keep humans in the loop |\n",
    "| **Evaluation** | Multi-step action sequences are hard to evaluate; new benchmarks needed |\n",
    "\n",
    "## \"There Is Nothing Magic\"\n",
    "\n",
    "LLM-based agents fit naturally into the **Reinforcement Learning** framework:\n",
    "- **States** = conversation history + memory + environment\n",
    "- **Actions** = generate text, call tools, ask clarifying questions\n",
    "- **Policy** = the LLM itself (mapping states to actions)\n",
    "- **Reward** = task completion, user satisfaction, factual accuracy\n",
    "\n",
    "The key difference from classical RL: the action space is **combinatorial and expressed in natural language**.\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "1. **Multimodal Conversational AI** — voice, text, and image search seamlessly combined\n",
    "2. **Augmented Reality Search** — smart glasses overlaying information on the real world\n",
    "3. **LLM + Structured Search Integration** — combining neural reasoning with database queries\n",
    "4. **Ethical AI** — addressing energy consumption, misinformation, bias, privacy, and filter bubbles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c30fc",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: The LLM–Agent Symbiosis\n",
    "\n",
    "**LLMs alone give us:**\n",
    "- Perception over diverse text (and, with multimodal models, images/audio/video)\n",
    "- Short-term conversation memory via the context window\n",
    "- Powerful but myopic reasoning inside one prompt\n",
    "\n",
    "**Agentic architectures add:**\n",
    "- Tools and environment control → real actions in the world\n",
    "- Structured memory (vector DBs, logs) beyond the context window\n",
    "- Goal & task management, planning, critics, and guardrails\n",
    "\n",
    "**Conversely, agentic scaffolding fixes several limitations of stand-alone LLMs:**\n",
    "- Reduced hallucinations via tools, retrieval, and critics\n",
    "- Longer-term coherence via explicit memories\n",
    "- Better safety via explicit guardrail components\n",
    "\n",
    "This is the **LLM–Agent symbiosis** that makes modern conversational search possible.\n",
    "\n",
    "### References\n",
    "\n",
    "| Paper | Authors |\n",
    "|---|---|\n",
    "| *The Rise and Potential of Large Language Model Based Agents* | Xi et al. (2023) |\n",
    "| *ReAct: Synergizing Reasoning and Acting in Language Models* | Yao et al. (2022) |\n",
    "| *TrustAgent: Towards Safe and Trustworthy LLM-based Agents* | Hua et al. (2024) |\n",
    "| *Chain-of-Agents: LLM Collaboration for Long-Context Tasks* | Google Research (2025) |\n",
    "| *PaSa: An LLM Agent for Comprehensive Academic Paper Search* | He et al. (2025, ACL) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64dd1f",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercises\n",
    "\n",
    "The following exercises are graded. Please provide your answers in the designated cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68255f54",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6939e1aed1092d838acb6a8fa482fde",
     "grade": true,
     "grade_id": "solution_1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 1 — RAG vs Agentic Search (5 points)\n",
    "\n",
    "Compare and contrast **standard RAG** (Retrieval-Augmented Generation) and **Agentic Search** as approaches to conversational information retrieval. In your answer, address:\n",
    "\n",
    "1. What are the key architectural differences between standard RAG and an agentic search system?\n",
    "2. What specific limitations of RAG does an agentic architecture overcome?\n",
    "3. Give a concrete example of a search task that *requires* an agentic approach and explain why standard RAG would fail.\n",
    "\n",
    "Write your answer in the cell below (minimum 150 words).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00f128",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40334574",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee0a1f32a7576a168525cde75e7e2a2c",
     "grade": true,
     "grade_id": "solution_2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 2 — Multi-Agent Orchestration Patterns (5 points)\n",
    "\n",
    "This tutorial demonstrated three multi-agent orchestration patterns: **Manager + Specialists**, **Debate / Committee**, and **Shared Blackboard**. In your answer, address:\n",
    "\n",
    "1. For each pattern, describe in one sentence what makes it distinct from the other two.\n",
    "2. What are the trade-offs of multi-agent systems vs. a single well-prompted agent? Consider cost, latency, reliability, and complexity.\n",
    "3. A law firm wants to build an AI system that (a) searches case law databases, (b) verifies legal citations, and (c) produces a summary memo for lawyers. Which orchestration pattern(s) would you recommend and why?\n",
    "\n",
    "Write your answer in the cell below (minimum 150 words).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c4283",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093f3eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f4324244a1ec27385e692bc9e5e4eca",
     "grade": true,
     "grade_id": "solution_3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 3 — Build a Fact-Checking Agent Pipeline (10 points)\n",
    "\n",
    "Write code that implements a **two-agent fact-checking pipeline** using the OpenAI Agents SDK:\n",
    "\n",
    "1. Create an `AnswerAgent` that answers a user question using `gpt-4o-mini`\n",
    "2. Create a `FactCheckAgent` that:\n",
    "   - Receives the `AnswerAgent`'s output\n",
    "   - Decomposes it into individual factual claims\n",
    "   - Evaluates each claim as \"supported\", \"unsupported\", or \"unverifiable\"\n",
    "   - Returns a JSON string with keys `\"claims\"` (list of dicts with `\"claim\"` and `\"verdict\"`) and `\"overall_trustworthy\"` (boolean)\n",
    "3. Run the pipeline on the question: `\"What are the main differences between BM25 and dense retrieval for document search?\"`\n",
    "4. Store the AnswerAgent's output in a variable called `answer_text` and the FactCheckAgent's output in a variable called `fact_check_result`\n",
    "\n",
    "You may use the `Agent`, `Runner`, and `await` pattern demonstrated in this tutorial.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError(\"Replace this line with your solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e601df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograder test cell — do not modify\n",
    "assert 'answer_text' in dir(), \"You need to define 'answer_text'\"\n",
    "assert 'fact_check_result' in dir(), \"You need to define 'fact_check_result'\"\n",
    "assert isinstance(answer_text, str) and len(answer_text) > 50, \\\n",
    "    \"answer_text should be a non-trivial string response\"\n",
    "assert isinstance(fact_check_result, str) and len(fact_check_result) > 20, \\\n",
    "    \"fact_check_result should be a non-trivial string response\"\n",
    "# Try parsing the fact-check result as JSON\n",
    "import json\n",
    "try:\n",
    "    parsed = json.loads(fact_check_result)\n",
    "    assert \"claims\" in parsed, \"fact_check_result JSON should contain 'claims' key\"\n",
    "    assert \"overall_trustworthy\" in parsed, \"fact_check_result JSON should contain 'overall_trustworthy' key\"\n",
    "    assert isinstance(parsed[\"claims\"], list), \"'claims' should be a list\"\n",
    "    assert len(parsed[\"claims\"]) > 0, \"'claims' list should not be empty\"\n",
    "    print(f\"Answer length: {len(answer_text)} chars\")\n",
    "    print(f\"Number of claims checked: {len(parsed['claims'])}\")\n",
    "    print(f\"Overall trustworthy: {parsed['overall_trustworthy']}\")\n",
    "    print(\"All auto-graded tests passed!\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Warning: fact_check_result is not valid JSON, but we will accept non-JSON critic output too.\")\n",
    "    print(f\"Answer length: {len(answer_text)} chars\")\n",
    "    print(f\"Fact-check length: {len(fact_check_result)} chars\")\n",
    "    print(\"Auto-graded tests passed (non-JSON output accepted).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
