{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230611e8",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f301d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c63ecf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0001",
   "metadata": {},
   "source": [
    "![Maastricht_University_logo.svg](data:image/svg+xml;base64,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)\n",
    "\n",
    "# Information Retrieval and Text Mining Course\n",
    "## Tutorial 08 — Detecting Patterns and Organizing Text: Supervised Text Classification (Part 1)\n",
    "\n",
    "**Author:** Jan Scholtes\n",
    "\n",
    "**Edition 2025-2026**\n",
    "\n",
    "Department of Advanced Computer Sciences — Maastricht University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0002",
   "metadata": {},
   "source": [
    "Welcome to Tutorial 08 on **Supervised Text Classification**. Text classification is a fundamental task in Information Retrieval and Text Mining: by transforming unstructured text into structured categories, we enable machines to understand intent, prioritize risk, and orchestrate complex tasks.\n",
    "\n",
    "In this tutorial, you will learn and practice several supervised methods for document classification:\n",
    "\n",
    "1. **Decision Trees and Random Forests** — entropy-based splitting and ensemble learning.\n",
    "2. **Naïve Bayes Classifier** — probabilistic classification using Bayes' rule.\n",
    "3. **Logistic Regression** — discriminative classification with gradient descent.\n",
    "4. **k-Nearest Neighbors (kNN)** — instance-based lazy learning.\n",
    "5. **Support Vector Machines (SVM)** — maximum-margin classification with linear and non-linear kernels.\n",
    "6. **Fine-tuning BERT for Sentiment Analysis** — deep learning approach with Transformers.\n",
    "7. **Sentiment and Emotion Analysis** — keyword-based vs. BERT-based approaches.\n",
    "8. **Toxic Text Detection** — content moderation with classification.\n",
    "\n",
    "At the end you will find the **Exercises** section with graded assignments.\n",
    "\n",
    "> **Note:** This course is about Information Retrieval, Text Mining, and Conversational Search — not about programming skills. The code cells below show you *how* these methods work in practice using Python libraries. Focus on understanding the **concepts** and **results**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0003",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "\n",
    "We install all required packages in a single cell. Run this cell once at the beginning of your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess, sys\n",
    "\n",
    "packages = [\n",
    "    \"scikit-learn\",\n",
    "    \"datasets\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"nltk\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"wordcloud\",\n",
    "]\n",
    "for pkg in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0005",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "\n",
    "All imports are grouped here so the notebook is easy to set up and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "# Data & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('movie_reviews', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer, TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"All libraries loaded successfully.\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0007",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset: The 20 Newsgroups Corpus\n",
    "\n",
    "Throughout this tutorial we will use the **20 Newsgroups** dataset, a classic benchmark for text classification. It contains approximately 20,000 newsgroup postings across 20 different topics.\n",
    "\n",
    "For the first five sections we select a 4-category subset to keep training times short. We also prepare the NLTK Movie Reviews corpus for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 20 Newsgroups (4 categories for speed)\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['sci.space', 'rec.sport.hockey', 'comp.graphics', 'talk.politics.mideast']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','footers','quotes'), random_state=SEED)\n",
    "newsgroups_test  = fetch_20newsgroups(subset='test',  categories=categories, remove=('headers','footers','quotes'), random_state=SEED)\n",
    "\n",
    "print(f\"Training documents: {len(newsgroups_train.data)}\")\n",
    "print(f\"Test documents:     {len(newsgroups_test.data)}\")\n",
    "print(f\"Categories:         {newsgroups_train.target_names}\")\n",
    "print(f\"\\nSample document (first 200 chars):\\n{newsgroups_train.data[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features (used by most classifiers)\n",
    "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(newsgroups_train.data)\n",
    "X_test_tfidf  = tfidf.transform(newsgroups_test.data)\n",
    "\n",
    "y_train = newsgroups_train.target\n",
    "y_test  = newsgroups_test.target\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X_train_tfidf.shape} (documents × features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0010",
   "metadata": {},
   "source": [
    "We also create a **CountVectorizer** (for Naïve Bayes, which works with raw counts) and store the target names for label display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count features for Naive Bayes\n",
    "count_vec = CountVectorizer(max_features=10000, stop_words='english')\n",
    "X_train_counts = count_vec.fit_transform(newsgroups_train.data)\n",
    "X_test_counts  = count_vec.transform(newsgroups_test.data)\n",
    "\n",
    "target_names = newsgroups_train.target_names\n",
    "\n",
    "# Helper function to print evaluation results\n",
    "def evaluate_classifier(name, y_true, y_pred, target_names):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0012",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Decision Trees and Random Forests\n",
    "\n",
    "## 1.1 Decision Trees\n",
    "\n",
    "A **decision tree** classifies documents by learning a hierarchy of if-then rules from the training data. At each internal node, the algorithm selects the feature (word) that best splits the data, measured by **information gain** (reduction in entropy).\n",
    "\n",
    "**Entropy** measures the impurity of a dataset:\n",
    "\n",
    "$$H(S) = -\\sum_{i=1}^{c} p_i \\log_2 p_i$$\n",
    "\n",
    "where $p_i$ is the proportion of samples belonging to class $i$. A set that is 100% one class has entropy 0 (pure); a 50-50 split has entropy 1 (maximum impurity).\n",
    "\n",
    "**Information gain** is the reduction in entropy achieved by splitting on a particular feature:\n",
    "\n",
    "$$IG(S, A) = H(S) - \\sum_{v \\in \\text{values}(A)} \\frac{|S_v|}{|S|} H(S_v)$$\n",
    "\n",
    "The algorithm recursively picks the attribute with the highest information gain as the splitting node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=20, random_state=SEED)\n",
    "dt_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_dt = dt_clf.predict(X_test_tfidf)\n",
    "acc_dt = evaluate_classifier(\"Decision Tree\", y_test, y_pred_dt, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top of the decision tree\n",
    "tree_text = export_text(dt_clf, feature_names=tfidf.get_feature_names_out().tolist(), max_depth=3)\n",
    "print(\"Decision Tree (first 3 levels):\\n\")\n",
    "print(tree_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances: which words are most discriminating?\n",
    "importances = dt_clf.feature_importances_\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "top_k = 20\n",
    "top_indices = np.argsort(importances)[-top_k:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_k), importances[top_indices])\n",
    "plt.yticks(range(top_k), feature_names[top_indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Most Important Words (Decision Tree)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0016",
   "metadata": {},
   "source": [
    "## 1.2 Random Forests\n",
    "\n",
    "A **Random Forest** is an *ensemble* of decision trees. Each tree is trained on a random subset of the data (bagging) and uses a random subset of features. The final prediction is the majority vote across all trees — the \"wisdom of crowds.\"\n",
    "\n",
    "Key advantages:\n",
    "- **Reduces overfitting** compared to a single decision tree\n",
    "- **Low correlation** between trees (due to random feature selection) increases ensemble diversity\n",
    "- **More robust** to noise and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=SEED, n_jobs=-1)\n",
    "rf_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test_tfidf)\n",
    "acc_rf = evaluate_classifier(\"Random Forest (100 trees)\", y_test, y_pred_rf, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0018",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Naïve Bayes Classifier\n",
    "\n",
    "**Naïve Bayes** is a probabilistic classifier based on Bayes' theorem with a strong (naïve) independence assumption between features. Given a document $d$ and a class $c$:\n",
    "\n",
    "$$c_{\\text{MAP}} = \\arg\\max_{c \\in C} P(c \\mid d) = \\arg\\max_{c \\in C} P(d \\mid c) \\cdot P(c)$$\n",
    "\n",
    "Under the **Naïve Bayes assumption**, the probability of observing a document given a class is the product of individual word probabilities:\n",
    "\n",
    "$$P(d \\mid c) = \\prod_{i=1}^{n} P(x_i \\mid c)$$\n",
    "\n",
    "**Key properties:**\n",
    "- **Training**: simply count word frequencies per class (very fast — $O(|D| \\cdot L_{\\text{avg}})$)\n",
    "- **Classification**: compute log-probabilities for each class and pick the highest ($O(|C| \\cdot L_t)$)\n",
    "- **Laplace smoothing** prevents zero probabilities for unseen words: $P(x_i \\mid c_j) = \\frac{N(x_i, c_j) + 1}{N(c_j) + |V|}$\n",
    "- Simple weight interpretation: $\\log P(x_i \\mid c)$ tells you how indicative word $x_i$ is of class $c$\n",
    "\n",
    "Despite violating the independence assumption (words in natural language are not independent), Naïve Bayes performs surprisingly well for text classification and is often used as a fast baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Multinomial Naive Bayes classifier (uses word counts, not TF-IDF)\n",
    "nb_clf = MultinomialNB(alpha=1.0)  # alpha=1.0 is Laplace smoothing\n",
    "nb_clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred_nb = nb_clf.predict(X_test_counts)\n",
    "acc_nb = evaluate_classifier(\"Naive Bayes (Multinomial)\", y_test, y_pred_nb, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most informative features per class\n",
    "print(\"Most informative words per class (highest log-probability):\\n\")\n",
    "for i, category in enumerate(target_names):\n",
    "    log_probs = nb_clf.feature_log_prob_[i]\n",
    "    top_indices = np.argsort(log_probs)[-10:][::-1]\n",
    "    words = count_vec.get_feature_names_out()[top_indices]\n",
    "    print(f\"  {category:30s}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0021",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Logistic Regression\n",
    "\n",
    "**Logistic Regression** is a *discriminative* classifier (unlike the *generative* Naïve Bayes). It directly models $P(c \\mid d)$ by learning a weight vector $\\mathbf{w}$ and bias $b$:\n",
    "\n",
    "$$z = \\mathbf{w} \\cdot \\mathbf{x} + b$$\n",
    "$$P(y=1 \\mid \\mathbf{x}) = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "**Generative vs. Discriminative:**\n",
    "- *Naïve Bayes* (generative): \"Given class $c$, what does a typical document look like?\"\n",
    "- *Logistic Regression* (discriminative): \"What features distinguish class $c$ from others?\"\n",
    "\n",
    "**Training** uses **cross-entropy loss** minimized by **stochastic gradient descent (SGD)**. The gradient update is remarkably simple:\n",
    "\n",
    "$$\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\cdot (\\hat{y} - y) \\cdot \\mathbf{x}$$\n",
    "\n",
    "**Properties:**\n",
    "- Computationally efficient and highly interpretable\n",
    "- Linear decision boundary (same as Naïve Bayes, but usually better calibrated)\n",
    "- Requires feature selection — sensitive to irrelevant features\n",
    "- Cannot solve non-linear problems (unlike SVM with kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=SEED, C=1.0)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = lr_clf.predict(X_test_tfidf)\n",
    "acc_lr = evaluate_classifier(\"Logistic Regression\", y_test, y_pred_lr, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most discriminative words per class (highest positive weights)\n",
    "print(\"Most discriminative words per class (Logistic Regression):\\n\")\n",
    "for i, category in enumerate(target_names):\n",
    "    top_indices = np.argsort(lr_clf.coef_[i])[-10:][::-1]\n",
    "    words = tfidf.get_feature_names_out()[top_indices]\n",
    "    print(f\"  {category:30s}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0024",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. k-Nearest Neighbors (kNN)\n",
    "\n",
    "**kNN** is a non-parametric, instance-based classifier. Instead of learning a model, it memorizes all training examples and classifies new documents by finding the $k$ most similar training documents and returning the majority class.\n",
    "\n",
    "$$c_{\\text{kNN}} = \\arg\\max_{c \\in C} \\sum_{d_i \\in N_k(d)} \\mathbf{1}[c(d_i) = c]$$\n",
    "\n",
    "**Key properties:**\n",
    "- **No training required** (lazy learning) — all computation happens at test time\n",
    "- **Similarity metric**: for text, cosine similarity of TF-IDF vectors is most effective\n",
    "- **k** is typically odd (3 or 5) to avoid ties\n",
    "- **Cover & Hart (1967)**: asymptotic error rate of 1-NN is less than twice the Bayes optimal rate\n",
    "- **Locally defined** decision boundaries — far-away points do not influence classification\n",
    "- Scales well with many classes (no need to train separate classifiers)\n",
    "- Can be expensive at test time for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a kNN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, metric='cosine', n_jobs=-1)\n",
    "knn_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_knn = knn_clf.predict(X_test_tfidf)\n",
    "acc_knn = evaluate_classifier(\"k-Nearest Neighbors (k=5)\", y_test, y_pred_knn, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0026",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Support Vector Machines (SVM)\n",
    "\n",
    "**Support Vector Machines** find the hyperplane that maximizes the *margin* — the distance between the decision boundary and the nearest training points (the *support vectors*).\n",
    "\n",
    "**Linear SVM** finds $\\mathbf{w}$ and $b$ such that:\n",
    "$$\\min_{\\mathbf{w},b} \\frac{1}{2} \\|\\mathbf{w}\\|^2 \\quad \\text{subject to} \\quad y_i(\\mathbf{w}^T \\mathbf{x}_i + b) \\geq 1 \\quad \\forall i$$\n",
    "\n",
    "The margin is $\\rho = \\frac{2}{\\|\\mathbf{w}\\|}$, and maximizing it is equivalent to minimizing $\\|\\mathbf{w}\\|^2$.\n",
    "\n",
    "**Why SVM works well for text:**\n",
    "- TF-IDF vectors are very high-dimensional and sparse → linear separability is common\n",
    "- The maximum-margin principle provides good generalization\n",
    "- Only support vectors matter; the classifier is robust to the bulk of training data\n",
    "\n",
    "**Non-linear SVM:** When data is not linearly separable, we can map features to a higher-dimensional space using a *kernel function* (e.g., polynomial, Gaussian/RBF). With dense word embeddings (Word2Vec, BERT), Gaussian SVM often outperforms linear SVM.\n",
    "\n",
    "**Class imbalance:** SVM can be biased toward the majority class. Solutions include:\n",
    "- **Under/over sampling** the training data\n",
    "- **Ensemble methods** (split majority class into balanced subsets)\n",
    "- **Cost-sensitive learning** (higher misclassification cost for minority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM (best for sparse TF-IDF features)\n",
    "lsvm_clf = LinearSVC(C=1.0, random_state=SEED, max_iter=10000)\n",
    "lsvm_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lsvm = lsvm_clf.predict(X_test_tfidf)\n",
    "acc_lsvm = evaluate_classifier(\"Linear SVM\", y_test, y_pred_lsvm, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all classifiers so far\n",
    "results = {\n",
    "    'Decision Tree': acc_dt,\n",
    "    'Random Forest':  acc_rf,\n",
    "    'Naive Bayes':    acc_nb,\n",
    "    'Logistic Reg':   acc_lr,\n",
    "    'kNN (k=5)':      acc_knn,\n",
    "    'Linear SVM':     acc_lsvm,\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(results.keys(), results.values(), color=['#e74c3c','#e67e22','#f1c40f','#2ecc71','#3498db','#9b59b6'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classifier Comparison on 20 Newsgroups (4 categories)')\n",
    "plt.ylim(0.5, 1.0)\n",
    "for bar, acc in zip(bars, results.values()):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{acc:.3f}', ha='center', fontsize=10)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0029",
   "metadata": {},
   "source": [
    "**Observation:** For text classification with TF-IDF features, **Linear SVM** and **Logistic Regression** typically perform best because TF-IDF features are high-dimensional and sparse, making linear separation effective. Naïve Bayes provides a fast, competitive baseline. Decision Trees tend to overfit without careful tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0030",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Fine-tuning BERT for Sentiment Analysis\n",
    "\n",
    "While traditional classifiers work well with handcrafted TF-IDF features, **BERT** (Bidirectional Encoder Representations from Transformers) can learn richer, context-sensitive representations. For **sentiment classification**, we use `BertForSequenceClassification`: the `[CLS]` token embedding is passed through a classification head, and the entire model is fine-tuned end-to-end.\n",
    "\n",
    "**Key advantages of Transformers for text classification:**\n",
    "- **Contextualized embeddings**: the meaning of a word depends on surrounding context\n",
    "- **Transfer learning**: pre-trained on massive text corpora, only needs fine-tuning on task-specific data\n",
    "- **No manual feature engineering**: no need for TF-IDF, stop word removal, or feature selection\n",
    "\n",
    "**Trade-offs:**\n",
    "- Requires a GPU for practical training times\n",
    "- Much larger model (~110M parameters for BERT-base vs. a few thousand for SVM)\n",
    "- Needs annotated training data for fine-tuning\n",
    "\n",
    "We fine-tune BERT on the **IMDB movie review dataset** for binary sentiment classification (positive vs. negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset and create a balanced random subset for fast training\n",
    "full_train = load_dataset(\"imdb\", split=\"train\")\n",
    "full_test  = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "# Shuffle with a fixed seed to randomize label order (IMDB stores neg first, then pos)\n",
    "full_train = full_train.shuffle(seed=SEED)\n",
    "full_test  = full_test.shuffle(seed=SEED)\n",
    "\n",
    "# Take a stratified subset: 1500 positive + 1500 negative = 3000 training samples\n",
    "# This ensures balanced classes and trains in ~2-4 minutes on an RTX 4070 GPU\n",
    "TRAIN_SIZE_PER_CLASS = 1500\n",
    "TEST_SIZE_PER_CLASS  = 500\n",
    "\n",
    "pos_train = full_train.filter(lambda x: x['label'] == 1).select(range(TRAIN_SIZE_PER_CLASS))\n",
    "neg_train = full_train.filter(lambda x: x['label'] == 0).select(range(TRAIN_SIZE_PER_CLASS))\n",
    "from datasets import concatenate_datasets\n",
    "train_set = concatenate_datasets([pos_train, neg_train]).shuffle(seed=SEED)\n",
    "\n",
    "pos_test = full_test.filter(lambda x: x['label'] == 1).select(range(TEST_SIZE_PER_CLASS))\n",
    "neg_test = full_test.filter(lambda x: x['label'] == 0).select(range(TEST_SIZE_PER_CLASS))\n",
    "test_set = concatenate_datasets([pos_test, neg_test]).shuffle(seed=SEED)\n",
    "\n",
    "print(f\"Training set: {len(train_set)} examples  (pos: {sum(1 for x in train_set if x['label']==1)}, neg: {sum(1 for x in train_set if x['label']==0)})\")\n",
    "print(f\"Test set:     {len(test_set)} examples  (pos: {sum(1 for x in test_set if x['label']==1)}, neg: {sum(1 for x in test_set if x['label']==0)})\")\n",
    "print(f\"\\nExample review (first 200 chars): {train_set[0]['text'][:200]}...\")\n",
    "print(f\"Label: {train_set[0]['label']} ({'positive' if train_set[0]['label'] == 1 else 'negative'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer for sentiment analysis\n",
    "model_sa = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer_sa = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_sa(data):\n",
    "    return tokenizer_sa(data['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_set = train_set.map(preprocess_sa, batched=True, batch_size=len(train_set))\n",
    "test_set = test_set.map(preprocess_sa, batched=True, batch_size=len(test_set))\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics_sa(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# Training arguments\n",
    "training_args_sa = TrainingArguments(\n",
    "    output_dir='./results_sa',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='no',\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer_sa = Trainer(\n",
    "    model=model_sa,\n",
    "    args=training_args_sa,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    compute_metrics=compute_metrics_sa,\n",
    ")\n",
    "\n",
    "# Train (~2-4 minutes on RTX 4070 GPU with 3000 balanced training samples)\n",
    "print(\"Starting sentiment analysis fine-tuning...\")\n",
    "trainer_sa.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "eval_results_sa = trainer_sa.evaluate()\n",
    "print(\"\\nSentiment Analysis Results:\")\n",
    "for k, v in eval_results_sa.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0035",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Sentiment and Emotion Analysis\n",
    "\n",
    "**Sentiment analysis** determines whether a piece of text expresses a positive, negative, or neutral opinion. It is one of the most widely used applications of text classification.\n",
    "\n",
    "**A typical sentiment analysis pipeline:**\n",
    "1. Find documents with sentiment or opinion words\n",
    "2. Identify subjective sentences (filter out objective ones)\n",
    "3. Identify individual opinion words/phrases\n",
    "4. Normalize opinion words (synonyms, lexical variants)\n",
    "5. Handle modifiers: negations (\"not good\"), boosters (\"very good\"), sarcasm\n",
    "6. Compute total sentiment score by sentence/document\n",
    "7. Aggregate and visualize results\n",
    "\n",
    "**Keyword-based approaches** use sentiment lexicons (lists of positive/negative words with scores). They achieve high recall but **low precision** because they cannot handle:\n",
    "- Negation (\"not good\")\n",
    "- Sarcasm (\"What a great car, it didn't start the first day\")\n",
    "- Context-dependent meanings\n",
    "- Subjectivity vs. objectivity (\"There is fighting, killing and blood\" — a movie plot summary, not an opinion)\n",
    "\n",
    "**BERT-based approaches** solve these issues through contextual understanding but require annotated training data.\n",
    "\n",
    "**Emotion mining** extends sentiment analysis to detect specific emotions (joy, anger, fear, trust, etc.) using models like Plutchik's Wheel of Emotions with 8 basic emotions forming 4 contrasting pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER: a simple keyword-based sentiment analyzer from NLTK\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test on various sentences\n",
    "test_sentences = [\n",
    "    \"I love this movie, it was absolutely fantastic!\",\n",
    "    \"This is the worst product I have ever bought.\",\n",
    "    \"The weather today is okay, nothing special.\",\n",
    "    \"Not bad at all, actually quite impressive.\",\n",
    "    \"What a great car, it didn't start the first day.\",  # Sarcasm\n",
    "    \"There is fighting, killing and blood all over the script.\",  # Objective\n",
    "]\n",
    "\n",
    "print(f\"{'Sentence':60s} {'neg':>6s} {'neu':>6s} {'pos':>6s} {'comp':>6s}\")\n",
    "print(\"-\" * 85)\n",
    "for sent in test_sentences:\n",
    "    scores = sia.polarity_scores(sent)\n",
    "    print(f\"{sent[:58]:60s} {scores['neg']:6.3f} {scores['neu']:6.3f} {scores['pos']:6.3f} {scores['compound']:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0037",
   "metadata": {},
   "source": [
    "**Observation:** Notice how VADER (keyword-based) struggles with sarcasm and objective statements. The sarcastic sentence \"What a great car, it didn't start the first day\" is scored as primarily neutral/positive, and the objective movie description is scored as very negative because of words like \"fighting\" and \"killing.\" These are exactly the limitations that BERT-based models address through contextual understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis on the NLTK Movie Reviews corpus\n",
    "# Load the corpus (2000 reviews, labeled pos/neg)\n",
    "documents = [(movie_reviews.raw(fileid), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "texts = [doc for doc, label in documents]\n",
    "labels = [1 if label == 'pos' else 0 for doc, label in documents]\n",
    "\n",
    "# Apply VADER to all reviews and compare with true labels\n",
    "vader_preds = []\n",
    "for text in texts:\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    vader_preds.append(1 if score >= 0.05 else 0)\n",
    "\n",
    "vader_acc = accuracy_score(labels, vader_preds)\n",
    "print(f\"VADER accuracy on NLTK Movie Reviews: {vader_acc:.3f}\")\n",
    "print(f\"\\nThis shows the limitation of keyword-based sentiment analysis.\")\n",
    "print(f\"Compare this with the BERT fine-tuned model which typically achieves >87% accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0039",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Toxic Text Detection\n",
    "\n",
    "Toxic text detection is a critical application of text classification for **content moderation** and **safety**. Detection models classify text into sub-types:\n",
    "\n",
    "| Category | Description | Example |\n",
    "|----------|------------|---------|\n",
    "| **Insult** | Rude or disrespectful comments | \"You are absolutely useless\" |\n",
    "| **Hate Speech** | Attacks based on protected attributes | Content targeting identity groups |\n",
    "| **Threat** | Statements of intent to harm | \"If I ever see you, you'll regret it\" |\n",
    "| **Obscenity** | Profanity violating community standards | Vulgar language |\n",
    "| **Severe Toxicity** | Highly offensive or hateful content | Requires immediate removal |\n",
    "\n",
    "**The \"Context\" Challenge:**\n",
    "- Simple keyword lists **fail** because context matters\n",
    "- A movie script about violence is *not* a threat\n",
    "- Sarcasm can turn positive words toxic: *\"Oh, what a brilliant idea\"*\n",
    "- BERT-based models excel here because they understand context\n",
    "\n",
    "**In Agentic AI workflows**, toxic text detection acts as a **guardrail**: before an AI agent processes a request or generates a response, a classification layer checks the input to ensure safety compliance.\n",
    "\n",
    "We demonstrate toxic text classification using a pre-trained model from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a toxicity detection pipeline from HuggingFace\n",
    "from transformers import pipeline\n",
    "\n",
    "toxicity_pipeline = pipeline(\"text-classification\", model=\"unitary/toxic-bert\", truncation=True)\n",
    "\n",
    "# Test on various texts\n",
    "toxic_tests = [\n",
    "    \"I hope you have a wonderful day!\",\n",
    "    \"You are the stupidest person I have ever met.\",\n",
    "    \"The movie contains violence and graphic scenes.\",\n",
    "    \"I will find you and make you pay for this.\",\n",
    "    \"This paper presents a novel approach to text mining.\",\n",
    "    \"Oh sure, your idea is just SO brilliant.\",\n",
    "]\n",
    "\n",
    "print(f\"{'Text':55s} {'Label':>10s} {'Score':>8s}\")\n",
    "print(\"-\" * 75)\n",
    "for text in toxic_tests:\n",
    "    result = toxicity_pipeline(text)[0]\n",
    "    print(f\"{text[:53]:55s} {result['label']:>10s} {result['score']:8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0041",
   "metadata": {},
   "source": [
    "**Observation:** The BERT-based toxicity classifier correctly identifies direct insults and threats with high confidence, while recognizing that violence in a movie description or academic language is not toxic. However, sarcasm remains challenging even for Transformer-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0042",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: Choosing the Right Classifier\n",
    "\n",
    "| Method | Strengths | Weaknesses | Best For |\n",
    "|--------|----------|------------|----------|\n",
    "| **Decision Tree** | Interpretable, fast | Overfits easily | Explainable models |\n",
    "| **Random Forest** | Robust, ensemble | Slower training | General purpose |\n",
    "| **Naïve Bayes** | Very fast, simple | Independence assumption | Baseline, sparse data |\n",
    "| **Logistic Regression** | Interpretable, efficient | Needs feature selection | Well-separated classes |\n",
    "| **kNN** | No training, many classes | Slow at test time | Few training samples |\n",
    "| **Linear SVM** | Best for sparse TF-IDF | Sensitive to imbalance | Long documents |\n",
    "| **BERT** | Context-aware, no features | Expensive, needs GPU | Maximum accuracy |\n",
    "\n",
    "**Rule of thumb:**\n",
    "- Start with **Naïve Bayes** or **Linear SVM** as a baseline\n",
    "- If you need interpretability, use **Logistic Regression** or **Decision Trees**\n",
    "- If you need maximum accuracy and have GPU resources, use **BERT**\n",
    "- For sentiment/toxicity detection, **BERT** significantly outperforms keyword approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0043",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercises\n",
    "\n",
    "The following exercises are graded. Please provide your answers in the designated cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0044",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e033dba4fc8d06e60b7aa4c6bee91df",
     "grade": true,
     "grade_id": "exercise_1_question",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 1 — Naïve Bayes vs. Logistic Regression (5 points)\n",
    "\n",
    "Compare the **Naïve Bayes** and **Logistic Regression** classifiers for text classification. In your answer, address:\n",
    "\n",
    "1. What is the fundamental difference between a *generative* model (Naïve Bayes) and a *discriminative* model (Logistic Regression)?\n",
    "2. Both are linear classifiers. Explain what this means and why it matters for text classification.\n",
    "3. Under what circumstances would you choose Naïve Bayes over Logistic Regression, and vice versa?\n",
    "\n",
    "Write your answer in the cell below (minimum 150 words).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0045",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03d6e747df7b9d361e55b75173f3f8a0",
     "grade": true,
     "grade_id": "exercise_1_answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0046",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be303fc292ef65c42adc269951de113a",
     "grade": true,
     "grade_id": "exercise_2_question",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 2 — SVM and Class Imbalance (5 points)\n",
    "\n",
    "Support Vector Machines are widely considered one of the best methods for text classification with TF-IDF features.\n",
    "\n",
    "1. Explain how SVM finds the optimal decision boundary (maximum margin). Why does maximizing the margin lead to better generalization?\n",
    "2. What are *support vectors* and why are they important?\n",
    "3. Class imbalance is a common problem in text classification (e.g., only 0.1% of documents are relevant). Describe at least two techniques to address class imbalance when using SVM.\n",
    "\n",
    "Write your answer in the cell below (minimum 150 words).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0047",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f88ffa849e16aea131982d07d577f3ec",
     "grade": true,
     "grade_id": "exercise_2_answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-0048",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7024fade407c9029d10a57da8761143b",
     "grade": true,
     "grade_id": "exercise_3_question",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": true
    }
   },
   "source": [
    "## Exercise 3 — Full 20 Newsgroups Classification (10 points)\n",
    "\n",
    "In this tutorial, we used only 4 categories from the 20 Newsgroups dataset. Your task is to build a classifier for **all 20 categories**.\n",
    "\n",
    "1. Load the full 20 Newsgroups dataset (all categories)\n",
    "2. Create TF-IDF features\n",
    "3. Train at least **two different classifiers** (e.g., Linear SVM and Logistic Regression)\n",
    "4. Evaluate both classifiers with `classification_report` and `accuracy_score`\n",
    "5. Store the accuracy of your best classifier in a variable called `best_accuracy`\n",
    "\n",
    "Write your code in the cell below.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0049",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c0984154000bfba9e23800959e9b8eb",
     "grade": false,
     "grade_id": "exercise_3_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-0050",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20cf11cb28b845fdb8f7257c3be45adc",
     "grade": true,
     "grade_id": "exercise_3_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell — do not modify\n",
    "assert 'best_accuracy' in dir(), \"You must define a variable 'best_accuracy' with the accuracy of your best classifier\"\n",
    "assert isinstance(best_accuracy, float), \"best_accuracy must be a float\"\n",
    "assert 0.0 < best_accuracy <= 1.0, \"best_accuracy must be between 0 and 1\"\n",
    "assert best_accuracy > 0.5, \"Your classifier should achieve at least 50% accuracy on 20 categories\"\n",
    "print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
    "print(\"Basic check passed. Your solution will be manually reviewed for correctness.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "nbgrader": {
   "grade": false,
   "grade_id": "",
   "locked": false,
   "schema_version": 3,
   "solution": false,
   "task": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
